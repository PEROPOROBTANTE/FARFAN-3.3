# FARFAN 3.0 Execution Mapping - Granular Method Chains
# $100 USD Production Specification
# NO PLACEHOLDERS - Every method mapped to real implementation

version: "2.0"
last_updated: "2025-10-16"

# ==============================================================================
# DIMENSION D1: INSUMOS (Recursos, Línea Base, Capacidad Institucional)
# ==============================================================================
D1_INSUMOS:
  description: "Evaluación de línea base, recursos disponibles, capacidad institucional"
  question_count: 50  # P1-P10 × Q1-Q5

  # Q1: Baseline Identification
  Q1_Baseline_Identification:
    description: "Identify and analyze baseline conditions"
    execution_chain:
      - step: 1
        module: semantic_processor
        class: SemanticProcessor
        method: chunk_text
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict[str, Any]]
          binding: text_chunks
        purpose: "Segment text into meaningful chunks for baseline analysis"
        async: false

      - step: 2
        module: policy_processor
        class: PolicyTextProcessor
        method: normalize_unicode
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: str
          binding: normalized_text
        purpose: "Normalize text encoding for consistent baseline processing"
        async: false
        dependencies: []

      - step: 3
        module: semantic_processor
        class: AdvancedSemanticChunker
        method: chunk_document
        args:
          - name: document
            type: str
            source: normalized_text
        returns:
          type: List[SemanticChunk]
          binding: semantic_chunks
        purpose: "Create semantic chunks preserving baseline context"
        async: false
        dependencies: [normalized_text]

      - step: 4
        module: policy_segmenter
        class: DocumentSegmenter
        method: segment
        args:
          - name: text
            type: str
            source: normalized_text
        returns:
          type: List[Dict[str, Any]]
          binding: baseline_segments
        purpose: "Extract baseline segments from document"
        async: false
        dependencies: [normalized_text]

    aggregation:
      strategy: baseline_weighted
      weights:
        text_chunks: 0.25
        normalized_text: 0.25
        semantic_chunks: 0.25
        baseline_segments: 0.25
      confidence_threshold: 0.65

  # Q2: Gap Analysis
  Q2_Gap_Analysis:
    description: "Analyze gaps between current state and requirements"
    execution_chain:
      - step: 1
        module: causal_processor
        class: BayesianEvidenceIntegrator
        method: integrate_evidence
        args:
          - name: similarities
            type: NDArray[np.float64]
            source: derived
            derivation: "extract_similarities_from(baseline_segments)"
          - name: chunk_metadata
            type: List[Dict[str, Any]]
            source: derived
            derivation: "extract_metadata_from(baseline_segments)"
        returns:
          type: Dict[str, float]
          binding: gap_evidence
        purpose: "Integrate evidence for gap analysis using Bayesian methods"
        async: false

      - step: 2
        module: analyzer_one
        class: SemanticAnalyzer
        method: extract_semantic_cube
        args:
          - name: text
            type: str
            source: normalized_text
        returns:
          type: Dict[str, Any]
          binding: semantic_cube
        purpose: "Extract semantic cube for gap identification"
        async: true
        dependencies: []

      - step: 3
        module: analyzer_one
        class: BayesianNumericalAnalyzer
        method: evaluate_policy_metric
        args:
          - name: metric_name
            type: str
            source: constant
            value: "baseline_gap"
          - name: text
            type: str
            source: normalized_text
        returns:
          type: Dict[str, Any]
          binding: gap_evaluation
        purpose: "Evaluate baseline gaps using Bayesian numerical analysis"
        async: false
        dependencies: [normalized_text]

    aggregation:
      strategy: gap_weighted
      weights:
        gap_evidence: 0.40
        semantic_cube: 0.30
        gap_evaluation: 0.30
      confidence_threshold: 0.65

  # Q3: Budget Allocation
  Q3_Budget_Allocation:
    description: "Analyze budget allocation for inputs"
    execution_chain:
      - step: 1
        module: financial_analyzer
        class: FinancialAuditor
        method: trace_financial_allocation
        args:
          - name: nodes
            type: List[MetaNode]
            source: derived
            derivation: "extract_input_nodes(baseline_segments)"
          - name: tables
            type: List[pd.DataFrame]
            source: derived
            derivation: "extract_financial_tables(normalized_text)"
        returns:
          type: Dict[str, Any]
          binding: budget_allocation
        purpose: "Trace financial allocation for input resources"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: analyze_financial_feasibility
        args:
          - name: budget_data
            type: Dict
            source: budget_allocation
        returns:
          type: Dict[str, Any]
          binding: financial_feasibility
        purpose: "Analyze financial feasibility of input allocation"
        async: false
        dependencies: [budget_allocation]

      - step: 3
        module: causal_processor
        class: CausalExtractor
        method: _extract_goals
        args:
          - name: text
            type: str
            source: normalized_text
        returns:
          type: List[Dict]
          binding: input_goals
        purpose: "Extract goals related to input allocation"
        async: true
        dependencies: []

    aggregation:
      strategy: budget_weighted
      weights:
        budget_allocation: 0.40
        financial_feasibility: 0.35
        input_goals: 0.25
      confidence_threshold: 0.70

  # Q4: Capacity Assessment
  Q4_Capacity_Assessment:
    description: "Assess institutional capacity for inputs"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: SemanticAnalyzer
        method: _classify_value_chain_link
        args:
          - name: text_segment
            type: str
            source: derived
            derivation: "extract_capacity_segments(normalized_text)"
        returns:
          type: Dict[str, Any]
          binding: capacity_links
        purpose: "Classify value chain links for capacity assessment"
        async: false

      - step: 2
        module: analyzer_one
        class: PerformanceAnalyzer
        method: analyze_performance
        args:
          - name: performance_data
            type: Dict
            source: derived
            derivation: "extract_performance_indicators(normalized_text)"
        returns:
          type: Dict[str, Any]
          binding: performance_analysis
        purpose: "Analyze performance indicators for capacity assessment"
        async: false

      - step: 3
        module: analyzer_one
        class: TextMiningEngine
        method: diagnose_critical_links
        args:
          - name: value_chain
            type: Dict
            source: capacity_links
        returns:
          type: List[Dict]
          binding: critical_links
        purpose: "Diagnose critical links in capacity chain"
        async: false
        dependencies: [capacity_links]

    aggregation:
      strategy: capacity_weighted
      weights:
        capacity_links: 0.35
        performance_analysis: 0.35
        critical_links: 0.30
      confidence_threshold: 0.65

  # Q5: Restriction Identification
  Q5_Restriction_Identification:
    description: "Identify restrictions on inputs"
    execution_chain:
      - step: 1
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: detect
        args:
          - name: text
            type: str
            source: normalized_text
          - name: plan_name
            type: str
            source: plan_metadata.file_name
          - name: dimension
            type: PolicyDimension
            source: constant
            value: PolicyDimension.INSUMOS
        returns:
          type: Dict[str, Any]
          binding: input_contradictions
        purpose: "Detect contradictions in input restrictions"
        async: true

      - step: 2
        module: dereck_beach
        class: OperationalizationAuditor
        method: audit_evidence_traceability
        args:
          - name: nodes
            type: List[MetaNode]
            source: derived
            derivation: "extract_restriction_nodes(normalized_text)"
          - name: links
            type: List[CausalLink]
            source: derived
            derivation: "extract_restriction_links(normalized_text)"
        returns:
          type: AuditResult
          binding: restriction_audit
        purpose: "Audit evidence traceability for input restrictions"
        async: false
        dependencies: []

      - step: 3
        module: semantic_processor
        class: SemanticProcessor
        method: _detect_pdm_structure
        args:
          - name: text
            type: str
            source: normalized_text
        returns:
          type: Dict[str, Any]
          binding: pdm_structure
        purpose: "Detect PDM structure for restriction analysis"
        async: true
        dependencies: []

    aggregation:
      strategy: restriction_weighted
      weights:
        input_contradictions: 0.35
        restriction_audit: 0.35
        pdm_structure: 0.30
      confidence_threshold: 0.65

  # Overall aggregation for D1
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_Baseline_Identification: 0.20
      Q2_Gap_Analysis: 0.20
      Q3_Budget_Allocation: 0.20
      Q4_Capacity_Assessment: 0.20
      Q5_Restriction_Identification: 0.20
    confidence_threshold: 0.65

# ==============================================================================
# DIMENSION D2: ACTIVIDADES (Mecanismos, Cronogramas, Secuencias)
# ==============================================================================
D2_ACTIVIDADES:
  description: "Evaluación de actividades, mecanismos causales, secuencias temporales"
  question_count: 50

  # Q1: Activity Format
  Q1_Activity_Format:
    description: "Analyze format and structure of activities"
    execution_chain:
      - step: 1
        module: policy_segmenter
        class: DocumentSegmenter
        method: segment
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict[str, Any]]
          binding: activity_segments
        purpose: "Segment document into activity sections"
        async: false

      - step: 2
        module: text_processor
        class: SpanishSentenceSegmenter
        method: segment
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[str]
          binding: activity_sentences
        purpose: "Segment text into sentences for activity analysis"
        async: false
        dependencies: []

      - step: 3
        module: policy_processor
        class: PolicyTextProcessor
        method: segment_into_sentences
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict[str, Any]]
          binding: formatted_activities
        purpose: "Format activities according to policy standards"
        async: false
        dependencies: []

    aggregation:
      strategy: format_weighted
      weights:
        activity_segments: 0.35
        activity_sentences: 0.30
        formatted_activities: 0.35
      confidence_threshold: 0.65

  # Q2: Mechanism Specification
  Q2_Mechanism_Specification:
    description: "Specify mechanisms for activities"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: MechanismPartExtractor
        method: extract_entity_activity
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[EntityActivity]
          binding: entity_activities
        purpose: "Extract entity-activity pairs for mechanism specification"
        async: false

      - step: 2
        module: causal_processor
        class: CausalExtractor
        method: _extract_causal_links
        args:
          - name: nodes
            type: List[MetaNode]
            source: derived
            derivation: "extract_activity_nodes(formatted_activities)"
          - name: doc
            type: spacy.Doc
            source: derived
            derivation: "parse_with_spacy(plan_text)"
        returns:
          type: List[CausalLink]
          binding: activity_links
        purpose: "Extract causal links between activities"
        async: false
        dependencies: [formatted_activities]

      - step: 3
        module: causal_processor
        class: TeoriaCambio
        method: construir_grafo_causal
        args:
          - name: entities
            type: List[Entity]
            source: derived
            derivation: "extract_entities_from(entity_activities)"
          - name: activities
            type: List[Activity]
            source: entity_activities
        returns:
          type: networkx.DiGraph
          binding: causal_graph
        purpose: "Build causal graph for mechanism specification"
        async: false
        dependencies: [entity_activities]

    aggregation:
      strategy: mechanism_weighted
      weights:
        entity_activities: 0.35
        activity_links: 0.30
        causal_graph: 0.35
      confidence_threshold: 0.65

  # Q3: Causal Links
  Q3_Causal_Links:
    description: "Analyze causal links between activities"
    execution_chain:
      - step: 1
        module: causal_processor
        class: CausalExtractor
        method: extract_causal_hierarchy
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Tuple[networkx.DiGraph, List[CausalLink]]
          binding: causal_hierarchy
        purpose: "Extract causal hierarchy for activities"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: construct_causal_dag
        args:
          - name: activities
            type: List[Activity]
            source: entity_activities
          - name: links
            type: List[CausalLink]
            source: activity_links
        returns:
          type: networkx.DiGraph
          binding: causal_dag
        purpose: "Construct causal DAG for activities"
        async: false
        dependencies: [entity_activities, activity_links]

      - step: 3
        module: causal_processor
        class: AdvancedDAGValidator
        method: add_edge
        args:
          - name: source
            type: str
            source: derived
            derivation: "extract_source_from(causal_links)"
          - name: target
            type: str
            source: derived
            derivation: "extract_target_from(causal_links)"
        returns:
          type: bool
          binding: edge_added
        purpose: "Add edges to causal DAG"
        async: false
        dependencies: [causal_links]

    aggregation:
      strategy: causal_weighted
      weights:
        causal_hierarchy: 0.35
        causal_dag: 0.35
        edge_added: 0.30
      confidence_threshold: 0.65

  # Q4: Risk Assessment
  Q4_Risk_Assessment:
    description: "Assess risks in activities"
    execution_chain:
      - step: 1
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: _detect_logical_incompatibilities
        args:
          - name: statements
            type: List[PolicyStatement]
            source: derived
            derivation: "extract_activity_statements(plan_text)"
        returns:
          type: List[ContradictionEvidence]
          binding: logical_incompatibilities
        purpose: "Detect logical incompatibilities in activities"
        async: false

      - step: 2
        module: analyzer_one
        class: TextMiningEngine
        method: _assess_risks
        args:
          - name: activities
            type: List[Activity]
            source: entity_activities
        returns:
          type: Dict[str, Any]
          binding: risk_assessment
        purpose: "Assess risks in activities"
        async: false
        dependencies: [entity_activities]

      - step: 3
        module: analyzer_one
        class: PerformanceAnalyzer
        method: _detect_bottlenecks
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: List[Dict]
          binding: bottlenecks
        purpose: "Detect bottlenecks in activity causal graph"
        async: false
        dependencies: [causal_graph]

    aggregation:
      strategy: risk_weighted
      weights:
        logical_incompatibilities: 0.35
        risk_assessment: 0.35
        bottlenecks: 0.30
      confidence_threshold: 0.65

  # Q5: Sequencing Logic
  Q5_Sequencing_Logic:
    description: "Analyze sequencing logic of activities"
    execution_chain:
      - step: 1
        module: temporal_processor
        class: TemporalLogicVerifier
        method: verify_temporal_consistency
        args:
          - name: activities
            type: List[Activity]
            source: entity_activities
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: Dict[str, Any]
          binding: temporal_consistency
        purpose: "Verify temporal consistency of activities"
        async: false
        dependencies: [entity_activities, causal_graph]

      - step: 2
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: _detect_temporal_conflicts
        args:
          - name: activities
            type: List[Activity]
            source: entity_activities
        returns:
          type: List[TemporalConflict]
          binding: temporal_conflicts
        purpose: "Detect temporal conflicts in activities"
        async: false
        dependencies: [entity_activities]

      - step: 3
        module: causal_processor
        class: CausalExtractor
        method: _assess_temporal_coherence
        args:
          - name: causal_links
            type: List[CausalLink]
            source: activity_links
        returns:
          type: Dict[str, Any]
          binding: temporal_coherence
        purpose: "Assess temporal coherence of causal links"
        async: false
        dependencies: [activity_links]

    aggregation:
      strategy: sequencing_weighted
      weights:
        temporal_consistency: 0.35
        temporal_conflicts: 0.30
        temporal_coherence: 0.35
      confidence_threshold: 0.65

  # Overall aggregation for D2
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_Activity_Format: 0.20
      Q2_Mechanism_Specification: 0.20
      Q3_Causal_Links: 0.20
      Q4_Risk_Assessment: 0.20
      Q5_Sequencing_Logic: 0.20
    confidence_threshold: 0.65

# ==============================================================================
# DIMENSION D3: PRODUCTOS (Entregables, Verificación, Presupuesto)
# ==============================================================================
D3_PRODUCTOS:
  description: "Evaluación de productos entregables, trazabilidad presupuestal"
  question_count: 50

  # Q1: DNP Ficha Completeness
  Q1_DNP_Ficha_Completeness:
    description: "Assess completeness of DNP ficha for products"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: CDAFFramework
        method: _validate_dnp_compliance
        args:
          - name: product_data
            type: Dict
            source: derived
            derivation: "extract_product_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: dnp_compliance
        purpose: "Validate DNP compliance for products"
        async: false

      - step: 2
        module: causal_processor
        class: PolicyDocumentAnalyzer
        method: analyze
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: product_analysis
        purpose: "Analyze product document structure"
        async: true
        dependencies: []

      - step: 3
        module: semantic_processor
        class: SemanticProcessor
        method: _detect_table
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict]
          binding: product_tables
        purpose: "Detect product tables in document"
        async: false
        dependencies: []

    aggregation:
      strategy: dnp_weighted
      weights:
        dnp_compliance: 0.40
        product_analysis: 0.30
        product_tables: 0.30
      confidence_threshold: 0.70

  # Q2: Indicator Specification
  Q2_Indicator_Specification:
    description: "Specify indicators for products"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: BayesianNumericalAnalyzer
        method: evaluate_policy_metric
        args:
          - name: metric_name
            type: str
            source: constant
            value: "product_indicator"
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: indicator_evaluation
        purpose: "Evaluate product indicators using Bayesian analysis"
        async: false

      - step: 2
        module: semantic_processor
        class: SemanticProcessor
        method: _detect_numerical_data
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict]
          binding: numerical_data
        purpose: "Detect numerical data for product indicators"
        async: false
        dependencies: []

      - step: 3
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: evaluate_policy_numerical_consistency
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: numerical_consistency
        purpose: "Evaluate numerical consistency of product indicators"
        async: false
        dependencies: []

    aggregation:
      strategy: indicator_weighted
      weights:
        indicator_evaluation: 0.35
        numerical_data: 0.30
        numerical_consistency: 0.35
      confidence_threshold: 0.65

  # Q3: Budget Alignment
  Q3_Budget_Alignment:
    description: "Assess budget alignment for products"
    execution_chain:
      - step: 1
        module: financial_analyzer
        class: FinancialAuditor
        method: trace_financial_allocation
        args:
          - name: nodes
            type: List[MetaNode]
            source: derived
            derivation: "extract_product_nodes(plan_text)"
          - name: tables
            type: List[pd.DataFrame]
            source: derived
            derivation: "extract_financial_tables(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: product_budget_allocation
        purpose: "Trace financial allocation for products"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: _extract_budget_for_pillar
        args:
          - name: pillar_name
            type: str
            source: constant
            value: "products"
          - name: budget_data
            type: Dict
            source: derived
            derivation: "extract_budget_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: pillar_budget
        purpose: "Extract budget for product pillar"
        async: false
        dependencies: []

      - step: 3
        module: causal_processor
        class: CausalExtractor
        method: _assess_financial_consistency
        args:
          - name: product_data
            type: Dict
            source: derived
            derivation: "extract_product_data(plan_text)"
          - name: budget_data
            type: Dict
            source: pillar_budget
        returns:
          type: Dict[str, Any]
          binding: financial_consistency
        purpose: "Assess financial consistency of products"
        async: false
        dependencies: [pillar_budget]

    aggregation:
      strategy: budget_alignment_weighted
      weights:
        product_budget_allocation: 0.35
        pillar_budget: 0.30
        financial_consistency: 0.35
      confidence_threshold: 0.70

  # Q4: Feasibility Assessment
  Q4_Feasibility_Assessment:
    description: "Assess feasibility of products"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: PerformanceAnalyzer
        method: analyze_performance
        args:
          - name: performance_data
            type: Dict
            source: derived
            derivation: "extract_product_performance_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: product_performance
        purpose: "Analyze product performance indicators"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: assess_financial_sustainability
        args:
          - name: budget_data
            type: Dict
            source: pillar_budget
        returns:
          type: Dict[str, Any]
          binding: financial_sustainability
        purpose: "Assess financial sustainability of products"
        async: false
        dependencies: [pillar_budget]

      - step: 3
        module: dereck_beach
        class: BayesianMechanismInference
        method: _calculate_coherence_factor
        args:
          - name: product_data
            type: Dict
            source: derived
            derivation: "extract_product_data(plan_text)"
          - name: causal_links
            type: List[CausalLink]
            source: derived
            derivation: "extract_product_causal_links(plan_text)"
        returns:
          type: float
          binding: coherence_factor
        purpose: "Calculate coherence factor for products"
        async: false
        dependencies: []

    aggregation:
      strategy: feasibility_weighted
      weights:
        product_performance: 0.35
        financial_sustainability: 0.35
        coherence_factor: 0.30
      confidence_threshold: 0.65

  # Q5: Mechanism Clarity
  Q5_Mechanism_Clarity:
    description: "Assess clarity of product mechanisms"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: MechanismPartExtractor
        method: extract_entity_activity
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[EntityActivity]
          binding: product_entity_activities
        purpose: "Extract entity-activity pairs for product mechanisms"
        async: false

      - step: 2
        module: analyzer_one
        class: SemanticAnalyzer
        method: _process_segment
        args:
          - name: segment
            type: str
            source: derived
            derivation: "extract_product_segments(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: processed_segments
        purpose: "Process product segments for mechanism analysis"
        async: false

      - step: 3
        module: causal_processor
        class: CausalExtractor
        method: _build_type_hierarchy
        args:
          - name: product_data
            type: Dict
            source: derived
            derivation: "extract_product_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: type_hierarchy
        purpose: "Build type hierarchy for product mechanisms"
        async: false
        dependencies: []

    aggregation:
      strategy: mechanism_clarity_weighted
      weights:
        product_entity_activities: 0.35
        processed_segments: 0.30
        type_hierarchy: 0.35
      confidence_threshold: 0.65

  # Overall aggregation for D3
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_DNP_Ficha_Completeness: 0.20
      Q2_Indicator_Specification: 0.20
      Q3_Budget_Alignment: 0.20
      Q4_Feasibility_Assessment: 0.20
      Q5_Mechanism_Clarity: 0.20
    confidence_threshold: 0.70

# ==============================================================================
# DIMENSION D4: RESULTADOS (Outcomes, Causalidad Mediano Plazo)
# ==============================================================================
D4_RESULTADOS:
  description: "Evaluación de resultados esperados, encadenamientos causales"
  question_count: 50

  # Q1: Measurability
  Q1_Measurability:
    description: "Assess measurability of results"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: BayesianNumericalAnalyzer
        method: evaluate_policy_metric
        args:
          - name: metric_name
            type: str
            source: constant
            value: "result_measurability"
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: measurability_evaluation
        purpose: "Evaluate measurability of results using Bayesian analysis"
        async: false

      - step: 2
        module: semantic_processor
        class: SemanticProcessor
        method: _detect_numerical_data
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict]
          binding: result_numerical_data
        purpose: "Detect numerical data for result measurability"
        async: false
        dependencies: []

      - step: 3
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: _extract_numerical_values
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict]
          binding: numerical_values
        purpose: "Extract numerical values for result measurability"
        async: false
        dependencies: []

    aggregation:
      strategy: measurability_weighted
      weights:
        measurability_evaluation: 0.35
        result_numerical_data: 0.30
        numerical_values: 0.35
      confidence_threshold: 0.65

  # Q2: Causal Chain Completeness
  Q2_Causal_Chain_Completeness:
    description: "Assess completeness of causal chains for results"
    execution_chain:
      - step: 1
        module: causal_processor
        class: CausalExtractor
        method: extract_causal_hierarchy
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Tuple[networkx.DiGraph, List[CausalLink]]
          binding: result_causal_hierarchy
        purpose: "Extract causal hierarchy for results"
        async: false

      - step: 2
        module: causal_processor
        class: TeoriaCambio
        method: validacion_completa
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: result_causal_hierarchy.graph
        returns:
          type: Dict[str, Any]
          binding: complete_validation
        purpose: "Validate completeness of causal chains for results"
        async: false
        dependencies: [result_causal_hierarchy]

      - step: 3
        module: causal_processor
        class: AdvancedDAGValidator
        method: calculate_acyclicity_pvalue
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: result_causal_hierarchy.graph
        returns:
          type: float
          binding: acyclicity_pvalue
        purpose: "Calculate acyclicity p-value for result causal graph"
        async: false
        dependencies: [result_causal_hierarchy]

    aggregation:
      strategy: causal_chain_weighted
      weights:
        result_causal_hierarchy: 0.35
        complete_validation: 0.35
        acyclicity_pvalue: 0.30
      confidence_threshold: 0.65

  # Q3: Timeframe Specification
  Q3_Timeframe_Specification:
    description: "Assess timeframe specification for results"
    execution_chain:
      - step: 1
        module: temporal_processor
        class: TemporalLogicVerifier
        method: verify_temporal_consistency
        args:
          - name: results
            type: List[Result]
            source: derived
            derivation: "extract_results(plan_text)"
          - name: causal_graph
            type: networkx.DiGraph
            source: result_causal_hierarchy.graph
        returns:
          type: Dict[str, Any]
          binding: result_temporal_consistency
        purpose: "Verify temporal consistency of results"
        async: false
        dependencies: [result_causal_hierarchy]

      - step: 2
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: _extract_temporal_markers
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[TemporalMarker]
          binding: temporal_markers
        purpose: "Extract temporal markers for results"
        async: false
        dependencies: []

      - step: 3
        module: causal_processor
        class: CausalExtractor
        method: _assess_temporal_coherence
        args:
          - name: causal_links
            type: List[CausalLink]
            source: result_causal_hierarchy.links
        returns:
          type: Dict[str, Any]
          binding: result_temporal_coherence
        purpose: "Assess temporal coherence of result causal links"
        async: false
        dependencies: [result_causal_hierarchy]

    aggregation:
      strategy: timeframe_weighted
      weights:
        result_temporal_consistency: 0.35
        temporal_markers: 0.30
        result_temporal_coherence: 0.35
      confidence_threshold: 0.65

  # Q4: Monitoring Mechanism
  Q4_Monitoring_Mechanism:
    description: "Assess monitoring mechanisms for results"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: OperationalizationAuditor
        method: audit_sequence_logic
        args:
          - name: entity_activities
            type: List[EntityActivity]
            source: derived
            derivation: "extract_result_activities(plan_text)"
        returns:
          type: List[str]
          binding: sequence_audit
        purpose: "Audit sequence logic for result monitoring"
        async: false

      - step: 2
        module: analyzer_one
        class: PerformanceAnalyzer
        method: _generate_recommendations
        args:
          - name: performance_data
            type: Dict
            source: derived
            derivation: "extract_result_performance_data(plan_text)"
        returns:
          type: List[Dict]
          binding: monitoring_recommendations
        purpose: "Generate recommendations for result monitoring"
        async: false
        dependencies: []

      - step: 3
        module: dereck_beach
        class: ReportingEngine
        method: generate_accountability_matrix
        args:
          - name: results
            type: List[Result]
            source: derived
            derivation: "extract_results(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: accountability_matrix
        purpose: "Generate accountability matrix for result monitoring"
        async: false
        dependencies: []

    aggregation:
      strategy: monitoring_weighted
      weights:
        sequence_audit: 0.35
        monitoring_recommendations: 0.30
        accountability_matrix: 0.35
      confidence_threshold: 0.65

  # Q5: Strategic Alignment
  Q5_Strategic_Alignment:
    description: "Assess strategic alignment of results"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: SemanticAnalyzer
        method: _classify_policy_domain
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: policy_domain
        purpose: "Classify policy domain for strategic alignment"
        async: false

      - step: 2
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: semantic_search
        args:
          - name: query
            type: str
            source: dynamic
            template: "strategic alignment {result}"
          - name: filters
            type: PDQIdentifier
            source: context
            fields:
              policy_area: "$policy_area"
              dimension: "D4"
        returns:
          type: List[SemanticChunk]
          binding: alignment_search_results
        purpose: "Search for strategic alignment evidence"
        async: false
        dependencies: []

      - step: 3
        module: policy_processor
        class: IndustrialPolicyProcessor
        method: _analyze_causal_dimensions
        args:
          - name: text
            type: str
            source: plan_text
          - name: dimension
            type: str
            source: constant
            value: "D4"
        returns:
          type: Dict[str, Any]
          binding: causal_dimensions
        purpose: "Analyze causal dimensions for strategic alignment"
        async: false
        dependencies: []

    aggregation:
      strategy: strategic_weighted
      weights:
        policy_domain: 0.30
        alignment_search_results: 0.35
        causal_dimensions: 0.35
      confidence_threshold: 0.65

  # Overall aggregation for D4
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_Measurability: 0.20
      Q2_Causal_Chain_Completeness: 0.20
      Q3_Timeframe_Specification: 0.20
      Q4_Monitoring_Mechanism: 0.20
      Q5_Strategic_Alignment: 0.20
    confidence_threshold: 0.65

# ==============================================================================
# DIMENSION D5: IMPACTOS (Transformación Estructural Largo Plazo)
# ==============================================================================
D5_IMPACTOS:
  description: "Evaluación de impactos de largo plazo, sostenibilidad"
  question_count: 50

  # Q1: Projection Methodology
  Q1_Projection_Methodology:
    description: "Assess projection methodology for impacts"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: BayesianNumericalAnalyzer
        method: _beta_binomial_posterior
        args:
          - name: alpha
            type: float
            source: derived
            derivation: "extract_alpha_from(plan_text)"
          - name: beta
            type: float
            source: derived
            derivation: "extract_beta_from(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: posterior_distribution
        purpose: "Calculate beta-binomial posterior for impact projections"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: generate_counterfactuals
        args:
          - name: impact_data
            type: Dict
            source: derived
            derivation: "extract_impact_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: impact_counterfactuals
        purpose: "Generate counterfactuals for impact projections"
        async: false
        dependencies: []

      - step: 3
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: compare_policy_interventions
        args:
          - name: interventions
            type: List[Dict]
            source: derived
            derivation: "extract_interventions(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: intervention_comparison
        purpose: "Compare policy interventions for impact projections"
        async: false
        dependencies: []

    aggregation:
      strategy: projection_weighted
      weights:
        posterior_distribution: 0.35
        impact_counterfactuals: 0.30
        intervention_comparison: 0.35
      confidence_threshold: 0.65

  # Q2: Proxy Indicators
  Q2_Proxy_Indicators:
    description: "Assess proxy indicators for impacts"
    execution_chain:
      - step: 1
        module: analyzer_one
        class: SemanticAnalyzer
        method: _classify_cross_cutting_themes
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: cross_cutting_themes
        purpose: "Classify cross-cutting themes for proxy indicators"
        async: false

      - step: 2
        module: embedding_policy
        class: PolicyCrossEncoderReranker
        method: rerank
        args:
          - name: documents
            type: List[str]
            source: derived
            derivation: "extract_impact_documents(plan_text)"
          - name: query
            type: str
            source: dynamic
            template: "proxy indicators for {impact}"
        returns:
          type: List[Dict]
          binding: reranked_documents
        purpose: "Rerank documents for proxy indicator analysis"
        async: false
        dependencies: []

      - step: 3
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: _filter_by_pdq
        args:
          - name: documents
            type: List[Dict]
            source: reranked_documents
          - name: pdq_filter
            type: PDQIdentifier
            source: context
            fields:
              policy_area: "$policy_area"
              dimension: "D5"
        returns:
          type: List[Dict]
          binding: filtered_documents
        purpose: "Filter documents by PDQ for proxy indicators"
        async: false
        dependencies: [reranked_documents]

    aggregation:
      strategy: proxy_weighted
      weights:
        cross_cutting_themes: 0.30
        reranked_documents: 0.35
        filtered_documents: 0.35
      confidence_threshold: 0.65

  # Q3: Validity Assessment
  Q3_Validity_Assessment:
    description: "Assess validity of impact projections"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: BayesianMechanismInference
        method: _test_sufficiency
        args:
          - name: evidence
            type: List[Dict]
            source: derived
            derivation: "extract_impact_evidence(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: sufficiency_test
        purpose: "Test sufficiency of impact evidence"
        async: false

      - step: 2
        module: dereck_beach
        class: BayesianMechanismInference
        method: _test_necessity
        args:
          - name: evidence
            type: List[Dict]
            source: derived
            derivation: "extract_impact_evidence(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: necessity_test
        purpose: "Test necessity of impact evidence"
        async: false
        dependencies: []

      - step: 3
        module: causal_processor
        class: AdvancedDAGValidator
        method: _perform_sensitivity_analysis_internal
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: derived
            derivation: "extract_impact_causal_graph(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: sensitivity_analysis
        purpose: "Perform sensitivity analysis for impact validity"
        async: false
        dependencies: []

    aggregation:
      strategy: validity_weighted
      weights:
        sufficiency_test: 0.35
        necessity_test: 0.35
        sensitivity_analysis: 0.30
      confidence_threshold: 0.65

  # Q4: Risk Analysis
  Q4_Risk_Analysis:
    description: "Assess risks for impacts"
    execution_chain:
      - step: 1
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: _detect_resource_conflicts
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: List[Dict]
          binding: resource_conflicts
        purpose: "Detect resource conflicts for impact risks"
        async: false

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: sensitivity_analysis
        args:
          - name: impact_data
            type: Dict
            source: derived
            derivation: "extract_impact_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: impact_sensitivity
        purpose: "Perform sensitivity analysis for impact risks"
        async: false
        dependencies: []

      - step: 3
        module: analyzer_one
        class: TextMiningEngine
        method: _assess_risks
        args:
          - name: impact_data
            type: Dict
            source: derived
            derivation: "extract_impact_data(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: impact_risks
        purpose: "Assess risks for impacts"
        async: false
        dependencies: []

    aggregation:
      strategy: risk_weighted
      weights:
        resource_conflicts: 0.35
        impact_sensitivity: 0.30
        impact_risks: 0.35
      confidence_threshold: 0.65

  # Q5: Unwanted Effects
  Q5_Unwanted_Effects:
    description: "Assess unwanted effects of impacts"
    execution_chain:
      - step: 1
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: detect
        args:
          - name: text
            type: str
            source: plan_text
          - name: plan_name
            type: str
            source: plan_metadata.file_name
          - name: dimension
            type: PolicyDimension
            source: constant
            value: PolicyDimension.IMPACTOS
        returns:
          type: Dict[str, Any]
          binding: impact_contradictions
        purpose: "Detect contradictions for unwanted effects"
        async: true

      - step: 2
        module: financial_analyzer
        class: PDETMunicipalPlanAnalyzer
        method: _simulate_intervention
        args:
          - name: intervention
            type: Dict
            source: derived
            derivation: "extract_impact_intervention(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: intervention_simulation
        purpose: "Simulate intervention for unwanted effects"
        async: false
        dependencies: []

      - step: 3
        module: causal_processor
        class: TeoriaCambio
        method: _validar_orden_causal
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: derived
            derivation: "extract_impact_causal_graph(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: causal_order_validation
        purpose: "Validate causal order for unwanted effects"
        async: false
        dependencies: []

    aggregation:
      strategy: unwanted_effects_weighted
      weights:
        impact_contradictions: 0.35
        intervention_simulation: 0.30
        causal_order_validation: 0.35
      confidence_threshold: 0.65

  # Overall aggregation for D5
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_Projection_Methodology: 0.20
      Q2_Proxy_Indicators: 0.20
      Q3_Validity_Assessment: 0.20
      Q4_Risk_Analysis: 0.20
      Q5_Unwanted_Effects: 0.20
    confidence_threshold: 0.60

# ==============================================================================
# DIMENSION D6: CAUSALIDAD (Coherencia Causal Global, Auditoría Completa)
# ==============================================================================
D6_CAUSALIDAD:
  description: "Evaluación de coherencia causal global, validación integral"
  question_count: 50
  execution_type: cyclic  # ÚNICO con ciclos iterativos
  max_iterations: 3
  convergence_criterion: "audit_passed OR iterations >= 3"

  # Q1: Theory of Change
  Q1_Theory_of_Change:
    description: "Assess theory of change"
    execution_chain:
      - step: 1
        module: causal_processor
        class: TeoriaCambio
        method: construir_grafo_causal
        args:
          - name: entities
            type: List[Entity]
            source: derived
            derivation: "extract_entities(plan_text)"
          - name: activities
            type: List[Activity]
            source: derived
            derivation: "extract_activities(plan_text)"
        returns:
          type: networkx.DiGraph
          binding: causal_graph
        purpose: "Build causal graph for theory of change"
        async: false

      - step: 2
        module: causal_processor
        class: CausalExtractor
        method: extract_causal_hierarchy
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Tuple[networkx.DiGraph, List[CausalLink]]
          binding: causal_hierarchy
        purpose: "Extract causal hierarchy for theory of change"
        async: false
        dependencies: []

      - step: 3
        module: policy_processor
        class: IndustrialPolicyProcessor
        method: _analyze_causal_dimensions
        args:
          - name: text
            type: str
            source: plan_text
          - name: dimension
            type: str
            source: constant
            value: "D6"
        returns:
          type: Dict[str, Any]
          binding: causal_dimensions
        purpose: "Analyze causal dimensions for theory of change"
        async: false
        dependencies: []

    aggregation:
      strategy: theory_weighted
      weights:
        causal_graph: 0.35
        causal_hierarchy: 0.35
        causal_dimensions: 0.30
      confidence_threshold: 0.65

  # Q2: Causal Logic
  Q2_Causal_Logic:
    description: "Assess causal logic"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: BeachEvidentialTest
        method: apply_test_logic
        args:
          - name: test_type
            type: TestType
            source: derived
            derivation: "classify_test(causal_links)"
          - name: evidence_found
            type: bool
            source: derived
            derivation: "check_evidence_exists(causal_links)"
          - name: prior
            type: float
            source: constant
            value: 0.5
          - name: bayes_factor
            type: float
            source: derived
            derivation: "compute_bayes_factor(causal_links)"
        returns:
          type: Tuple[float, str]
          binding: beach_posterior
        purpose: "Apply Beach evidential test for causal logic"
        async: false

      - step: 2
        module: dereck_beach
        class: BayesianMechanismInference
        method: infer_mechanisms
        args:
          - name: nodes
            type: List[MetaNode]
            source: causal_hierarchy.graph.nodes
          - name: links
            type: List[CausalLink]
            source: causal_hierarchy.links
          - name: entity_activities
            type: List[EntityActivity]
            source: derived
            derivation: "extract_all_activities(plan_text)"
        returns:
          type: List[Dict[str, Any]]
          binding: mechanisms
        purpose: "Infer mechanisms for causal logic"
        async: false
        dependencies: [causal_hierarchy]

      - step: 3
        module: causal_processor
        class: CausalInferenceSetup
        method: assign_probative_value
        args:
          - name: evidence
            type: List[Dict]
            source: derived
            derivation: "extract_evidence(plan_text)"
        returns:
          type: Dict[str, Any]
          binding: probative_value
        purpose: "Assign probative value for causal logic"
        async: false
        dependencies: []

    aggregation:
      strategy: causal_logic_weighted
      weights:
        beach_posterior: 0.35
        mechanisms: 0.35
        probative_value: 0.30
      confidence_threshold: 0.65

  # Q3: Inconsistency Detection
  Q3_Inconsistency_Detection:
    description: "Detect inconsistencies in causal logic"
    execution_chain:
      - step: 1
        module: contradiction_detector
        class: PolicyContradictionDetector
        method: detect
        args:
          - name: text
            type: str
            source: plan_text
          - name: plan_name
            type: str
            source: plan_metadata.file_name
          - name: dimension
            type: PolicyDimension
            source: constant
            value: PolicyDimension.CAUSALIDAD
        returns:
          type: Dict[str, Any]
          binding: causal_contradictions
        purpose: "Detect contradictions in causal logic"
        async: true

      - step: 2
        module: causal_processor
        class: AdvancedDAGValidator
        method: _is_acyclic
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: bool
          binding: is_acyclic
        purpose: "Check if causal graph is acyclic"
        async: false
        dependencies: [causal_graph]

      - step: 3
        module: dereck_beach
        class: OperationalizationAuditor
        method: bayesian_counterfactual_audit
        args:
          - name: links
            type: List[CausalLink]
            source: causal_hierarchy.links
          - name: threshold
            type: float
            source: constant
            value: 0.5
        returns:
          type: Dict[str, Any]
          binding: counterfactual_audit
        purpose: "Perform counterfactual audit for inconsistency detection"
        async: false
        dependencies: [causal_hierarchy]

    aggregation:
      strategy: inconsistency_weighted
      weights:
        causal_contradictions: 0.35
        is_acyclic: 0.30
        counterfactual_audit: 0.35
      confidence_threshold: 0.65

  # Q4: Adaptive Monitoring
  Q4_Adaptive_Monitoring:
    description: "Assess adaptive monitoring for causal logic"
    execution_chain:
      - step: 1
        module: dereck_beach
        class: ReportingEngine
        method: generate_causal_diagram
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: Dict[str, Any]
          binding: causal_diagram
        purpose: "Generate causal diagram for adaptive monitoring"
        async: false
        dependencies: [causal_graph]

      - step: 2
        module: causal_processor
        class: CausalExtractor
        method: _check_structural_violation
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: List[Dict]
          binding: structural_violations
        purpose: "Check structural violations for adaptive monitoring"
        async: false
        dependencies: [causal_graph]

      - step: 3
        module: analyzer_one
        class: PerformanceAnalyzer
        method: _calculate_throughput_metrics
        args:
          - name: causal_graph
            type: networkx.DiGraph
            source: causal_graph
        returns:
          type: Dict[str, Any]
          binding: throughput_metrics
        purpose: "Calculate throughput metrics for adaptive monitoring"
        async: false
        dependencies: [causal_graph]

    aggregation:
      strategy: adaptive_weighted
      weights:
        causal_diagram: 0.35
        structural_violations: 0.30
        throughput_metrics: 0.35
      confidence_threshold: 0.65

  # Q5: Differential Approach
  Q5_Differential_Approach:
    description: "Assess differential approach for causal logic"
    execution_chain:
      - step: 1
        module: embedding_policy
        class: PolicyAnalysisEmbedder
        method: generate_pdq_report
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: pdq_report
        purpose: "Generate PDQ report for differential approach"
        async: false

      - step: 2
        module: analyzer_one
        class: SemanticAnalyzer
        method: _calculate_semantic_complexity
        args:
          - name: text
            type: str
            source: plan_text
        returns:
          type: Dict[str, Any]
          binding: semantic_complexity
        purpose: "Calculate semantic complexity for differential approach"
        async: false
        dependencies: []

      - step: 3
        module: causal_processor
        class: BayesianEvidenceIntegrator
        method: causal_strength
        args:
          - name: cause_emb
            type: NDArray[np.float32]
            source: derived
            derivation: "get_embedding(cause_node.text)"
          - name: effect_emb
            type: NDArray[np.float32]
            source: derived
            derivation: "get_embedding(effect_node.text)"
          - name: context_emb
            type: NDArray[np.float32]
            source: derived
            derivation: "get_context_embedding(plan_text)"
        returns:
          type: float
          binding: causal_strength_score
        purpose: "Calculate causal strength for differential approach"
        async: false
        dependencies: []

    aggregation:
      strategy: differential_weighted
      weights:
        pdq_report: 0.35
        semantic_complexity: 0.30
        causal_strength_score: 0.35
      confidence_threshold: 0.65

  # Overall aggregation for D6
  overall_aggregation:
    strategy: dimension_weighted
    weights:
      Q1_Theory_of_Change: 0.20
      Q2_Causal_Logic: 0.20
      Q3_Inconsistency_Detection: 0.20
      Q4_Adaptive_Monitoring: 0.20
      Q5_Differential_Approach: 0.20
    confidence_threshold: 0.70

# ==============================================================================
# GLOBAL CONFIGURATION
# ==============================================================================
global_config:
  async_executor: asyncio
  max_parallel_modules: 4
  timeout_per_module: 120  # seconds
  retry_strategy:
    max_retries: 2
    backoff_factor: 2
    retry_on_errors: [TimeoutError, ConnectionError]

  circuit_breaker:
    failure_threshold: 5
    recovery_timeout: 60
    half_open_requests: 3

  caching:
    enabled: true
    ttl: 3600  # 1 hour
    cache_keys:
      - plan_text_hash
      - module_version
      - execution_chain_version

  logging:
    level: INFO
    format: "%(asctime)s [%(levelname)s] %(module)s.%(method)s: %(message)s"
    log_module_traces: true
    log_execution_times: true

  error_handling:
    degraded_mode: true  # Continue with partial results if module fails
    minimum_modules_required:
      D1: 4  # Need at least 4/7 modules
      D2: 5  # Need at least 5/8 modules (critical for mechanisms)
      D3: 4
      D4: 4
      D5: 4
      D6: 7  # Need almost all modules for global validation