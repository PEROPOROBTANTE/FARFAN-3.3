{
  "causal_proccesor": {
    "module_name": "causal_proccesor",
    "docstring": "Causal Policy Analysis Framework - State-of-the-Art Edition\nSpecialized for Colombian Municipal Development Plans (PDM)\n\nScientific Foundation:\n- Semantic: BGE-M3 (2024, SOTA multilingual dense retrieval)\n- Chunking: Semantic-aware with policy structure recognition\n- Math: Information-theoretic Bayesian evidence accumulation\n- Causal: Directed Acyclic Graph inference with interventional calculus\n\nDesign Principles:\n- Zero placeholders, zero heuristics\n- Calibrated to Colombian PDM structure (Ley 152/1994, DNP guidelines)\n- Production-grade error handling\n- Lazy loading for resource efficiency",
    "classes": [
      {
        "name": "CausalDimension",
        "docstring": "Marco Lógico standard (DNP Colombia)",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 43,
        "methods": []
      },
      {
        "name": "PDMSection",
        "docstring": "Estructura típica PDM colombiano (Ley 152/1994)",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 53,
        "methods": []
      },
      {
        "name": "SemanticConfig",
        "docstring": "Configuración calibrada para análisis de políticas públicas",
        "base_classes": [],
        "is_public": true,
        "lineno": 64,
        "methods": []
      },
      {
        "name": "SemanticProcessor",
        "docstring": "State-of-the-art semantic processing with:\n- BGE-M3 embeddings (2024 SOTA)\n- Policy-aware chunking (respects PDM structure)\n- Efficient batching with FP16",
        "base_classes": [],
        "is_public": true,
        "lineno": 82,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SemanticConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SemanticConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 90,
            "invocation_pattern": "semanticprocessor_instance.__init__()"
          },
          {
            "name": "_lazy_load",
            "decorator": null,
            "signature": "_lazy_load(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 96,
            "invocation_pattern": "semanticprocessor_instance._lazy_load()"
          },
          {
            "name": "chunk_text",
            "decorator": null,
            "signature": "chunk_text(self, text: str, preserve_structure: bool = True) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "preserve_structure",
                "annotation": "bool",
                "default": "True"
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Policy-aware semantic chunking:\n- Respects section boundaries (numbered lists, headers)\n- Maintains table integrity\n- Preserves reference links between text segments",
            "is_public": true,
            "lineno": 121,
            "invocation_pattern": "semanticprocessor_instance.chunk_text()"
          },
          {
            "name": "_detect_pdm_structure",
            "decorator": null,
            "signature": "_detect_pdm_structure(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Detect PDM sections using Colombian policy document patterns",
            "is_public": false,
            "lineno": 165,
            "invocation_pattern": "semanticprocessor_instance._detect_pdm_structure()"
          },
          {
            "name": "_detect_table",
            "decorator": null,
            "signature": "_detect_table(self, text: str) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detect if chunk contains tabular data",
            "is_public": false,
            "lineno": 199,
            "invocation_pattern": "semanticprocessor_instance._detect_table()"
          },
          {
            "name": "_detect_numerical_data",
            "decorator": null,
            "signature": "_detect_numerical_data(self, text: str) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detect if chunk contains significant numerical/financial data",
            "is_public": false,
            "lineno": 206,
            "invocation_pattern": "semanticprocessor_instance._detect_numerical_data()"
          },
          {
            "name": "_embed_batch",
            "decorator": null,
            "signature": "_embed_batch(self, texts: list[str]) -> list[NDArray[np.float32]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "texts",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "list[NDArray[np.float32]]",
            "docstring": "Batch embedding with BGE-M3",
            "is_public": false,
            "lineno": 217,
            "invocation_pattern": "semanticprocessor_instance._embed_batch()"
          },
          {
            "name": "embed_single",
            "decorator": null,
            "signature": "embed_single(self, text: str) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Single text embedding",
            "is_public": true,
            "lineno": 251,
            "invocation_pattern": "semanticprocessor_instance.embed_single()"
          }
        ]
      },
      {
        "name": "BayesianEvidenceIntegrator",
        "docstring": "Information-theoretic Bayesian evidence accumulation:\n- Dirichlet-Multinomial for multi-hypothesis tracking\n- KL divergence for belief update quantification\n- Entropy-based confidence calibration\n- No simplifications or heuristics",
        "base_classes": [],
        "is_public": true,
        "lineno": 260,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, prior_concentration: float = 0.5)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "prior_concentration",
                "annotation": "float",
                "default": "0.5"
              }
            ],
            "return_type": null,
            "docstring": "Args:\n    prior_concentration: Dirichlet concentration (α).\n                        Lower = more uncertain prior (conservative)",
            "is_public": false,
            "lineno": 269,
            "invocation_pattern": "bayesianevidenceintegrator_instance.__init__()"
          },
          {
            "name": "integrate_evidence",
            "decorator": null,
            "signature": "integrate_evidence(self, similarities: NDArray[np.float64], chunk_metadata: list[dict[str, Any]]) -> dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "similarities",
                "annotation": "NDArray[np.float64]",
                "default": null
              },
              {
                "name": "chunk_metadata",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "dict[str, float]",
            "docstring": "Bayesian evidence integration with information-theoretic rigor:\n\n1. Map similarities to likelihood space via monotonic transform\n2. Weight evidence by chunk reliability (position, structure, content type)\n3. Update Dirichlet posterior\n4. Compute information gain (KL divergence from prior)\n5. Calculate calibrated confidence with epistemic uncertainty",
            "is_public": true,
            "lineno": 279,
            "invocation_pattern": "bayesianevidenceintegrator_instance.integrate_evidence()"
          },
          {
            "name": "_similarity_to_probability",
            "decorator": null,
            "signature": "_similarity_to_probability(self, sims: NDArray[np.float64]) -> NDArray[np.float64]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sims",
                "annotation": "NDArray[np.float64]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float64]",
            "docstring": "Calibrated transform from cosine similarity [-1,1] to probability [0,1]\nUsing sigmoid with empirically derived temperature",
            "is_public": false,
            "lineno": 341,
            "invocation_pattern": "bayesianevidenceintegrator_instance._similarity_to_probability()"
          },
          {
            "name": "_compute_reliability_weights",
            "decorator": null,
            "signature": "_compute_reliability_weights(self, metadata: list[dict[str, Any]]) -> NDArray[np.float64]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "metadata",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float64]",
            "docstring": "Evidence reliability based on:\n- Position in document (early sections more diagnostic)\n- Content type (tables/numbers more reliable for quantitative claims)\n- Section type (plan sections more reliable than diagnostics)",
            "is_public": false,
            "lineno": 351,
            "invocation_pattern": "bayesianevidenceintegrator_instance._compute_reliability_weights()"
          },
          {
            "name": "_null_evidence",
            "decorator": null,
            "signature": "_null_evidence(self) -> dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[str, float]",
            "docstring": "Return prior state (no evidence)",
            "is_public": false,
            "lineno": 384,
            "invocation_pattern": "bayesianevidenceintegrator_instance._null_evidence()"
          },
          {
            "name": "causal_strength",
            "decorator": null,
            "signature": "causal_strength(self, cause_emb: NDArray[np.float32], effect_emb: NDArray[np.float32], context_emb: NDArray[np.float32]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "cause_emb",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "effect_emb",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "context_emb",
                "annotation": "NDArray[np.float32]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Causal strength via conditional independence approximation:\nstrength = sim(cause, effect) * [1 - |sim(cause,ctx) - sim(effect,ctx)|]\n\nIntuition: Strong causal link if cause-effect similar AND\n           both relate similarly to context (conditional independence test proxy)",
            "is_public": true,
            "lineno": 397,
            "invocation_pattern": "bayesianevidenceintegrator_instance.causal_strength()"
          }
        ]
      },
      {
        "name": "PolicyDocumentAnalyzer",
        "docstring": "Colombian Municipal Development Plan Analyzer:\n- BGE-M3 semantic processing\n- Policy-aware chunking (respects PDM structure)\n- Bayesian evidence integration with information theory\n- Causal dimension analysis per Marco Lógico",
        "base_classes": [],
        "is_public": true,
        "lineno": 426,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SemanticConfig | None = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SemanticConfig | None",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 435,
            "invocation_pattern": "policydocumentanalyzer_instance.__init__()"
          },
          {
            "name": "_init_dimension_embeddings",
            "decorator": null,
            "signature": "_init_dimension_embeddings(self) -> dict[CausalDimension, NDArray[np.float32]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[CausalDimension, NDArray[np.float32]]",
            "docstring": "Canonical embeddings for Marco Lógico dimensions\nUsing Colombian policy-specific terminology",
            "is_public": false,
            "lineno": 445,
            "invocation_pattern": "policydocumentanalyzer_instance._init_dimension_embeddings()"
          },
          {
            "name": "analyze",
            "decorator": null,
            "signature": "analyze(self, text: str) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Full pipeline: chunking → embedding → dimension analysis → evidence integration",
            "is_public": true,
            "lineno": 482,
            "invocation_pattern": "policydocumentanalyzer_instance.analyze()"
          },
          {
            "name": "_extract_key_excerpts",
            "decorator": null,
            "signature": "_extract_key_excerpts(self, chunks: list[dict[str, Any]], dimension_results: dict[str, dict[str, Any]]) -> dict[str, list[str]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunks",
                "annotation": "list[dict[str, Any]]",
                "default": null
              },
              {
                "name": "dimension_results",
                "annotation": "dict[str, dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "dict[str, list[str]]",
            "docstring": "Extract most relevant text excerpts per dimension",
            "is_public": false,
            "lineno": 533,
            "invocation_pattern": "policydocumentanalyzer_instance._extract_key_excerpts()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "main",
        "signature": "main()",
        "parameters": [],
        "return_type": null,
        "docstring": "Example usage",
        "is_public": true,
        "lineno": 563
      }
    ]
  },
  "contradiction_deteccion": {
    "module_name": "contradiction_deteccion",
    "docstring": "Advanced Policy Contradiction Detection System for Colombian Municipal Development Plans\n\nEste sistema implementa el estado del arte en detección de contradicciones para análisis\nde políticas públicas, específicamente calibrado para Planes de Desarrollo Municipal (PDM)\ncolombianos según la Ley 152 de 1994 y metodología DNP.\n\nInnovations:\n- Transformer-based semantic similarity using sentence-transformers\n- Graph-based contradiction reasoning with NetworkX\n- Bayesian inference for confidence scoring\n- Temporal logic verification for timeline consistency\n- Multi-dimensional vector embeddings for policy alignment\n- Statistical hypothesis testing for numerical claims",
    "classes": [
      {
        "name": "ContradictionType",
        "docstring": "Taxonomía de contradicciones según estándares de política pública",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 49,
        "methods": []
      },
      {
        "name": "PolicyDimension",
        "docstring": "Dimensiones del Plan de Desarrollo según DNP Colombia",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 61,
        "methods": []
      },
      {
        "name": "PolicyStatement",
        "docstring": "Representación estructurada de una declaración de política",
        "base_classes": [],
        "is_public": true,
        "lineno": 72,
        "methods": []
      },
      {
        "name": "ContradictionEvidence",
        "docstring": "Evidencia estructurada de contradicción con trazabilidad completa",
        "base_classes": [],
        "is_public": true,
        "lineno": 87,
        "methods": []
      },
      {
        "name": "BayesianConfidenceCalculator",
        "docstring": "Cálculo Bayesiano de confianza con priors informados por dominio",
        "base_classes": [],
        "is_public": true,
        "lineno": 104,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 107,
            "invocation_pattern": "bayesianconfidencecalculator_instance.__init__()"
          },
          {
            "name": "calculate_posterior",
            "decorator": null,
            "signature": "calculate_posterior(self, evidence_strength: float, observations: int, domain_weight: float = 1.0) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "evidence_strength",
                "annotation": "float",
                "default": null
              },
              {
                "name": "observations",
                "annotation": "int",
                "default": null
              },
              {
                "name": "domain_weight",
                "annotation": "float",
                "default": "1.0"
              }
            ],
            "return_type": "float",
            "docstring": "Calcula probabilidad posterior usando inferencia Bayesiana\n\nArgs:\n    evidence_strength: Fuerza de la evidencia [0, 1]\n    observations: Número de observaciones que soportan la evidencia\n    domain_weight: Peso específico del dominio de política",
            "is_public": true,
            "lineno": 112,
            "invocation_pattern": "bayesianconfidencecalculator_instance.calculate_posterior()"
          }
        ]
      },
      {
        "name": "TemporalLogicVerifier",
        "docstring": "Verificación de consistencia temporal usando lógica temporal lineal (LTL)",
        "base_classes": [],
        "is_public": true,
        "lineno": 142,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 145,
            "invocation_pattern": "temporallogicverifier_instance.__init__()"
          },
          {
            "name": "verify_temporal_consistency",
            "decorator": null,
            "signature": "verify_temporal_consistency(self, statements: List[PolicyStatement]) -> Tuple[bool, List[Dict[str, Any]]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "Tuple[bool, List[Dict[str, Any]]]",
            "docstring": "Verifica consistencia temporal entre declaraciones\n\nReturns:\n    (is_consistent, conflicts_found)",
            "is_public": true,
            "lineno": 153,
            "invocation_pattern": "temporallogicverifier_instance.verify_temporal_consistency()"
          },
          {
            "name": "_build_timeline",
            "decorator": null,
            "signature": "_build_timeline(self, statements: List[PolicyStatement]) -> List[Dict]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[Dict]",
            "docstring": "Construye línea temporal a partir de declaraciones",
            "is_public": false,
            "lineno": 182,
            "invocation_pattern": "temporallogicverifier_instance._build_timeline()"
          },
          {
            "name": "_parse_temporal_marker",
            "decorator": null,
            "signature": "_parse_temporal_marker(self, marker: str) -> Optional[int]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "marker",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Optional[int]",
            "docstring": "Parsea marcador temporal a timestamp numérico",
            "is_public": false,
            "lineno": 196,
            "invocation_pattern": "temporallogicverifier_instance._parse_temporal_marker()"
          },
          {
            "name": "_has_temporal_conflict",
            "decorator": null,
            "signature": "_has_temporal_conflict(self, event_a: Dict, event_b: Dict) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "event_a",
                "annotation": "Dict",
                "default": null
              },
              {
                "name": "event_b",
                "annotation": "Dict",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detecta conflictos temporales entre eventos",
            "is_public": false,
            "lineno": 213,
            "invocation_pattern": "temporallogicverifier_instance._has_temporal_conflict()"
          },
          {
            "name": "_are_mutually_exclusive",
            "decorator": null,
            "signature": "_are_mutually_exclusive(self, stmt_a: PolicyStatement, stmt_b: PolicyStatement) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "stmt_a",
                "annotation": "PolicyStatement",
                "default": null
              },
              {
                "name": "stmt_b",
                "annotation": "PolicyStatement",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Determina si dos declaraciones son mutuamente excluyentes",
            "is_public": false,
            "lineno": 224,
            "invocation_pattern": "temporallogicverifier_instance._are_mutually_exclusive()"
          },
          {
            "name": "_extract_resources",
            "decorator": null,
            "signature": "_extract_resources(self, text: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Extrae recursos mencionados en el texto",
            "is_public": false,
            "lineno": 236,
            "invocation_pattern": "temporallogicverifier_instance._extract_resources()"
          },
          {
            "name": "_check_deadline_constraints",
            "decorator": null,
            "signature": "_check_deadline_constraints(self, timeline: List[Dict]) -> List[Dict]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "timeline",
                "annotation": "List[Dict]",
                "default": null
              }
            ],
            "return_type": "List[Dict]",
            "docstring": "Verifica violaciones de restricciones de plazo",
            "is_public": false,
            "lineno": 251,
            "invocation_pattern": "temporallogicverifier_instance._check_deadline_constraints()"
          },
          {
            "name": "_should_precede",
            "decorator": null,
            "signature": "_should_precede(self, stmt_a: PolicyStatement, stmt_b: PolicyStatement) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "stmt_a",
                "annotation": "PolicyStatement",
                "default": null
              },
              {
                "name": "stmt_b",
                "annotation": "PolicyStatement",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Determina si stmt_a debe preceder a stmt_b",
            "is_public": false,
            "lineno": 268,
            "invocation_pattern": "temporallogicverifier_instance._should_precede()"
          },
          {
            "name": "_classify_temporal_type",
            "decorator": null,
            "signature": "_classify_temporal_type(self, marker: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "marker",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Clasifica el tipo de marcador temporal",
            "is_public": false,
            "lineno": 273,
            "invocation_pattern": "temporallogicverifier_instance._classify_temporal_type()"
          }
        ]
      },
      {
        "name": "PolicyContradictionDetector",
        "docstring": "Sistema avanzado de detección de contradicciones para PDMs colombianos.\nImplementa el estado del arte en NLP y razonamiento lógico.",
        "base_classes": [],
        "is_public": true,
        "lineno": 281,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, model_name: str = 'hiiamsid/sentence_similarity_spanish_es', spacy_model: str = 'es_core_news_lg', device: str = 'cuda' if torch.cuda.is_available() else 'cpu')",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "model_name",
                "annotation": "str",
                "default": "'hiiamsid/sentence_similarity_spanish_es'"
              },
              {
                "name": "spacy_model",
                "annotation": "str",
                "default": "'es_core_news_lg'"
              },
              {
                "name": "device",
                "annotation": "str",
                "default": "'cuda' if torch.cuda.is_available() else 'cpu'"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 287,
            "invocation_pattern": "policycontradictiondetector_instance.__init__()"
          },
          {
            "name": "_initialize_pdm_patterns",
            "decorator": null,
            "signature": "_initialize_pdm_patterns(self)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": "Inicializa patrones específicos de PDMs colombianos",
            "is_public": false,
            "lineno": 323,
            "invocation_pattern": "policycontradictiondetector_instance._initialize_pdm_patterns()"
          },
          {
            "name": "detect",
            "decorator": null,
            "signature": "detect(self, text: str, plan_name: str = 'PDM', dimension: PolicyDimension = PolicyDimension.ESTRATEGICO) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "plan_name",
                "annotation": "str",
                "default": "'PDM'"
              },
              {
                "name": "dimension",
                "annotation": "PolicyDimension",
                "default": "PolicyDimension.ESTRATEGICO"
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Detecta contradicciones con análisis multi-dimensional avanzado\n\nArgs:\n    text: Texto del plan de desarrollo\n    plan_name: Nombre del PDM\n    dimension: Dimensión del plan siendo analizada\n\nReturns:\n    Análisis completo con contradicciones detectadas y métricas",
            "is_public": true,
            "lineno": 348,
            "invocation_pattern": "policycontradictiondetector_instance.detect()"
          },
          {
            "name": "_extract_policy_statements",
            "decorator": null,
            "signature": "_extract_policy_statements(self, text: str, dimension: PolicyDimension) -> List[PolicyStatement]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "dimension",
                "annotation": "PolicyDimension",
                "default": null
              }
            ],
            "return_type": "List[PolicyStatement]",
            "docstring": "Extrae declaraciones de política estructuradas del texto",
            "is_public": false,
            "lineno": 418,
            "invocation_pattern": "policycontradictiondetector_instance._extract_policy_statements()"
          },
          {
            "name": "_generate_embeddings",
            "decorator": null,
            "signature": "_generate_embeddings(self, statements: List[PolicyStatement]) -> List[PolicyStatement]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[PolicyStatement]",
            "docstring": "Genera embeddings semánticos para las declaraciones",
            "is_public": false,
            "lineno": 459,
            "invocation_pattern": "policycontradictiondetector_instance._generate_embeddings()"
          },
          {
            "name": "_build_knowledge_graph",
            "decorator": null,
            "signature": "_build_knowledge_graph(self, statements: List[PolicyStatement])",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": "Construye grafo de conocimiento para razonamiento",
            "is_public": false,
            "lineno": 486,
            "invocation_pattern": "policycontradictiondetector_instance._build_knowledge_graph()"
          },
          {
            "name": "_detect_semantic_contradictions",
            "decorator": null,
            "signature": "_detect_semantic_contradictions(self, statements: List[PolicyStatement]) -> List[ContradictionEvidence]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[ContradictionEvidence]",
            "docstring": "Detecta contradicciones semánticas usando transformers",
            "is_public": false,
            "lineno": 512,
            "invocation_pattern": "policycontradictiondetector_instance._detect_semantic_contradictions()"
          },
          {
            "name": "_detect_numerical_inconsistencies",
            "decorator": null,
            "signature": "_detect_numerical_inconsistencies(self, statements: List[PolicyStatement]) -> List[ContradictionEvidence]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[ContradictionEvidence]",
            "docstring": "Detecta inconsistencias numéricas con análisis estadístico",
            "is_public": false,
            "lineno": 556,
            "invocation_pattern": "policycontradictiondetector_instance._detect_numerical_inconsistencies()"
          },
          {
            "name": "_detect_temporal_conflicts",
            "decorator": null,
            "signature": "_detect_temporal_conflicts(self, statements: List[PolicyStatement]) -> List[ContradictionEvidence]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[ContradictionEvidence]",
            "docstring": "Detecta conflictos temporales usando verificación lógica",
            "is_public": false,
            "lineno": 608,
            "invocation_pattern": "policycontradictiondetector_instance._detect_temporal_conflicts()"
          },
          {
            "name": "_detect_logical_incompatibilities",
            "decorator": null,
            "signature": "_detect_logical_incompatibilities(self, statements: List[PolicyStatement]) -> List[ContradictionEvidence]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[ContradictionEvidence]",
            "docstring": "Detecta incompatibilidades lógicas usando razonamiento en grafo",
            "is_public": false,
            "lineno": 652,
            "invocation_pattern": "policycontradictiondetector_instance._detect_logical_incompatibilities()"
          },
          {
            "name": "_detect_resource_conflicts",
            "decorator": null,
            "signature": "_detect_resource_conflicts(self, statements: List[PolicyStatement]) -> List[ContradictionEvidence]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "List[ContradictionEvidence]",
            "docstring": "Detecta conflictos en asignación de recursos",
            "is_public": false,
            "lineno": 705,
            "invocation_pattern": "policycontradictiondetector_instance._detect_resource_conflicts()"
          },
          {
            "name": "_calculate_coherence_metrics",
            "decorator": null,
            "signature": "_calculate_coherence_metrics(self, contradictions: List[ContradictionEvidence], statements: List[PolicyStatement], text: str) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "contradictions",
                "annotation": "List[ContradictionEvidence]",
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Calcula métricas avanzadas de coherencia del documento",
            "is_public": false,
            "lineno": 760,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_coherence_metrics()"
          },
          {
            "name": "_calculate_global_semantic_coherence",
            "decorator": null,
            "signature": "_calculate_global_semantic_coherence(self, statements: List[PolicyStatement]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula coherencia semántica global usando embeddings",
            "is_public": false,
            "lineno": 817,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_global_semantic_coherence()"
          },
          {
            "name": "_calculate_objective_alignment",
            "decorator": null,
            "signature": "_calculate_objective_alignment(self, statements: List[PolicyStatement]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "statements",
                "annotation": "List[PolicyStatement]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula alineación entre objetivos declarados",
            "is_public": false,
            "lineno": 845,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_objective_alignment()"
          },
          {
            "name": "_calculate_graph_fragmentation",
            "decorator": null,
            "signature": "_calculate_graph_fragmentation(self) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula fragmentación del grafo de conocimiento",
            "is_public": false,
            "lineno": 871,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_graph_fragmentation()"
          },
          {
            "name": "_calculate_contradiction_entropy",
            "decorator": null,
            "signature": "_calculate_contradiction_entropy(self, contradictions: List[ContradictionEvidence]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "contradictions",
                "annotation": "List[ContradictionEvidence]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula entropía de distribución de tipos de contradicción",
            "is_public": false,
            "lineno": 885,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_contradiction_entropy()"
          },
          {
            "name": "_calculate_syntactic_complexity",
            "decorator": null,
            "signature": "_calculate_syntactic_complexity(self, text: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula complejidad sintáctica del documento",
            "is_public": false,
            "lineno": 911,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_syntactic_complexity()"
          },
          {
            "name": "_get_dependency_depth",
            "decorator": null,
            "signature": "_get_dependency_depth(self, token) -> int",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "token",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "int",
            "docstring": "Calcula profundidad de un token en el árbol de dependencias",
            "is_public": false,
            "lineno": 940,
            "invocation_pattern": "policycontradictiondetector_instance._get_dependency_depth()"
          },
          {
            "name": "_calculate_confidence_interval",
            "decorator": null,
            "signature": "_calculate_confidence_interval(self, score: float, n_observations: int) -> Tuple[float, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "score",
                "annotation": "float",
                "default": null
              },
              {
                "name": "n_observations",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "Tuple[float, float]",
            "docstring": "Calcula intervalo de confianza del 95% para el score",
            "is_public": false,
            "lineno": 949,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_confidence_interval()"
          },
          {
            "name": "_generate_resolution_recommendations",
            "decorator": null,
            "signature": "_generate_resolution_recommendations(self, contradictions: List[ContradictionEvidence]) -> List[Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "contradictions",
                "annotation": "List[ContradictionEvidence]",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, Any]]",
            "docstring": "Genera recomendaciones específicas para resolver contradicciones",
            "is_public": false,
            "lineno": 972,
            "invocation_pattern": "policycontradictiondetector_instance._generate_resolution_recommendations()"
          },
          {
            "name": "_identify_affected_sections",
            "decorator": null,
            "signature": "_identify_affected_sections(self, conflicts: List[ContradictionEvidence]) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "conflicts",
                "annotation": "List[ContradictionEvidence]",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Identifica secciones del plan afectadas por contradicciones",
            "is_public": false,
            "lineno": 1046,
            "invocation_pattern": "policycontradictiondetector_instance._identify_affected_sections()"
          },
          {
            "name": "_serialize_contradiction",
            "decorator": null,
            "signature": "_serialize_contradiction(self, contradiction: ContradictionEvidence) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "contradiction",
                "annotation": "ContradictionEvidence",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Serializa evidencia de contradicción para output",
            "is_public": false,
            "lineno": 1062,
            "invocation_pattern": "policycontradictiondetector_instance._serialize_contradiction()"
          },
          {
            "name": "_get_graph_statistics",
            "decorator": null,
            "signature": "_get_graph_statistics(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Obtiene estadísticas del grafo de conocimiento",
            "is_public": false,
            "lineno": 1087,
            "invocation_pattern": "policycontradictiondetector_instance._get_graph_statistics()"
          },
          {
            "name": "_extract_temporal_markers",
            "decorator": null,
            "signature": "_extract_temporal_markers(self, text: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Extrae marcadores temporales del texto",
            "is_public": false,
            "lineno": 1104,
            "invocation_pattern": "policycontradictiondetector_instance._extract_temporal_markers()"
          },
          {
            "name": "_extract_quantitative_claims",
            "decorator": null,
            "signature": "_extract_quantitative_claims(self, text: str) -> List[Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, Any]]",
            "docstring": "Extrae afirmaciones cuantitativas estructuradas",
            "is_public": false,
            "lineno": 1125,
            "invocation_pattern": "policycontradictiondetector_instance._extract_quantitative_claims()"
          },
          {
            "name": "_parse_number",
            "decorator": null,
            "signature": "_parse_number(self, text: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Parsea número desde texto",
            "is_public": false,
            "lineno": 1155,
            "invocation_pattern": "policycontradictiondetector_instance._parse_number()"
          },
          {
            "name": "_extract_resource_mentions",
            "decorator": null,
            "signature": "_extract_resource_mentions(self, text: str) -> List[Tuple[str, Optional[float]]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[Tuple[str, Optional[float]]]",
            "docstring": "Extrae menciones de recursos con montos",
            "is_public": false,
            "lineno": 1164,
            "invocation_pattern": "policycontradictiondetector_instance._extract_resource_mentions()"
          },
          {
            "name": "_determine_semantic_role",
            "decorator": null,
            "signature": "_determine_semantic_role(self, sent) -> Optional[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sent",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Optional[str]",
            "docstring": "Determina el rol semántico de una oración",
            "is_public": false,
            "lineno": 1187,
            "invocation_pattern": "policycontradictiondetector_instance._determine_semantic_role()"
          },
          {
            "name": "_identify_dependencies",
            "decorator": null,
            "signature": "_identify_dependencies(self, sent, doc) -> Set[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sent",
                "annotation": null,
                "default": null
              },
              {
                "name": "doc",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Set[str]",
            "docstring": "Identifica dependencias entre declaraciones",
            "is_public": false,
            "lineno": 1206,
            "invocation_pattern": "policycontradictiondetector_instance._identify_dependencies()"
          },
          {
            "name": "_get_context_window",
            "decorator": null,
            "signature": "_get_context_window(self, text: str, start: int, end: int, window_size: int = 200) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "start",
                "annotation": "int",
                "default": null
              },
              {
                "name": "end",
                "annotation": "int",
                "default": null
              },
              {
                "name": "window_size",
                "annotation": "int",
                "default": "200"
              }
            ],
            "return_type": "str",
            "docstring": "Obtiene ventana de contexto alrededor de una posición",
            "is_public": false,
            "lineno": 1229,
            "invocation_pattern": "policycontradictiondetector_instance._get_context_window()"
          },
          {
            "name": "_calculate_similarity",
            "decorator": null,
            "signature": "_calculate_similarity(self, stmt_a: PolicyStatement, stmt_b: PolicyStatement) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "stmt_a",
                "annotation": "PolicyStatement",
                "default": null
              },
              {
                "name": "stmt_b",
                "annotation": "PolicyStatement",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula similaridad entre dos declaraciones",
            "is_public": false,
            "lineno": 1235,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_similarity()"
          },
          {
            "name": "_classify_contradiction",
            "decorator": null,
            "signature": "_classify_contradiction(self, text: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Clasifica probabilidad de contradicción en texto",
            "is_public": false,
            "lineno": 1241,
            "invocation_pattern": "policycontradictiondetector_instance._classify_contradiction()"
          },
          {
            "name": "_get_domain_weight",
            "decorator": null,
            "signature": "_get_domain_weight(self, dimension: PolicyDimension) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dimension",
                "annotation": "PolicyDimension",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Obtiene peso específico del dominio",
            "is_public": false,
            "lineno": 1254,
            "invocation_pattern": "policycontradictiondetector_instance._get_domain_weight()"
          },
          {
            "name": "_suggest_resolutions",
            "decorator": null,
            "signature": "_suggest_resolutions(self, contradiction_type: ContradictionType) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "contradiction_type",
                "annotation": "ContradictionType",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Sugiere resoluciones específicas por tipo de contradicción",
            "is_public": false,
            "lineno": 1266,
            "invocation_pattern": "policycontradictiondetector_instance._suggest_resolutions()"
          },
          {
            "name": "_are_comparable_claims",
            "decorator": null,
            "signature": "_are_comparable_claims(self, claim_a: Dict, claim_b: Dict) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "claim_a",
                "annotation": "Dict",
                "default": null
              },
              {
                "name": "claim_b",
                "annotation": "Dict",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Determina si dos afirmaciones cuantitativas son comparables",
            "is_public": false,
            "lineno": 1297,
            "invocation_pattern": "policycontradictiondetector_instance._are_comparable_claims()"
          },
          {
            "name": "_text_similarity",
            "decorator": null,
            "signature": "_text_similarity(self, text_a: str, text_b: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text_a",
                "annotation": "str",
                "default": null
              },
              {
                "name": "text_b",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calcula similaridad simple entre textos",
            "is_public": false,
            "lineno": 1311,
            "invocation_pattern": "policycontradictiondetector_instance._text_similarity()"
          },
          {
            "name": "_calculate_numerical_divergence",
            "decorator": null,
            "signature": "_calculate_numerical_divergence(self, claim_a: Dict, claim_b: Dict) -> Optional[float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "claim_a",
                "annotation": "Dict",
                "default": null
              },
              {
                "name": "claim_b",
                "annotation": "Dict",
                "default": null
              }
            ],
            "return_type": "Optional[float]",
            "docstring": "Calcula divergencia entre valores numéricos",
            "is_public": false,
            "lineno": 1329,
            "invocation_pattern": "policycontradictiondetector_instance._calculate_numerical_divergence()"
          },
          {
            "name": "_statistical_significance_test",
            "decorator": null,
            "signature": "_statistical_significance_test(self, claim_a: Dict, claim_b: Dict) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "claim_a",
                "annotation": "Dict",
                "default": null
              },
              {
                "name": "claim_b",
                "annotation": "Dict",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Realiza test de significancia estadística",
            "is_public": false,
            "lineno": 1349,
            "invocation_pattern": "policycontradictiondetector_instance._statistical_significance_test()"
          },
          {
            "name": "_has_logical_conflict",
            "decorator": null,
            "signature": "_has_logical_conflict(self, stmt_a: PolicyStatement, stmt_b: PolicyStatement) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "stmt_a",
                "annotation": "PolicyStatement",
                "default": null
              },
              {
                "name": "stmt_b",
                "annotation": "PolicyStatement",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Determina si hay conflicto lógico entre declaraciones",
            "is_public": false,
            "lineno": 1380,
            "invocation_pattern": "policycontradictiondetector_instance._has_logical_conflict()"
          },
          {
            "name": "_are_conflicting_allocations",
            "decorator": null,
            "signature": "_are_conflicting_allocations(self, amount_a: float, amount_b: float, total: float) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "amount_a",
                "annotation": "float",
                "default": null
              },
              {
                "name": "amount_b",
                "annotation": "float",
                "default": null
              },
              {
                "name": "total",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Determina si las asignaciones de recursos están en conflicto",
            "is_public": false,
            "lineno": 1409,
            "invocation_pattern": "policycontradictiondetector_instance._are_conflicting_allocations()"
          }
        ]
      }
    ],
    "functions": []
  },
  "dereck_beach": {
    "module_name": "dereck_beach",
    "docstring": "Causal Deconstruction and Audit Framework (CDAF) v2.0\nFramework de Producción para Análisis Causal de Planes de Desarrollo Territorial\n\nTHEORETICAL FOUNDATION (Derek Beach):\n\"A causal mechanism is a system of interlocking parts (entities engaging in\nactivities) that transmits causal forces from X to Y\" (Beach 2016: 465)\n\nThis framework implements Theory-Testing Process Tracing with mechanistic evidence\nevaluation using Beach's evidential tests taxonomy (Beach & Pedersen 2019).\n\nAuthor: AI Systems Architect\nVersion: 2.0.0 (Beach-Grounded Production Grade)",
    "classes": [
      {
        "name": "BeachEvidentialTest",
        "docstring": "Derek Beach evidential tests implementation (Beach & Pedersen 2019: Ch 5).\n\nFOUR-FOLD TYPOLOGY calibrated by necessity (N) and sufficiency (S):\n\nHOOP TEST [N: High, S: Low]:\n- Fail → ELIMINATES hypothesis (definitive knock-out)\n- Pass → Hypothesis survives but not proven\n- Example: \"Responsible entity must be documented\"\n\nSMOKING GUN [N: Low, S: High]:\n- Pass → Strongly confirms hypothesis\n- Fail → Doesn't eliminate (could be false negative)\n- Example: \"Unique policy instrument only used for this mechanism\"\n\nDOUBLY DECISIVE [N: High, S: High]:\n- Pass → Conclusively confirms\n- Fail → Conclusively eliminates\n- Extremely rare in social science\n\nSTRAW-IN-WIND [N: Low, S: Low]:\n- Pass/Fail → Marginal confidence change\n- Used for preliminary screening\n\nREFERENCE: Beach & Pedersen (2019), pp 117-126",
        "base_classes": [],
        "is_public": true,
        "lineno": 93,
        "methods": [
          {
            "name": "classify_test",
            "decorator": "staticmethod",
            "signature": "classify_test(necessity: float, sufficiency: float) -> TestType",
            "parameters": [
              {
                "name": "necessity",
                "annotation": "float",
                "default": null
              },
              {
                "name": "sufficiency",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "TestType",
            "docstring": "Classify evidential test type based on necessity and sufficiency.\n\nBeach calibration:\n- Necessity > 0.7 → High necessity\n- Sufficiency > 0.7 → High sufficiency",
            "is_public": true,
            "lineno": 122,
            "invocation_pattern": "BeachEvidentialTest.classify_test()"
          },
          {
            "name": "apply_test_logic",
            "decorator": "staticmethod",
            "signature": "apply_test_logic(test_type: TestType, evidence_found: bool, prior: float, bayes_factor: float) -> Tuple[float, str]",
            "parameters": [
              {
                "name": "test_type",
                "annotation": "TestType",
                "default": null
              },
              {
                "name": "evidence_found",
                "annotation": "bool",
                "default": null
              },
              {
                "name": "prior",
                "annotation": "float",
                "default": null
              },
              {
                "name": "bayes_factor",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Tuple[float, str]",
            "docstring": "Apply Beach test-specific logic to Bayesian updating.\n\nCRITICAL RULES:\n1. Hoop Test FAIL → posterior ≈ 0 (knock-out)\n2. Smoking Gun PASS → multiply prior by large BF (>10)\n3. Doubly Decisive → extreme updates (BF > 100 or < 0.01)\n\nReturns: (posterior_confidence, interpretation)",
            "is_public": true,
            "lineno": 143,
            "invocation_pattern": "BeachEvidentialTest.apply_test_logic()"
          }
        ]
      },
      {
        "name": "CDAFException",
        "docstring": "Base exception for CDAF framework with structured payloads",
        "base_classes": [
          "Exception"
        ],
        "is_public": true,
        "lineno": 194,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, message: str, details: Optional[Dict[str, Any]] = None, stage: Optional[str] = None, recoverable: bool = False)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "message",
                "annotation": "str",
                "default": null
              },
              {
                "name": "details",
                "annotation": "Optional[Dict[str, Any]]",
                "default": "None"
              },
              {
                "name": "stage",
                "annotation": "Optional[str]",
                "default": "None"
              },
              {
                "name": "recoverable",
                "annotation": "bool",
                "default": "False"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 197,
            "invocation_pattern": "cdafexception_instance.__init__()"
          },
          {
            "name": "_format_message",
            "decorator": null,
            "signature": "_format_message(self) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Format error message with structured information",
            "is_public": false,
            "lineno": 205,
            "invocation_pattern": "cdafexception_instance._format_message()"
          },
          {
            "name": "to_dict",
            "decorator": null,
            "signature": "to_dict(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Convert exception to structured dictionary",
            "is_public": true,
            "lineno": 215,
            "invocation_pattern": "cdafexception_instance.to_dict()"
          }
        ]
      },
      {
        "name": "CDAFValidationError",
        "docstring": "Configuration or data validation error",
        "base_classes": [
          "CDAFException"
        ],
        "is_public": true,
        "lineno": 226,
        "methods": []
      },
      {
        "name": "CDAFProcessingError",
        "docstring": "Error during document processing",
        "base_classes": [
          "CDAFException"
        ],
        "is_public": true,
        "lineno": 231,
        "methods": []
      },
      {
        "name": "CDAFBayesianError",
        "docstring": "Error during Bayesian inference",
        "base_classes": [
          "CDAFException"
        ],
        "is_public": true,
        "lineno": 236,
        "methods": []
      },
      {
        "name": "CDAFConfigError",
        "docstring": "Configuration loading or validation error",
        "base_classes": [
          "CDAFException"
        ],
        "is_public": true,
        "lineno": 241,
        "methods": []
      },
      {
        "name": "BayesianThresholdsConfig",
        "docstring": "Bayesian inference thresholds configuration",
        "base_classes": [
          "BaseModel"
        ],
        "is_public": true,
        "lineno": 250,
        "methods": []
      },
      {
        "name": "MechanismTypeConfig",
        "docstring": "Mechanism type prior probabilities",
        "base_classes": [
          "BaseModel"
        ],
        "is_public": true,
        "lineno": 280,
        "methods": [
          {
            "name": "check_sum_to_one",
            "decorator": null,
            "signature": "check_sum_to_one(cls, v, values)",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "v",
                "annotation": null,
                "default": null
              },
              {
                "name": "values",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": "Validate that probabilities sum to approximately 1.0",
            "is_public": true,
            "lineno": 289,
            "invocation_pattern": "mechanismtypeconfig_instance.check_sum_to_one()"
          }
        ]
      },
      {
        "name": "PerformanceConfig",
        "docstring": "Performance and optimization settings",
        "base_classes": [
          "BaseModel"
        ],
        "is_public": true,
        "lineno": 298,
        "methods": []
      },
      {
        "name": "SelfReflectionConfig",
        "docstring": "Self-reflective learning configuration",
        "base_classes": [
          "BaseModel"
        ],
        "is_public": true,
        "lineno": 319,
        "methods": []
      },
      {
        "name": "CDAFConfigSchema",
        "docstring": "Complete CDAF configuration schema with validation",
        "base_classes": [
          "BaseModel"
        ],
        "is_public": true,
        "lineno": 342,
        "methods": []
      },
      {
        "name": "GoalClassification",
        "docstring": "Classification structure for goals",
        "base_classes": [
          "NamedTuple"
        ],
        "is_public": true,
        "lineno": 377,
        "methods": []
      },
      {
        "name": "EntityActivity",
        "docstring": "Entity-Activity tuple for mechanism parts (Beach 2016).\n\nBEACH DEFINITION:\n\"A mechanism part consists of an entity (organization, actor, structure)\nengaging in an activity that transmits causal forces\" (Beach 2016: 465)\n\nThis is the FUNDAMENTAL UNIT of mechanistic evidence in Process Tracing.",
        "base_classes": [
          "NamedTuple"
        ],
        "is_public": true,
        "lineno": 385,
        "methods": []
      },
      {
        "name": "CausalLink",
        "docstring": "Structure for causal links in the graph",
        "base_classes": [
          "TypedDict"
        ],
        "is_public": true,
        "lineno": 401,
        "methods": []
      },
      {
        "name": "AuditResult",
        "docstring": "Audit result structure",
        "base_classes": [
          "TypedDict"
        ],
        "is_public": true,
        "lineno": 414,
        "methods": []
      },
      {
        "name": "MetaNode",
        "docstring": "Comprehensive node structure for goals/metas",
        "base_classes": [],
        "is_public": true,
        "lineno": 423,
        "methods": []
      },
      {
        "name": "ConfigLoader",
        "docstring": "External configuration management with Pydantic schema validation",
        "base_classes": [],
        "is_public": true,
        "lineno": 444,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config_path: Path) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config_path",
                "annotation": "Path",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 447,
            "invocation_pattern": "configloader_instance.__init__()"
          },
          {
            "name": "_load_config",
            "decorator": null,
            "signature": "_load_config(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Load YAML configuration file",
            "is_public": false,
            "lineno": 458,
            "invocation_pattern": "configloader_instance._load_config()"
          },
          {
            "name": "_load_default_config",
            "decorator": null,
            "signature": "_load_default_config(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Load default configuration if custom fails",
            "is_public": false,
            "lineno": 475,
            "invocation_pattern": "configloader_instance._load_default_config()"
          },
          {
            "name": "_validate_config",
            "decorator": null,
            "signature": "_validate_config(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Validate configuration structure using Pydantic schema",
            "is_public": false,
            "lineno": 562,
            "invocation_pattern": "configloader_instance._validate_config()"
          },
          {
            "name": "get",
            "decorator": null,
            "signature": "get(self, key: str, default: Any = None) -> Any",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "key",
                "annotation": "str",
                "default": null
              },
              {
                "name": "default",
                "annotation": "Any",
                "default": "None"
              }
            ],
            "return_type": "Any",
            "docstring": "Get configuration value with dot notation support",
            "is_public": true,
            "lineno": 593,
            "invocation_pattern": "configloader_instance.get()"
          },
          {
            "name": "get_bayesian_threshold",
            "decorator": null,
            "signature": "get_bayesian_threshold(self, key: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "key",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Get Bayesian threshold with type safety",
            "is_public": true,
            "lineno": 604,
            "invocation_pattern": "configloader_instance.get_bayesian_threshold()"
          },
          {
            "name": "get_mechanism_prior",
            "decorator": null,
            "signature": "get_mechanism_prior(self, mechanism_type: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "mechanism_type",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Get mechanism type prior probability with type safety",
            "is_public": true,
            "lineno": 610,
            "invocation_pattern": "configloader_instance.get_mechanism_prior()"
          },
          {
            "name": "get_performance_setting",
            "decorator": null,
            "signature": "get_performance_setting(self, key: str) -> Any",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "key",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Any",
            "docstring": "Get performance setting with type safety",
            "is_public": true,
            "lineno": 616,
            "invocation_pattern": "configloader_instance.get_performance_setting()"
          },
          {
            "name": "update_priors_from_feedback",
            "decorator": null,
            "signature": "update_priors_from_feedback(self, feedback_data: Dict[str, Any]) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "feedback_data",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Self-reflective loop: Update priors based on audit feedback\nImplements frontier paradigm of learning from results\n\nHARMONIC FRONT 4 ENHANCEMENT:\n- Applies penalties to mechanism types with implementation_failure flags\n- Heavily penalizes \"miracle\" mechanisms failing necessity/sufficiency tests\n- Ensures mean mech_uncertainty decreases by ≥5% over iterations",
            "is_public": true,
            "lineno": 622,
            "invocation_pattern": "configloader_instance.update_priors_from_feedback()"
          },
          {
            "name": "_save_prior_history",
            "decorator": null,
            "signature": "_save_prior_history(self, feedback_data: Optional[Dict[str, Any]] = None, uncertainty_reduction: Optional[float] = None) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "feedback_data",
                "annotation": "Optional[Dict[str, Any]]",
                "default": "None"
              },
              {
                "name": "uncertainty_reduction",
                "annotation": "Optional[float]",
                "default": "None"
              }
            ],
            "return_type": "None",
            "docstring": "Save prior history for learning across documents\n\nHARMONIC FRONT 4 ENHANCEMENT:\n- Tracks uncertainty reduction over iterations\n- Records penalty applications and test failures",
            "is_public": false,
            "lineno": 718,
            "invocation_pattern": "configloader_instance._save_prior_history()"
          },
          {
            "name": "_load_uncertainty_history",
            "decorator": null,
            "signature": "_load_uncertainty_history(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Load historical uncertainty measurements\n\nHARMONIC FRONT 4: Required for tracking ≥5% reduction over 10 iterations",
            "is_public": false,
            "lineno": 781,
            "invocation_pattern": "configloader_instance._load_uncertainty_history()"
          },
          {
            "name": "check_uncertainty_reduction_criterion",
            "decorator": null,
            "signature": "check_uncertainty_reduction_criterion(self, current_uncertainty: float) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "current_uncertainty",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Check if mean mechanism_type uncertainty has decreased ≥5% over 10 iterations\n\nHARMONIC FRONT 4 QUALITY CRITERIA:\nSuccess verified if mean mech_uncertainty decreases by ≥5% over 10 sequential PDM analyses",
            "is_public": true,
            "lineno": 806,
            "invocation_pattern": "configloader_instance.check_uncertainty_reduction_criterion()"
          }
        ]
      },
      {
        "name": "PDFProcessor",
        "docstring": "Advanced PDF processing and extraction",
        "base_classes": [],
        "is_public": true,
        "lineno": 849,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader, retry_handler = None) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              },
              {
                "name": "retry_handler",
                "annotation": null,
                "default": "None"
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 852,
            "invocation_pattern": "pdfprocessor_instance.__init__()"
          },
          {
            "name": "load_document",
            "decorator": null,
            "signature": "load_document(self, pdf_path: Path) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pdf_path",
                "annotation": "Path",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Load PDF document with retry logic",
            "is_public": true,
            "lineno": 861,
            "invocation_pattern": "pdfprocessor_instance.load_document()"
          },
          {
            "name": "extract_text",
            "decorator": null,
            "signature": "extract_text(self) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Extract all text from PDF",
            "is_public": true,
            "lineno": 894,
            "invocation_pattern": "pdfprocessor_instance.extract_text()"
          },
          {
            "name": "extract_tables",
            "decorator": null,
            "signature": "extract_tables(self) -> List[pd.DataFrame]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "List[pd.DataFrame]",
            "docstring": "Extract tables from PDF",
            "is_public": true,
            "lineno": 912,
            "invocation_pattern": "pdfprocessor_instance.extract_tables()"
          },
          {
            "name": "extract_sections",
            "decorator": null,
            "signature": "extract_sections(self) -> Dict[str, str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, str]",
            "docstring": "Extract document sections based on patterns",
            "is_public": true,
            "lineno": 943,
            "invocation_pattern": "pdfprocessor_instance.extract_sections()"
          }
        ]
      },
      {
        "name": "CausalExtractor",
        "docstring": "Extract and structure causal chains from text",
        "base_classes": [],
        "is_public": true,
        "lineno": 963,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader, nlp_model: spacy.Language) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              },
              {
                "name": "nlp_model",
                "annotation": "spacy.Language",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 966,
            "invocation_pattern": "causalextractor_instance.__init__()"
          },
          {
            "name": "extract_causal_hierarchy",
            "decorator": null,
            "signature": "extract_causal_hierarchy(self, text: str) -> nx.DiGraph",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "nx.DiGraph",
            "docstring": "Extract complete causal hierarchy from text",
            "is_public": true,
            "lineno": 974,
            "invocation_pattern": "causalextractor_instance.extract_causal_hierarchy()"
          },
          {
            "name": "_extract_goals",
            "decorator": null,
            "signature": "_extract_goals(self, text: str) -> List[MetaNode]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[MetaNode]",
            "docstring": "Extract all goals from text",
            "is_public": false,
            "lineno": 993,
            "invocation_pattern": "causalextractor_instance._extract_goals()"
          },
          {
            "name": "_parse_goal_context",
            "decorator": null,
            "signature": "_parse_goal_context(self, goal_id: str, context: str) -> Optional[MetaNode]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "goal_id",
                "annotation": "str",
                "default": null
              },
              {
                "name": "context",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Optional[MetaNode]",
            "docstring": "Parse goal context to extract structured information",
            "is_public": false,
            "lineno": 1015,
            "invocation_pattern": "causalextractor_instance._parse_goal_context()"
          },
          {
            "name": "_add_node_to_graph",
            "decorator": null,
            "signature": "_add_node_to_graph(self, node: MetaNode) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Add node to causal graph",
            "is_public": false,
            "lineno": 1051,
            "invocation_pattern": "causalextractor_instance._add_node_to_graph()"
          },
          {
            "name": "_extract_causal_links",
            "decorator": null,
            "signature": "_extract_causal_links(self, text: str) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "AGUJA I: El Prior Informado Adaptativo\nExtract causal links using Bayesian inference with adaptive priors",
            "is_public": false,
            "lineno": 1059,
            "invocation_pattern": "causalextractor_instance._extract_causal_links()"
          },
          {
            "name": "_calculate_semantic_distance",
            "decorator": null,
            "signature": "_calculate_semantic_distance(self, source: str, target: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate semantic distance between nodes using spaCy embeddings\n\nPERFORMANCE NOTE: This method can be optimized with:\n1. Vectorized operations using numpy for batch processing\n2. Embedding caching to avoid recomputing spaCy vectors\n3. Async processing for large documents with many nodes\n4. Alternative: BERT/transformer embeddings for higher fidelity (SOTA)\n\nCurrent implementation prioritizes determinism over speed.\nEnable performance.cache_embeddings in config for production use.",
            "is_public": false,
            "lineno": 1194,
            "invocation_pattern": "causalextractor_instance._calculate_semantic_distance()"
          },
          {
            "name": "_calculate_type_transition_prior",
            "decorator": null,
            "signature": "_calculate_type_transition_prior(self, source: str, target: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate prior based on historical transition frequencies between goal types",
            "is_public": false,
            "lineno": 1232,
            "invocation_pattern": "causalextractor_instance._calculate_type_transition_prior()"
          },
          {
            "name": "_check_structural_violation",
            "decorator": null,
            "signature": "_check_structural_violation(self, source: str, target: str) -> Optional[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Optional[str]",
            "docstring": "AUDIT POINT 2.1: Structural Veto (D6-Q2)\n\nCheck if causal link violates structural hierarchy based on TeoriaCambio axioms.\nImplements set-theoretic constraints per Goertz & Mahoney 2012.\n\nReturns:\n    None if link is valid, otherwise a string describing the violation",
            "is_public": false,
            "lineno": 1255,
            "invocation_pattern": "causalextractor_instance._check_structural_violation()"
          },
          {
            "name": "_calculate_language_specificity",
            "decorator": null,
            "signature": "_calculate_language_specificity(self, keyword: str, policy_area: Optional[str] = None, context: Optional[str] = None) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "keyword",
                "annotation": "str",
                "default": null
              },
              {
                "name": "policy_area",
                "annotation": "Optional[str]",
                "default": "None"
              },
              {
                "name": "context",
                "annotation": "Optional[str]",
                "default": "None"
              }
            ],
            "return_type": "float",
            "docstring": "Assess specificity of causal language (epistemic certainty)\n\nHarmonic Front 3 - Enhancement 4: Language Specificity Assessment\nEnhanced to check policy-specific vocabulary (patrones_verificacion) for current\nPolicy Area (P1–P10), not just generic causal keywords.\n\nFor D6-Q5 (Contextual/Differential Focus): rewards use of specialized terminology\nthat anchors intervention in social/cultural context (e.g., \"catastro multipropósito\",\n\"reparación integral\", \"mujeres rurales\", \"guardia indígena\").",
            "is_public": false,
            "lineno": 1295,
            "invocation_pattern": "causalextractor_instance._calculate_language_specificity()"
          },
          {
            "name": "_assess_temporal_coherence",
            "decorator": null,
            "signature": "_assess_temporal_coherence(self, source: str, target: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Assess temporal coherence based on verb sequences",
            "is_public": false,
            "lineno": 1405,
            "invocation_pattern": "causalextractor_instance._assess_temporal_coherence()"
          },
          {
            "name": "_assess_financial_consistency",
            "decorator": null,
            "signature": "_assess_financial_consistency(self, source: str, target: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Assess financial alignment between connected nodes",
            "is_public": false,
            "lineno": 1436,
            "invocation_pattern": "causalextractor_instance._assess_financial_consistency()"
          },
          {
            "name": "_calculate_textual_proximity",
            "decorator": null,
            "signature": "_calculate_textual_proximity(self, source: str, target: str, text: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate how often node IDs appear together in text windows",
            "is_public": false,
            "lineno": 1460,
            "invocation_pattern": "causalextractor_instance._calculate_textual_proximity()"
          },
          {
            "name": "_initialize_prior",
            "decorator": null,
            "signature": "_initialize_prior(self, source: str, target: str) -> Tuple[float, float, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "source",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Tuple[float, float, float]",
            "docstring": "Initialize prior distribution for causal link",
            "is_public": false,
            "lineno": 1482,
            "invocation_pattern": "causalextractor_instance._initialize_prior()"
          },
          {
            "name": "_calculate_composite_likelihood",
            "decorator": null,
            "signature": "_calculate_composite_likelihood(self, evidence: Dict[str, Any]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "evidence",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate composite likelihood from multiple evidence components\n\nEnhanced with:\n- Nonlinear transformation rewarding triangulation\n- Evidence diversity verification across analytical domains",
            "is_public": false,
            "lineno": 1500,
            "invocation_pattern": "causalextractor_instance._calculate_composite_likelihood()"
          },
          {
            "name": "_build_type_hierarchy",
            "decorator": null,
            "signature": "_build_type_hierarchy(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Build hierarchy based on goal types",
            "is_public": false,
            "lineno": 1559,
            "invocation_pattern": "causalextractor_instance._build_type_hierarchy()"
          }
        ]
      },
      {
        "name": "MechanismPartExtractor",
        "docstring": "Extract Entity-Activity pairs for mechanism parts",
        "base_classes": [],
        "is_public": true,
        "lineno": 1581,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader, nlp_model: spacy.Language) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              },
              {
                "name": "nlp_model",
                "annotation": "spacy.Language",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 1584,
            "invocation_pattern": "mechanismpartextractor_instance.__init__()"
          },
          {
            "name": "extract_entity_activity",
            "decorator": null,
            "signature": "extract_entity_activity(self, text: str) -> Optional[EntityActivity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Optional[EntityActivity]",
            "docstring": "Extract Entity-Activity tuple from text",
            "is_public": true,
            "lineno": 1590,
            "invocation_pattern": "mechanismpartextractor_instance.extract_entity_activity()"
          },
          {
            "name": "_normalize_entity",
            "decorator": null,
            "signature": "_normalize_entity(self, entity: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "entity",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Normalize entity name using aliases",
            "is_public": false,
            "lineno": 1628,
            "invocation_pattern": "mechanismpartextractor_instance._normalize_entity()"
          }
        ]
      },
      {
        "name": "FinancialAuditor",
        "docstring": "Financial traceability and auditing",
        "base_classes": [],
        "is_public": true,
        "lineno": 1634,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 1637,
            "invocation_pattern": "financialauditor_instance.__init__()"
          },
          {
            "name": "trace_financial_allocation",
            "decorator": null,
            "signature": "trace_financial_allocation(self, tables: List[pd.DataFrame], nodes: Dict[str, MetaNode], graph: Optional[nx.DiGraph] = None) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[pd.DataFrame]",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "Optional[nx.DiGraph]",
                "default": "None"
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Trace financial allocations to programs/goals\n\nHarmonic Front 3 - Enhancement 5: Single-Case Counterfactual Budget Check\nIncorporates logic from single-case counterfactuals to test minimal sufficiency.\nFor D3-Q3 (Traceability/Resources): checks if resource X (BPIN code) were removed,\nwould the mechanism (Product) still execute? Only boosts budget traceability score\nif allocation is tied to a specific project.",
            "is_public": true,
            "lineno": 1646,
            "invocation_pattern": "financialauditor_instance.trace_financial_allocation()"
          },
          {
            "name": "_process_financial_table",
            "decorator": null,
            "signature": "_process_financial_table(self, table: pd.DataFrame, nodes: Dict[str, MetaNode]) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "table",
                "annotation": "pd.DataFrame",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Process a single financial table",
            "is_public": false,
            "lineno": 1676,
            "invocation_pattern": "financialauditor_instance._process_financial_table()"
          },
          {
            "name": "_parse_amount",
            "decorator": null,
            "signature": "_parse_amount(self, value: Any) -> Optional[float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "value",
                "annotation": "Any",
                "default": null
              }
            ],
            "return_type": "Optional[float]",
            "docstring": "Parse monetary amount from various formats",
            "is_public": false,
            "lineno": 1747,
            "invocation_pattern": "financialauditor_instance._parse_amount()"
          },
          {
            "name": "_match_program_to_node",
            "decorator": null,
            "signature": "_match_program_to_node(self, program_id: str, nodes: Dict[str, MetaNode]) -> Optional[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "program_id",
                "annotation": "str",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "Optional[str]",
            "docstring": "Match program ID to existing node using fuzzy matching\n\nEnhanced for D1-Q3 / D3-Q3 Financial Traceability:\n- Implements confidence penalty if fuzzy match ratio < 100\n- Reduces node.financial_allocation confidence by 15% for imperfect matches\n- Tracks match quality for overall financial traceability scoring",
            "is_public": false,
            "lineno": 1762,
            "invocation_pattern": "financialauditor_instance._match_program_to_node()"
          },
          {
            "name": "_perform_counterfactual_budget_check",
            "decorator": null,
            "signature": "_perform_counterfactual_budget_check(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Harmonic Front 3 - Enhancement 5: Counterfactual Sufficiency Test for D3-Q3\n\nTests minimal sufficiency: if resource X (BPIN code) were removed, would the\nmechanism (Product) still execute? Only boosts budget traceability score if\nallocation is tied to a specific project.\n\nFor D3-Q3 (Traceability/Resources): ensures funding is necessary for the mechanism\nand prevents false positives from generic or disconnected budget entries.",
            "is_public": false,
            "lineno": 1817,
            "invocation_pattern": "financialauditor_instance._perform_counterfactual_budget_check()"
          }
        ]
      },
      {
        "name": "OperationalizationAuditor",
        "docstring": "Audit operationalization quality",
        "base_classes": [],
        "is_public": true,
        "lineno": 1912,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 1915,
            "invocation_pattern": "operationalizationauditor_instance.__init__()"
          },
          {
            "name": "audit_evidence_traceability",
            "decorator": null,
            "signature": "audit_evidence_traceability(self, nodes: Dict[str, MetaNode]) -> Dict[str, AuditResult]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "Dict[str, AuditResult]",
            "docstring": "Audit evidence traceability for all nodes\n\nEnhanced with D3-Q1 Ficha Técnica validation:\n- Cross-checks baseline/target against extracted quantitative_claims\n- Verifies DNP INDICATOR_STRUCTURE compliance for producto nodes\n- Scores 'Excelente' only if ≥80% of productos pass full audit",
            "is_public": true,
            "lineno": 1922,
            "invocation_pattern": "operationalizationauditor_instance.audit_evidence_traceability()"
          },
          {
            "name": "audit_sequence_logic",
            "decorator": null,
            "signature": "audit_sequence_logic(self, graph: nx.DiGraph) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Audit logical sequence of activities",
            "is_public": true,
            "lineno": 2052,
            "invocation_pattern": "operationalizationauditor_instance.audit_sequence_logic()"
          },
          {
            "name": "bayesian_counterfactual_audit",
            "decorator": null,
            "signature": "bayesian_counterfactual_audit(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph, historical_data: Optional[Dict[str, Any]] = None, pdet_alignment: Optional[float] = None) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "historical_data",
                "annotation": "Optional[Dict[str, Any]]",
                "default": "None"
              },
              {
                "name": "pdet_alignment",
                "annotation": "Optional[float]",
                "default": "None"
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "AGUJA III: El Auditor Contrafactual Bayesiano\nPerform counterfactual audit using Bayesian causal reasoning\n\nHarmonic Front 3: Enhanced to consume pdet_alignment scores for D4-Q5 and D5-Q4 integration",
            "is_public": true,
            "lineno": 2092,
            "invocation_pattern": "operationalizationauditor_instance.bayesian_counterfactual_audit()"
          },
          {
            "name": "_build_normative_dag",
            "decorator": null,
            "signature": "_build_normative_dag(self) -> nx.DiGraph",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "nx.DiGraph",
            "docstring": "Build normative DAG of expected relationships in well-formed plans",
            "is_public": false,
            "lineno": 2140,
            "invocation_pattern": "operationalizationauditor_instance._build_normative_dag()"
          },
          {
            "name": "_get_default_historical_priors",
            "decorator": null,
            "signature": "_get_default_historical_priors(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Get default historical priors if no data is available",
            "is_public": false,
            "lineno": 2163,
            "invocation_pattern": "operationalizationauditor_instance._get_default_historical_priors()"
          },
          {
            "name": "_audit_direct_evidence",
            "decorator": null,
            "signature": "_audit_direct_evidence(self, nodes: Dict[str, MetaNode], scm_dag: nx.DiGraph, historical_data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "scm_dag",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "historical_data",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Dict[str, Any]]",
            "docstring": "Layer 1: Audit direct evidence of required components\n\nEnhanced with highly specific Bayesian priors for rare evidence items.\nExample: D2-Q4 risk matrix, D5-Q5 unwanted effects are rare in poor PDMs.",
            "is_public": false,
            "lineno": 2179,
            "invocation_pattern": "operationalizationauditor_instance._audit_direct_evidence()"
          },
          {
            "name": "_audit_causal_implications",
            "decorator": null,
            "signature": "_audit_causal_implications(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph, direct_evidence: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "direct_evidence",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Dict[str, Any]]",
            "docstring": "Layer 2: Audit causal implications of omissions",
            "is_public": false,
            "lineno": 2281,
            "invocation_pattern": "operationalizationauditor_instance._audit_causal_implications()"
          },
          {
            "name": "_audit_systemic_risk",
            "decorator": null,
            "signature": "_audit_systemic_risk(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph, direct_evidence: Dict[str, Dict[str, Any]], causal_implications: Dict[str, Dict[str, Any]], pdet_alignment: Optional[float] = None) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "direct_evidence",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              },
              {
                "name": "causal_implications",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              },
              {
                "name": "pdet_alignment",
                "annotation": "Optional[float]",
                "default": "None"
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "AUDIT POINT 2.3: Policy Alignment Dual Constraint\nLayer 3: Calculate systemic risk from accumulated omissions\n\nHarmonic Front 3 - Enhancement 1: Alignment and Systemic Risk Linkage\nIncorporates Policy Alignment scores (PND, ODS, RRI) as variable in systemic risk.\n\nFor D5-Q4 (Riesgos Sistémicos) and D4-Q5 (Alineación):\n- If pdet_alignment ≤ 0.60, applies 1.2× multiplier to risk_score\n- Excelente on D5-Q4 requires risk_score < 0.10\n\nImplements dual constraints integrating macro-micro causality per Lieberman 2015.",
            "is_public": false,
            "lineno": 2334,
            "invocation_pattern": "operationalizationauditor_instance._audit_systemic_risk()"
          },
          {
            "name": "_generate_optimal_remediations",
            "decorator": null,
            "signature": "_generate_optimal_remediations(self, direct_evidence: Dict[str, Dict[str, Any]], causal_implications: Dict[str, Dict[str, Any]], systemic_risk: Dict[str, Any]) -> List[Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "direct_evidence",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              },
              {
                "name": "causal_implications",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              },
              {
                "name": "systemic_risk",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, Any]]",
            "docstring": "Generate prioritized remediation recommendations",
            "is_public": false,
            "lineno": 2452,
            "invocation_pattern": "operationalizationauditor_instance._generate_optimal_remediations()"
          },
          {
            "name": "_get_remediation_text",
            "decorator": null,
            "signature": "_get_remediation_text(self, omission: str, node_id: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "omission",
                "annotation": "str",
                "default": null
              },
              {
                "name": "node_id",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Get specific remediation text for an omission",
            "is_public": false,
            "lineno": 2500,
            "invocation_pattern": "operationalizationauditor_instance._get_remediation_text()"
          }
        ]
      },
      {
        "name": "BayesianMechanismInference",
        "docstring": "AGUJA II: El Modelo Generativo de Mecanismos\nHierarchical Bayesian model for causal mechanism inference\n\nF1.2 ARCHITECTURAL REFACTORING:\nThis class now integrates with refactored Bayesian engine components:\n- BayesianPriorBuilder: Construye priors adaptativos (AGUJA I)\n- BayesianSamplingEngine: Ejecuta MCMC sampling (AGUJA II)\n- NecessitySufficiencyTester: Ejecuta Hoop Tests (AGUJA III)\n\nThe refactored components provide:\n- Crystal-clear separation of concerns\n- Trivial unit testing\n- Explicit compliance with Fronts B and C\n\nLegacy methods are preserved for backward compatibility.",
        "base_classes": [],
        "is_public": true,
        "lineno": 2512,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader, nlp_model: spacy.Language) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              },
              {
                "name": "nlp_model",
                "annotation": "spacy.Language",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 2531,
            "invocation_pattern": "bayesianmechanisminference_instance.__init__()"
          },
          {
            "name": "_log_refactored_components",
            "decorator": null,
            "signature": "_log_refactored_components(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Log status of refactored Bayesian components (F1.2)",
            "is_public": false,
            "lineno": 2572,
            "invocation_pattern": "bayesianmechanisminference_instance._log_refactored_components()"
          },
          {
            "name": "infer_mechanisms",
            "decorator": null,
            "signature": "infer_mechanisms(self, nodes: Dict[str, MetaNode], text: str) -> Dict[str, Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Dict[str, Any]]",
            "docstring": "Infer latent causal mechanisms using hierarchical Bayesian modeling\n\nHARMONIC FRONT 4 ENHANCEMENT:\n- Tracks mean mechanism_type uncertainty for quality criteria\n- Reports uncertainty reduction metrics",
            "is_public": true,
            "lineno": 2583,
            "invocation_pattern": "bayesianmechanisminference_instance.infer_mechanisms()"
          },
          {
            "name": "_infer_single_mechanism",
            "decorator": null,
            "signature": "_infer_single_mechanism(self, node: MetaNode, text: str, all_nodes: Dict[str, MetaNode]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "all_nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Infer mechanism for a single product node",
            "is_public": false,
            "lineno": 2622,
            "invocation_pattern": "bayesianmechanisminference_instance._infer_single_mechanism()"
          },
          {
            "name": "_extract_observations",
            "decorator": null,
            "signature": "_extract_observations(self, node: MetaNode, text: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Extract textual observations related to the mechanism",
            "is_public": false,
            "lineno": 2664,
            "invocation_pattern": "bayesianmechanisminference_instance._extract_observations()"
          },
          {
            "name": "_infer_mechanism_type",
            "decorator": null,
            "signature": "_infer_mechanism_type(self, observations: Dict[str, Any]) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Infer mechanism type using Bayesian updating",
            "is_public": false,
            "lineno": 2706,
            "invocation_pattern": "bayesianmechanisminference_instance._infer_mechanism_type()"
          },
          {
            "name": "_infer_activity_sequence",
            "decorator": null,
            "signature": "_infer_activity_sequence(self, observations: Dict[str, Any], mechanism_type_posterior: Dict[str, float]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "mechanism_type_posterior",
                "annotation": "Dict[str, float]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Infer activity sequence parameters",
            "is_public": false,
            "lineno": 2744,
            "invocation_pattern": "bayesianmechanisminference_instance._infer_activity_sequence()"
          },
          {
            "name": "_calculate_coherence_factor",
            "decorator": null,
            "signature": "_calculate_coherence_factor(self, node: MetaNode, observations: Dict[str, Any], all_nodes: Dict[str, MetaNode]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "all_nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate mechanism coherence score",
            "is_public": false,
            "lineno": 2772,
            "invocation_pattern": "bayesianmechanisminference_instance._calculate_coherence_factor()"
          },
          {
            "name": "_test_sufficiency",
            "decorator": null,
            "signature": "_test_sufficiency(self, node: MetaNode, observations: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Test if mechanism is sufficient to produce the outcome",
            "is_public": false,
            "lineno": 2813,
            "invocation_pattern": "bayesianmechanisminference_instance._test_sufficiency()"
          },
          {
            "name": "_test_necessity",
            "decorator": null,
            "signature": "_test_necessity(self, node: MetaNode, observations: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "AUDIT POINT 2.2: Mechanism Necessity Hoop Test\n\nTest if mechanism is necessary by checking documented components:\n- Entity (responsable)\n- Activity (verb lemma sequence)\n- Budget (presupuesto asignado)\n\nImplements Beach 2017 Hoop Tests for necessity verification.\nPer Falleti & Lynch 2009, Bayesian-deterministic hybrid boosts mechanism depth.\n\nReturns:\n    Dict with 'is_necessary', 'missing_components', and remediation text",
            "is_public": false,
            "lineno": 2841,
            "invocation_pattern": "bayesianmechanisminference_instance._test_necessity()"
          },
          {
            "name": "_generate_necessity_remediation",
            "decorator": null,
            "signature": "_generate_necessity_remediation(self, node_id: str, missing_components: List[str]) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node_id",
                "annotation": "str",
                "default": null
              },
              {
                "name": "missing_components",
                "annotation": "List[str]",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Generate remediation text for failed necessity test",
            "is_public": false,
            "lineno": 2925,
            "invocation_pattern": "bayesianmechanisminference_instance._generate_necessity_remediation()"
          },
          {
            "name": "_quantify_uncertainty",
            "decorator": null,
            "signature": "_quantify_uncertainty(self, mechanism_type_posterior: Dict[str, float], sequence_posterior: Dict[str, Any], coherence_score: float) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "mechanism_type_posterior",
                "annotation": "Dict[str, float]",
                "default": null
              },
              {
                "name": "sequence_posterior",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "coherence_score",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Quantify epistemic uncertainty",
            "is_public": false,
            "lineno": 2944,
            "invocation_pattern": "bayesianmechanisminference_instance._quantify_uncertainty()"
          },
          {
            "name": "_detect_gaps",
            "decorator": null,
            "signature": "_detect_gaps(self, node: MetaNode, observations: Dict[str, Any], uncertainty: Dict[str, float]) -> List[Dict[str, str]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "node",
                "annotation": "MetaNode",
                "default": null
              },
              {
                "name": "observations",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "uncertainty",
                "annotation": "Dict[str, float]",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, str]]",
            "docstring": "Detect documentation gaps based on uncertainty",
            "is_public": false,
            "lineno": 2978,
            "invocation_pattern": "bayesianmechanisminference_instance._detect_gaps()"
          }
        ]
      },
      {
        "name": "CausalInferenceSetup",
        "docstring": "Prepare model for causal inference",
        "base_classes": [],
        "is_public": true,
        "lineno": 3022,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 3025,
            "invocation_pattern": "causalinferencesetup_instance.__init__()"
          },
          {
            "name": "classify_goal_dynamics",
            "decorator": null,
            "signature": "classify_goal_dynamics(self, nodes: Dict[str, MetaNode]) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Classify dynamics for each goal",
            "is_public": true,
            "lineno": 3032,
            "invocation_pattern": "causalinferencesetup_instance.classify_goal_dynamics()"
          },
          {
            "name": "assign_probative_value",
            "decorator": null,
            "signature": "assign_probative_value(self, nodes: Dict[str, MetaNode]) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Assign probative test types to nodes",
            "is_public": true,
            "lineno": 3043,
            "invocation_pattern": "causalinferencesetup_instance.assign_probative_value()"
          },
          {
            "name": "identify_failure_points",
            "decorator": null,
            "signature": "identify_failure_points(self, graph: nx.DiGraph, text: str) -> Set[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Set[str]",
            "docstring": "Identify single points of failure in causal chain\n\nHarmonic Front 3 - Enhancement 2: Contextual Failure Point Detection\nExpands risk_pattern to explicitly include localized contextual factors from rubrics:\n- restricciones territoriales\n- patrones culturales machistas\n- limitación normativa\n\nFor D6-Q5 (Enfoque Diferencial/Restricciones): Excelente requires ≥3 distinct\ncontextual factors correctly mapped to nodes, satisfying enfoque_diferencial\nand analisis_contextual criteria.",
            "is_public": true,
            "lineno": 3102,
            "invocation_pattern": "causalinferencesetup_instance.identify_failure_points()"
          }
        ]
      },
      {
        "name": "ReportingEngine",
        "docstring": "Generate visualizations and reports",
        "base_classes": [],
        "is_public": true,
        "lineno": 3201,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ConfigLoader, output_dir: Path) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ConfigLoader",
                "default": null
              },
              {
                "name": "output_dir",
                "annotation": "Path",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 3204,
            "invocation_pattern": "reportingengine_instance.__init__()"
          },
          {
            "name": "generate_causal_diagram",
            "decorator": null,
            "signature": "generate_causal_diagram(self, graph: nx.DiGraph, policy_code: str) -> Path",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Path",
            "docstring": "Generate causal diagram visualization",
            "is_public": true,
            "lineno": 3210,
            "invocation_pattern": "reportingengine_instance.generate_causal_diagram()"
          },
          {
            "name": "generate_accountability_matrix",
            "decorator": null,
            "signature": "generate_accountability_matrix(self, graph: nx.DiGraph, policy_code: str) -> Path",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Path",
            "docstring": "Generate accountability matrix in Markdown",
            "is_public": true,
            "lineno": 3297,
            "invocation_pattern": "reportingengine_instance.generate_accountability_matrix()"
          },
          {
            "name": "generate_confidence_report",
            "decorator": null,
            "signature": "generate_confidence_report(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph, causal_chains: List[CausalLink], audit_results: Dict[str, AuditResult], financial_auditor: FinancialAuditor, sequence_warnings: List[str], policy_code: str) -> Path",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "causal_chains",
                "annotation": "List[CausalLink]",
                "default": null
              },
              {
                "name": "audit_results",
                "annotation": "Dict[str, AuditResult]",
                "default": null
              },
              {
                "name": "financial_auditor",
                "annotation": "FinancialAuditor",
                "default": null
              },
              {
                "name": "sequence_warnings",
                "annotation": "List[str]",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Path",
            "docstring": "Generate extraction confidence report",
            "is_public": true,
            "lineno": 3356,
            "invocation_pattern": "reportingengine_instance.generate_confidence_report()"
          },
          {
            "name": "_calculate_quality_score",
            "decorator": null,
            "signature": "_calculate_quality_score(self, traceability: float, financial: float, logic: float, ea: float) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "traceability",
                "annotation": "float",
                "default": null
              },
              {
                "name": "financial",
                "annotation": "float",
                "default": null
              },
              {
                "name": "logic",
                "annotation": "float",
                "default": null
              },
              {
                "name": "ea",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate overall quality score (0-100)",
            "is_public": false,
            "lineno": 3446,
            "invocation_pattern": "reportingengine_instance._calculate_quality_score()"
          },
          {
            "name": "generate_causal_model_json",
            "decorator": null,
            "signature": "generate_causal_model_json(self, graph: nx.DiGraph, nodes: Dict[str, MetaNode], policy_code: str) -> Path",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Path",
            "docstring": "Generate structured JSON export of causal model",
            "is_public": true,
            "lineno": 3456,
            "invocation_pattern": "reportingengine_instance.generate_causal_model_json()"
          }
        ]
      },
      {
        "name": "CDAFFramework",
        "docstring": "Main orchestrator for the CDAF pipeline",
        "base_classes": [],
        "is_public": true,
        "lineno": 3505,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config_path: Path, output_dir: Path, log_level: str = 'INFO') -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config_path",
                "annotation": "Path",
                "default": null
              },
              {
                "name": "output_dir",
                "annotation": "Path",
                "default": null
              },
              {
                "name": "log_level",
                "annotation": "str",
                "default": "'INFO'"
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 3508,
            "invocation_pattern": "cdafframework_instance.__init__()"
          },
          {
            "name": "process_document",
            "decorator": null,
            "signature": "process_document(self, pdf_path: Path, policy_code: str) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pdf_path",
                "annotation": "Path",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Main processing pipeline",
            "is_public": true,
            "lineno": 3579,
            "invocation_pattern": "cdafframework_instance.process_document()"
          },
          {
            "name": "_extract_feedback_from_audit",
            "decorator": null,
            "signature": "_extract_feedback_from_audit(self, inferred_mechanisms: Dict[str, Dict[str, Any]], counterfactual_audit: Dict[str, Any], audit_results: Dict[str, AuditResult]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "inferred_mechanisms",
                "annotation": "Dict[str, Dict[str, Any]]",
                "default": null
              },
              {
                "name": "counterfactual_audit",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "audit_results",
                "annotation": "Dict[str, AuditResult]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Extract feedback data from audit results for self-reflective prior updating\n\nThis implements the frontier paradigm of learning from audit results\nto improve future inference accuracy.\n\nHARMONIC FRONT 4 ENHANCEMENT:\n- Reduces mechanism_type_priors for mechanisms with implementation_failure flags\n- Tracks necessity/sufficiency test failures\n- Penalizes \"miracle\" mechanisms that fail counterfactual tests",
            "is_public": false,
            "lineno": 3690,
            "invocation_pattern": "cdafframework_instance._extract_feedback_from_audit()"
          },
          {
            "name": "_validate_dnp_compliance",
            "decorator": null,
            "signature": "_validate_dnp_compliance(self, nodes: Dict[str, MetaNode], graph: nx.DiGraph, policy_code: str) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, MetaNode]",
                "default": null
              },
              {
                "name": "graph",
                "annotation": "nx.DiGraph",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Validate DNP compliance for all nodes/projects\nGenerates DNP compliance report",
            "is_public": false,
            "lineno": 3788,
            "invocation_pattern": "cdafframework_instance._validate_dnp_compliance()"
          },
          {
            "name": "_generate_dnp_report",
            "decorator": null,
            "signature": "_generate_dnp_report(self, dnp_results: List[Dict], policy_code: str) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dnp_results",
                "annotation": "List[Dict]",
                "default": null
              },
              {
                "name": "policy_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Generate comprehensive DNP compliance report",
            "is_public": false,
            "lineno": 3864,
            "invocation_pattern": "cdafframework_instance._generate_dnp_report()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "main",
        "signature": "main() -> int",
        "parameters": [],
        "return_type": "int",
        "docstring": "CLI entry point",
        "is_public": true,
        "lineno": 3973
      }
    ]
  },
  "emebedding_policy": {
    "module_name": "emebedding_policy",
    "docstring": "State-of-the-Art Semantic Embedding System for Colombian Municipal Development Plans\n====================================================================================\nSpecialized framework for P-D-Q canonical notation system with:\n- Advanced semantic chunking with hierarchical document structure preservation\n- Bayesian uncertainty quantification for numerical policy analysis\n- Graph-based multi-hop reasoning across document sections\n- Cross-encoder reranking optimized for Spanish policy documents\n- Causal inference framework for policy intervention assessment\n- Zero-shot classification aligned with Colombian policy taxonomy\n\nArchitecture: Modular, type-safe, production-ready\nTarget: Municipal Development Plans (PDM) - Colombia\nCompliance: P#-D#-Q# canonical notation system",
    "classes": [
      {
        "name": "PolicyDomain",
        "docstring": "Colombian PDM policy areas (P1-P10) per Decálogo.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 47,
        "methods": []
      },
      {
        "name": "AnalyticalDimension",
        "docstring": "Analytical dimensions (D1-D6) per canonical notation.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 62,
        "methods": []
      },
      {
        "name": "PDQIdentifier",
        "docstring": "Canonical P-D-Q identifier structure.",
        "base_classes": [
          "TypedDict"
        ],
        "is_public": true,
        "lineno": 73,
        "methods": []
      },
      {
        "name": "SemanticChunk",
        "docstring": "Structured semantic chunk with metadata.",
        "base_classes": [
          "TypedDict"
        ],
        "is_public": true,
        "lineno": 83,
        "methods": []
      },
      {
        "name": "BayesianEvaluation",
        "docstring": "Bayesian uncertainty-aware evaluation result.",
        "base_classes": [
          "TypedDict"
        ],
        "is_public": true,
        "lineno": 95,
        "methods": []
      },
      {
        "name": "EmbeddingProtocol",
        "docstring": "Protocol for embedding models.",
        "base_classes": [
          "Protocol"
        ],
        "is_public": true,
        "lineno": 105,
        "methods": [
          {
            "name": "encode",
            "decorator": null,
            "signature": "encode(self, texts: list[str], batch_size: int = 32, normalize: bool = True) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "texts",
                "annotation": "list[str]",
                "default": null
              },
              {
                "name": "batch_size",
                "annotation": "int",
                "default": "32"
              },
              {
                "name": "normalize",
                "annotation": "bool",
                "default": "True"
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": null,
            "is_public": true,
            "lineno": 108,
            "invocation_pattern": "embeddingprotocol_instance.encode()"
          }
        ]
      },
      {
        "name": "ChunkingConfig",
        "docstring": "Configuration for semantic chunking optimized for PDM documents.",
        "base_classes": [],
        "is_public": true,
        "lineno": 119,
        "methods": []
      },
      {
        "name": "AdvancedSemanticChunker",
        "docstring": "State-of-the-art semantic chunking for Colombian policy documents.\n\nImplements:\n- Recursive character splitting with semantic boundary preservation\n- Table structure detection and preservation\n- List and enumeration recognition\n- Hierarchical section awareness (P-D-Q structure)\n- Token-aware splitting (not just character-based)",
        "base_classes": [],
        "is_public": true,
        "lineno": 131,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ChunkingConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ChunkingConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 154,
            "invocation_pattern": "advancedsemanticchunker_instance.__init__()"
          },
          {
            "name": "chunk_document",
            "decorator": null,
            "signature": "chunk_document(self, text: str, document_metadata: dict[str, Any]) -> list[SemanticChunk]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "document_metadata",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[SemanticChunk]",
            "docstring": "Chunk document with advanced semantic awareness.\n\nReturns chunks with preserved structure and P-D-Q context.",
            "is_public": true,
            "lineno": 158,
            "invocation_pattern": "advancedsemanticchunker_instance.chunk_document()"
          },
          {
            "name": "_normalize_text",
            "decorator": null,
            "signature": "_normalize_text(self, text: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Normalize text while preserving structure.",
            "is_public": false,
            "lineno": 226,
            "invocation_pattern": "advancedsemanticchunker_instance._normalize_text()"
          },
          {
            "name": "_recursive_split",
            "decorator": null,
            "signature": "_recursive_split(self, text: str, target_size: int, overlap: int) -> list[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "target_size",
                "annotation": "int",
                "default": null
              },
              {
                "name": "overlap",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "list[str]",
            "docstring": "Recursive character splitting with semantic boundary respect.\n\nPriority: Paragraph > Sentence > Word > Character",
            "is_public": false,
            "lineno": 233,
            "invocation_pattern": "advancedsemanticchunker_instance._recursive_split()"
          },
          {
            "name": "_find_sentence_boundary",
            "decorator": null,
            "signature": "_find_sentence_boundary(self, text: str, start: int, end: int) -> int | None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "start",
                "annotation": "int",
                "default": null
              },
              {
                "name": "end",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "int | None",
            "docstring": "Find sentence boundary using Spanish punctuation rules.",
            "is_public": false,
            "lineno": 275,
            "invocation_pattern": "advancedsemanticchunker_instance._find_sentence_boundary()"
          },
          {
            "name": "_extract_sections",
            "decorator": null,
            "signature": "_extract_sections(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Extract document sections with hierarchical structure.",
            "is_public": false,
            "lineno": 286,
            "invocation_pattern": "advancedsemanticchunker_instance._extract_sections()"
          },
          {
            "name": "_extract_tables",
            "decorator": null,
            "signature": "_extract_tables(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Identify table regions in document.",
            "is_public": false,
            "lineno": 302,
            "invocation_pattern": "advancedsemanticchunker_instance._extract_tables()"
          },
          {
            "name": "_extract_lists",
            "decorator": null,
            "signature": "_extract_lists(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Identify list structures.",
            "is_public": false,
            "lineno": 316,
            "invocation_pattern": "advancedsemanticchunker_instance._extract_lists()"
          },
          {
            "name": "_infer_pdq_context",
            "decorator": null,
            "signature": "_infer_pdq_context(self, chunk_text: str) -> PDQIdentifier | None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunk_text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "PDQIdentifier | None",
            "docstring": "Infer P-D-Q context from chunk content.\n\nUses heuristics based on Colombian policy vocabulary.",
            "is_public": false,
            "lineno": 323,
            "invocation_pattern": "advancedsemanticchunker_instance._infer_pdq_context()"
          },
          {
            "name": "_contains_table",
            "decorator": null,
            "signature": "_contains_table(self, chunk_text: str, tables: list[dict[str, Any]]) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunk_text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Check if chunk contains table markers.",
            "is_public": false,
            "lineno": 384,
            "invocation_pattern": "advancedsemanticchunker_instance._contains_table()"
          },
          {
            "name": "_contains_list",
            "decorator": null,
            "signature": "_contains_list(self, chunk_text: str, lists: list[dict[str, Any]]) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunk_text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "lists",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Check if chunk contains list structures.",
            "is_public": false,
            "lineno": 393,
            "invocation_pattern": "advancedsemanticchunker_instance._contains_list()"
          },
          {
            "name": "_find_section",
            "decorator": null,
            "signature": "_find_section(self, chunk_text: str, sections: list[dict[str, Any]]) -> str | None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunk_text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "sections",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "str | None",
            "docstring": "Find section title for chunk.",
            "is_public": false,
            "lineno": 397,
            "invocation_pattern": "advancedsemanticchunker_instance._find_section()"
          }
        ]
      },
      {
        "name": "BayesianNumericalAnalyzer",
        "docstring": "Bayesian framework for uncertainty-aware numerical policy analysis.\n\nImplements:\n- Beta-Binomial conjugate prior for proportions\n- Normal-Normal conjugate prior for continuous metrics\n- Bayesian hypothesis testing for policy comparisons\n- Credible interval estimation\n- Evidence strength quantification (Bayes factors)",
        "base_classes": [],
        "is_public": true,
        "lineno": 413,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, prior_strength: float = 1.0)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "prior_strength",
                "annotation": "float",
                "default": "1.0"
              }
            ],
            "return_type": null,
            "docstring": "Initialize Bayesian analyzer.\n\nArgs:\n    prior_strength: Prior belief strength (1.0 = weak, 10.0 = strong)",
            "is_public": false,
            "lineno": 425,
            "invocation_pattern": "bayesiannumericalanalyzer_instance.__init__()"
          },
          {
            "name": "evaluate_policy_metric",
            "decorator": null,
            "signature": "evaluate_policy_metric(self, observed_values: list[float], n_posterior_samples: int = 10000) -> BayesianEvaluation",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observed_values",
                "annotation": "list[float]",
                "default": null
              },
              {
                "name": "n_posterior_samples",
                "annotation": "int",
                "default": "10000"
              }
            ],
            "return_type": "BayesianEvaluation",
            "docstring": "Bayesian evaluation of policy metric with uncertainty quantification.\n\nReturns posterior distribution, credible intervals, and evidence strength.",
            "is_public": true,
            "lineno": 436,
            "invocation_pattern": "bayesiannumericalanalyzer_instance.evaluate_policy_metric()"
          },
          {
            "name": "_beta_binomial_posterior",
            "decorator": null,
            "signature": "_beta_binomial_posterior(self, observations: NDArray[np.float32], n_samples: int) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observations",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "n_samples",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Beta-Binomial conjugate posterior for proportion metrics.\n\nPrior: Beta(α, β)\nLikelihood: Binomial\nPosterior: Beta(α + successes, β + failures)",
            "is_public": false,
            "lineno": 485,
            "invocation_pattern": "bayesiannumericalanalyzer_instance._beta_binomial_posterior()"
          },
          {
            "name": "_normal_normal_posterior",
            "decorator": null,
            "signature": "_normal_normal_posterior(self, observations: NDArray[np.float32], n_samples: int) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observations",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "n_samples",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Normal-Normal conjugate posterior for continuous metrics.\n\nPrior: Normal(μ₀, σ₀²)\nLikelihood: Normal(μ, σ²)\nPosterior: Normal(μ_post, σ_post²)",
            "is_public": false,
            "lineno": 512,
            "invocation_pattern": "bayesiannumericalanalyzer_instance._normal_normal_posterior()"
          },
          {
            "name": "_classify_evidence_strength",
            "decorator": null,
            "signature": "_classify_evidence_strength(self, credible_interval_width: float) -> Literal['weak', 'moderate', 'strong', 'very_strong']",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "credible_interval_width",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Literal['weak', 'moderate', 'strong', 'very_strong']",
            "docstring": "Classify evidence strength based on posterior uncertainty.",
            "is_public": false,
            "lineno": 545,
            "invocation_pattern": "bayesiannumericalanalyzer_instance._classify_evidence_strength()"
          },
          {
            "name": "_compute_coherence",
            "decorator": null,
            "signature": "_compute_coherence(self, observations: NDArray[np.float32]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "observations",
                "annotation": "NDArray[np.float32]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Compute numerical coherence (consistency) score.\n\nUses coefficient of variation and statistical tests.",
            "is_public": false,
            "lineno": 558,
            "invocation_pattern": "bayesiannumericalanalyzer_instance._compute_coherence()"
          },
          {
            "name": "_null_evaluation",
            "decorator": null,
            "signature": "_null_evaluation(self) -> BayesianEvaluation",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "BayesianEvaluation",
            "docstring": "Return null evaluation when no data available.",
            "is_public": false,
            "lineno": 581,
            "invocation_pattern": "bayesiannumericalanalyzer_instance._null_evaluation()"
          },
          {
            "name": "compare_policies",
            "decorator": null,
            "signature": "compare_policies(self, policy_a_values: list[float], policy_b_values: list[float]) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "policy_a_values",
                "annotation": "list[float]",
                "default": null
              },
              {
                "name": "policy_b_values",
                "annotation": "list[float]",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Bayesian comparison of two policy metrics.\n\nReturns probability that A > B and Bayes factor.",
            "is_public": true,
            "lineno": 591,
            "invocation_pattern": "bayesiannumericalanalyzer_instance.compare_policies()"
          }
        ]
      },
      {
        "name": "PolicyCrossEncoderReranker",
        "docstring": "Cross-encoder reranking optimized for Spanish policy documents.\n\nUses transformer-based cross-attention for precise relevance scoring.\nSuperior to bi-encoder + cosine similarity for final ranking.",
        "base_classes": [],
        "is_public": true,
        "lineno": 647,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, model_name: str = DEFAULT_CROSS_ENCODER_MODEL, max_length: int = 512, retry_handler = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "model_name",
                "annotation": "str",
                "default": "DEFAULT_CROSS_ENCODER_MODEL"
              },
              {
                "name": "max_length",
                "annotation": "int",
                "default": "512"
              },
              {
                "name": "retry_handler",
                "annotation": null,
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": "Initialize cross-encoder reranker.\n\nArgs:\n    model_name: HuggingFace model name (multilingual preferred)\n    max_length: Maximum sequence length for cross-encoder\n    retry_handler: Optional RetryHandler for model loading",
            "is_public": false,
            "lineno": 655,
            "invocation_pattern": "policycrossencoderreranker_instance.__init__()"
          },
          {
            "name": "rerank",
            "decorator": null,
            "signature": "rerank(self, query: str, candidates: list[SemanticChunk], top_k: int = 10, min_score: float = 0.0) -> list[tuple[SemanticChunk, float]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "query",
                "annotation": "str",
                "default": null
              },
              {
                "name": "candidates",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "top_k",
                "annotation": "int",
                "default": "10"
              },
              {
                "name": "min_score",
                "annotation": "float",
                "default": "0.0"
              }
            ],
            "return_type": "list[tuple[SemanticChunk, float]]",
            "docstring": "Rerank candidates using cross-encoder attention.\n\nReturns top-k chunks with relevance scores.",
            "is_public": true,
            "lineno": 694,
            "invocation_pattern": "policycrossencoderreranker_instance.rerank()"
          }
        ]
      },
      {
        "name": "PolicyEmbeddingConfig",
        "docstring": "Configuration for policy embedding system.",
        "base_classes": [],
        "is_public": true,
        "lineno": 739,
        "methods": []
      },
      {
        "name": "PolicyAnalysisEmbedder",
        "docstring": "Production-ready embedding system for Colombian PDM analysis.\n\nImplements complete pipeline:\n1. Advanced semantic chunking with P-D-Q awareness\n2. Multilingual embedding (Spanish-optimized)\n3. Bi-encoder retrieval + cross-encoder reranking\n4. Bayesian numerical analysis with uncertainty quantification\n5. MMR-based diversification\n\nThread-safe, production-grade, fully typed.",
        "base_classes": [],
        "is_public": true,
        "lineno": 763,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: PolicyEmbeddingConfig, retry_handler = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "PolicyEmbeddingConfig",
                "default": null
              },
              {
                "name": "retry_handler",
                "annotation": null,
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 777,
            "invocation_pattern": "policyanalysisembedder_instance.__init__()"
          },
          {
            "name": "process_document",
            "decorator": null,
            "signature": "process_document(self, document_text: str, document_metadata: dict[str, Any]) -> list[SemanticChunk]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "document_text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "document_metadata",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[SemanticChunk]",
            "docstring": "Process complete PDM document into semantic chunks with embeddings.\n\nArgs:\n    document_text: Full document text\n    document_metadata: Metadata including doc_id, municipality, year\n\nReturns:\n    List of semantic chunks with embeddings and P-D-Q context",
            "is_public": true,
            "lineno": 826,
            "invocation_pattern": "policyanalysisembedder_instance.process_document()"
          },
          {
            "name": "semantic_search",
            "decorator": null,
            "signature": "semantic_search(self, query: str, document_chunks: list[SemanticChunk], pdq_filter: PDQIdentifier | None = None, use_reranking: bool = True) -> list[tuple[SemanticChunk, float]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "query",
                "annotation": "str",
                "default": null
              },
              {
                "name": "document_chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "pdq_filter",
                "annotation": "PDQIdentifier | None",
                "default": "None"
              },
              {
                "name": "use_reranking",
                "annotation": "bool",
                "default": "True"
              }
            ],
            "return_type": "list[tuple[SemanticChunk, float]]",
            "docstring": "Advanced semantic search with P-D-Q filtering and reranking.\n\nPipeline:\n1. Bi-encoder retrieval (fast, approximate)\n2. P-D-Q filtering (if specified)\n3. Cross-encoder reranking (precise)\n4. MMR diversification\n\nArgs:\n    query: Search query\n    document_chunks: Pool of chunks to search\n    pdq_filter: Optional P-D-Q context filter\n    use_reranking: Enable cross-encoder reranking\n\nReturns:\n    Ranked list of (chunk, score) tuples",
            "is_public": true,
            "lineno": 874,
            "invocation_pattern": "policyanalysisembedder_instance.semantic_search()"
          },
          {
            "name": "evaluate_policy_numerical_consistency",
            "decorator": null,
            "signature": "evaluate_policy_numerical_consistency(self, chunks: list[SemanticChunk], pdq_context: PDQIdentifier) -> BayesianEvaluation",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "pdq_context",
                "annotation": "PDQIdentifier",
                "default": null
              }
            ],
            "return_type": "BayesianEvaluation",
            "docstring": "Bayesian evaluation of numerical consistency for policy metric.\n\nExtracts numerical values from chunks matching P-D-Q context,\nperforms rigorous statistical analysis with uncertainty quantification.\n\nArgs:\n    chunks: Document chunks to analyze\n    pdq_context: P-D-Q context to filter relevant chunks\n\nReturns:\n    Bayesian evaluation with credible intervals and evidence strength",
            "is_public": true,
            "lineno": 944,
            "invocation_pattern": "policyanalysisembedder_instance.evaluate_policy_numerical_consistency()"
          },
          {
            "name": "compare_policy_interventions",
            "decorator": null,
            "signature": "compare_policy_interventions(self, intervention_a_chunks: list[SemanticChunk], intervention_b_chunks: list[SemanticChunk], pdq_context: PDQIdentifier) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "intervention_a_chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "intervention_b_chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "pdq_context",
                "annotation": "PDQIdentifier",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Bayesian comparison of two policy interventions.\n\nReturns probability and evidence for superiority.",
            "is_public": true,
            "lineno": 996,
            "invocation_pattern": "policyanalysisembedder_instance.compare_policy_interventions()"
          },
          {
            "name": "generate_pdq_report",
            "decorator": null,
            "signature": "generate_pdq_report(self, document_chunks: list[SemanticChunk], target_pdq: PDQIdentifier) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "document_chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "target_pdq",
                "annotation": "PDQIdentifier",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Generate comprehensive analytical report for P-D-Q question.\n\nCombines semantic search, numerical analysis, and evidence synthesis.",
            "is_public": true,
            "lineno": 1016,
            "invocation_pattern": "policyanalysisembedder_instance.generate_pdq_report()"
          },
          {
            "name": "_embed_texts",
            "decorator": null,
            "signature": "_embed_texts(self, texts: list[str]) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "texts",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Generate embeddings with caching and retry logic.",
            "is_public": false,
            "lineno": 1070,
            "invocation_pattern": "policyanalysisembedder_instance._embed_texts()"
          },
          {
            "name": "_filter_by_pdq",
            "decorator": null,
            "signature": "_filter_by_pdq(self, chunks: list[SemanticChunk], pdq_filter: PDQIdentifier) -> list[SemanticChunk]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              },
              {
                "name": "pdq_filter",
                "annotation": "PDQIdentifier",
                "default": null
              }
            ],
            "return_type": "list[SemanticChunk]",
            "docstring": "Filter chunks by P-D-Q context.",
            "is_public": false,
            "lineno": 1127,
            "invocation_pattern": "policyanalysisembedder_instance._filter_by_pdq()"
          },
          {
            "name": "_apply_mmr",
            "decorator": null,
            "signature": "_apply_mmr(self, ranked_results: list[tuple[SemanticChunk, float]]) -> list[tuple[SemanticChunk, float]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "ranked_results",
                "annotation": "list[tuple[SemanticChunk, float]]",
                "default": null
              }
            ],
            "return_type": "list[tuple[SemanticChunk, float]]",
            "docstring": "Apply Maximal Marginal Relevance for diversification.\n\nBalances relevance with diversity to avoid redundant results.",
            "is_public": false,
            "lineno": 1139,
            "invocation_pattern": "policyanalysisembedder_instance._apply_mmr()"
          },
          {
            "name": "_extract_numerical_values",
            "decorator": null,
            "signature": "_extract_numerical_values(self, chunks: list[SemanticChunk]) -> list[float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunks",
                "annotation": "list[SemanticChunk]",
                "default": null
              }
            ],
            "return_type": "list[float]",
            "docstring": "Extract numerical values from chunks using advanced patterns.\n\nFocuses on policy-relevant metrics: percentages, amounts, counts.",
            "is_public": false,
            "lineno": 1193,
            "invocation_pattern": "policyanalysisembedder_instance._extract_numerical_values()"
          },
          {
            "name": "_generate_query_from_pdq",
            "decorator": null,
            "signature": "_generate_query_from_pdq(self, pdq: PDQIdentifier) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pdq",
                "annotation": "PDQIdentifier",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Generate search query from P-D-Q identifier.",
            "is_public": false,
            "lineno": 1248,
            "invocation_pattern": "policyanalysisembedder_instance._generate_query_from_pdq()"
          },
          {
            "name": "_compute_overall_confidence",
            "decorator": null,
            "signature": "_compute_overall_confidence(self, relevant_chunks: list[tuple[SemanticChunk, float]], numerical_eval: BayesianEvaluation) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "relevant_chunks",
                "annotation": "list[tuple[SemanticChunk, float]]",
                "default": null
              },
              {
                "name": "numerical_eval",
                "annotation": "BayesianEvaluation",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Compute overall confidence score combining semantic and numerical evidence.\n\nConsiders:\n- Number of relevant chunks\n- Semantic relevance scores\n- Numerical evidence strength\n- Statistical coherence",
            "is_public": false,
            "lineno": 1256,
            "invocation_pattern": "policyanalysisembedder_instance._compute_overall_confidence()"
          },
          {
            "name": "_cached_similarity",
            "decorator": null,
            "signature": "_cached_similarity(self, text_hash1: str, text_hash2: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text_hash1",
                "annotation": "str",
                "default": null
              },
              {
                "name": "text_hash2",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Cached similarity computation for performance.\nAssumes embeddings are cached in self._embedding_cache using text_hash as key.",
            "is_public": false,
            "lineno": 1297,
            "invocation_pattern": "policyanalysisembedder_instance._cached_similarity()"
          },
          {
            "name": "get_diagnostics",
            "decorator": null,
            "signature": "get_diagnostics(self) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Get system diagnostics and performance metrics.",
            "is_public": true,
            "lineno": 1305,
            "invocation_pattern": "policyanalysisembedder_instance.get_diagnostics()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "create_policy_embedder",
        "signature": "create_policy_embedder(model_tier: Literal['fast', 'balanced', 'accurate'] = 'balanced') -> PolicyAnalysisEmbedder",
        "parameters": [
          {
            "name": "model_tier",
            "annotation": "Literal['fast', 'balanced', 'accurate']",
            "default": "'balanced'"
          }
        ],
        "return_type": "PolicyAnalysisEmbedder",
        "docstring": "Factory function for creating production-ready policy embedder.\n\nArgs:\n    model_tier: Performance/accuracy trade-off\n        - \"fast\": Lightweight, low latency\n        - \"balanced\": Good performance/accuracy balance (default)\n        - \"accurate\": Maximum accuracy, higher latency\n\nReturns:\n    Configured PolicyAnalysisEmbedder instance",
        "is_public": true,
        "lineno": 1329
      },
      {
        "name": "example_pdm_analysis",
        "signature": "example_pdm_analysis()",
        "parameters": [],
        "return_type": null,
        "docstring": "Complete example: analyzing Colombian Municipal Development Plan.",
        "is_public": true,
        "lineno": 1387
      }
    ]
  },
  "policy_processor": {
    "module_name": "policy_processor",
    "docstring": "Causal Framework Policy Plan Processor - Industrial Grade\n=========================================================\n\nA mathematically rigorous, production-hardened system for extracting and\nvalidating causal evidence from Colombian local development plans against\nthe DECALOGO framework's six-dimensional evaluation criteria.\n\nArchitecture:\n    - Bayesian evidence accumulation for probabilistic confidence scoring\n    - Multi-scale text segmentation with coherence-preserving boundaries\n    - Differential privacy-aware pattern matching for reproducibility\n    - Entropy-based relevance ranking with TF-IDF normalization\n    - Graph-theoretic dependency validation for causal chain integrity\n\nVersion: 3.0.0 | ISO 9001:2015 Compliant\nAuthor: Policy Analytics Research Unit\nLicense: Proprietary",
    "classes": [
      {
        "name": "CausalDimension",
        "docstring": "Six-dimensional causal framework taxonomy aligned with DECALOGO.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 51,
        "methods": []
      },
      {
        "name": "ProcessorConfig",
        "docstring": "Immutable configuration for policy plan processing.",
        "base_classes": [],
        "is_public": true,
        "lineno": 215,
        "methods": [
          {
            "name": "from_legacy",
            "decorator": "classmethod",
            "signature": "from_legacy(cls, **kwargs: Any) -> 'ProcessorConfig'",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "**kwargs",
                "annotation": "Any",
                "default": null
              }
            ],
            "return_type": "'ProcessorConfig'",
            "docstring": "Construct configuration from legacy parameter names.",
            "is_public": true,
            "lineno": 239,
            "invocation_pattern": "ProcessorConfig.from_legacy()"
          },
          {
            "name": "validate",
            "decorator": null,
            "signature": "validate(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Validate configuration parameters.",
            "is_public": true,
            "lineno": 247,
            "invocation_pattern": "processorconfig_instance.validate()"
          }
        ]
      },
      {
        "name": "BayesianEvidenceScorer",
        "docstring": "Bayesian evidence accumulation with entropy-weighted confidence scoring.\n\nImplements a modified Dempster-Shafer framework for multi-evidence fusion\nwith automatic calibration against ground-truth policy corpora.",
        "base_classes": [],
        "is_public": true,
        "lineno": 261,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, prior_confidence: float = 0.5, entropy_weight: float = 0.3)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "prior_confidence",
                "annotation": "float",
                "default": "0.5"
              },
              {
                "name": "entropy_weight",
                "annotation": "float",
                "default": "0.3"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 269,
            "invocation_pattern": "bayesianevidencescorer_instance.__init__()"
          },
          {
            "name": "compute_evidence_score",
            "decorator": null,
            "signature": "compute_evidence_score(self, matches: List[str], total_corpus_size: int, pattern_specificity: float = 0.8) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "matches",
                "annotation": "List[str]",
                "default": null
              },
              {
                "name": "total_corpus_size",
                "annotation": "int",
                "default": null
              },
              {
                "name": "pattern_specificity",
                "annotation": "float",
                "default": "0.8"
              }
            ],
            "return_type": "float",
            "docstring": "Compute probabilistic confidence score for evidence matches.\n\nArgs:\n    matches: List of matched text segments\n    total_corpus_size: Total document size in characters\n    pattern_specificity: Pattern discrimination power [0,1]\n\nReturns:\n    Calibrated confidence score in [0, 1]",
            "is_public": true,
            "lineno": 274,
            "invocation_pattern": "bayesianevidencescorer_instance.compute_evidence_score()"
          },
          {
            "name": "_calculate_shannon_entropy",
            "decorator": "staticmethod",
            "signature": "_calculate_shannon_entropy(values: np.ndarray) -> float",
            "parameters": [
              {
                "name": "values",
                "annotation": "np.ndarray",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate normalized Shannon entropy for value distribution.",
            "is_public": false,
            "lineno": 315,
            "invocation_pattern": "BayesianEvidenceScorer._calculate_shannon_entropy()"
          }
        ]
      },
      {
        "name": "PolicyTextProcessor",
        "docstring": "Industrial-grade text processing with multi-scale segmentation and\ncoherence-preserving normalization for policy document analysis.",
        "base_classes": [],
        "is_public": true,
        "lineno": 335,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ProcessorConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ProcessorConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 341,
            "invocation_pattern": "policytextprocessor_instance.__init__()"
          },
          {
            "name": "normalize_unicode",
            "decorator": null,
            "signature": "normalize_unicode(self, text: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Apply canonical Unicode normalization (NFC/NFKC).",
            "is_public": true,
            "lineno": 348,
            "invocation_pattern": "policytextprocessor_instance.normalize_unicode()"
          },
          {
            "name": "segment_into_sentences",
            "decorator": null,
            "signature": "segment_into_sentences(self, text: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Segment text into sentences with context-aware boundary detection.\nHandles abbreviations, numerical lists, and Colombian naming conventions.",
            "is_public": true,
            "lineno": 352,
            "invocation_pattern": "policytextprocessor_instance.segment_into_sentences()"
          },
          {
            "name": "extract_contextual_window",
            "decorator": null,
            "signature": "extract_contextual_window(self, text: str, match_position: int, window_size: int) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "match_position",
                "annotation": "int",
                "default": null
              },
              {
                "name": "window_size",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Extract semantically coherent context window around a match.",
            "is_public": true,
            "lineno": 378,
            "invocation_pattern": "policytextprocessor_instance.extract_contextual_window()"
          },
          {
            "name": "compile_pattern",
            "decorator": null,
            "signature": "compile_pattern(self, pattern_str: str) -> re.Pattern",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pattern_str",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "re.Pattern",
            "docstring": "Cache and compile regex patterns for performance.",
            "is_public": true,
            "lineno": 394,
            "invocation_pattern": "policytextprocessor_instance.compile_pattern()"
          }
        ]
      },
      {
        "name": "EvidenceBundle",
        "docstring": "Structured evidence container with provenance and confidence metadata.",
        "base_classes": [],
        "is_public": true,
        "lineno": 404,
        "methods": [
          {
            "name": "to_dict",
            "decorator": null,
            "signature": "to_dict(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": null,
            "is_public": true,
            "lineno": 414,
            "invocation_pattern": "evidencebundle_instance.to_dict()"
          }
        ]
      },
      {
        "name": "IndustrialPolicyProcessor",
        "docstring": "State-of-the-art policy plan processor implementing rigorous causal\nframework analysis with Bayesian evidence scoring and graph-theoretic\nvalidation for Colombian local development plans.",
        "base_classes": [],
        "is_public": true,
        "lineno": 425,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: Optional[ProcessorConfig] = None, questionnaire_path: Optional[Path] = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "Optional[ProcessorConfig]",
                "default": "None"
              },
              {
                "name": "questionnaire_path",
                "annotation": "Optional[Path]",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 434,
            "invocation_pattern": "industrialpolicyprocessor_instance.__init__()"
          },
          {
            "name": "_load_questionnaire",
            "decorator": null,
            "signature": "_load_questionnaire(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Load and validate DECALOGO questionnaire structure.",
            "is_public": false,
            "lineno": 462,
            "invocation_pattern": "industrialpolicyprocessor_instance._load_questionnaire()"
          },
          {
            "name": "_compile_pattern_registry",
            "decorator": null,
            "signature": "_compile_pattern_registry(self) -> Dict[CausalDimension, Dict[str, List[re.Pattern]]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[CausalDimension, Dict[str, List[re.Pattern]]]",
            "docstring": "Compile all causal patterns into efficient regex objects.",
            "is_public": false,
            "lineno": 476,
            "invocation_pattern": "industrialpolicyprocessor_instance._compile_pattern_registry()"
          },
          {
            "name": "_build_point_patterns",
            "decorator": null,
            "signature": "_build_point_patterns(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Extract and compile patterns for each policy point from questionnaire.",
            "is_public": false,
            "lineno": 487,
            "invocation_pattern": "industrialpolicyprocessor_instance._build_point_patterns()"
          },
          {
            "name": "process",
            "decorator": null,
            "signature": "process(self, raw_text: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "raw_text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Execute comprehensive policy plan analysis.\n\nArgs:\n    raw_text: Sanitized policy document text\n\nReturns:\n    Structured analysis results with evidence bundles and confidence scores",
            "is_public": true,
            "lineno": 516,
            "invocation_pattern": "industrialpolicyprocessor_instance.process()"
          },
          {
            "name": "_match_patterns_in_sentences",
            "decorator": null,
            "signature": "_match_patterns_in_sentences(self, compiled_patterns: List, relevant_sentences: List[str]) -> Tuple[List[str], List[int]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "compiled_patterns",
                "annotation": "List",
                "default": null
              },
              {
                "name": "relevant_sentences",
                "annotation": "List[str]",
                "default": null
              }
            ],
            "return_type": "Tuple[List[str], List[int]]",
            "docstring": "Execute pattern matching across relevant sentences and collect matches with positions.\n\nArgs:\n    compiled_patterns: List of compiled regex patterns to match\n    relevant_sentences: Filtered sentences to search within\n    \nReturns:\n    Tuple of (matched_strings, match_positions)",
            "is_public": false,
            "lineno": 569,
            "invocation_pattern": "industrialpolicyprocessor_instance._match_patterns_in_sentences()"
          },
          {
            "name": "_compute_evidence_confidence",
            "decorator": null,
            "signature": "_compute_evidence_confidence(self, matches: List[str], text_length: int, pattern_specificity: float) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "matches",
                "annotation": "List[str]",
                "default": null
              },
              {
                "name": "text_length",
                "annotation": "int",
                "default": null
              },
              {
                "name": "pattern_specificity",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate confidence score for evidence based on pattern matches and contextual factors.\n\nArgs:\n    matches: List of matched pattern strings\n    text_length: Total length of the document text\n    pattern_specificity: Specificity coefficient for pattern weighting\n    \nReturns:\n    Computed confidence score",
            "is_public": false,
            "lineno": 593,
            "invocation_pattern": "industrialpolicyprocessor_instance._compute_evidence_confidence()"
          },
          {
            "name": "_construct_evidence_bundle",
            "decorator": null,
            "signature": "_construct_evidence_bundle(self, dimension: CausalDimension, category: str, matches: List[str], positions: List[int], confidence: float) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dimension",
                "annotation": "CausalDimension",
                "default": null
              },
              {
                "name": "category",
                "annotation": "str",
                "default": null
              },
              {
                "name": "matches",
                "annotation": "List[str]",
                "default": null
              },
              {
                "name": "positions",
                "annotation": "List[int]",
                "default": null
              },
              {
                "name": "confidence",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Assemble evidence bundle from matched patterns and computed confidence.\n\nArgs:\n    dimension: Causal dimension classification\n    category: Specific category within dimension\n    matches: List of matched pattern strings\n    positions: List of match positions in text\n    confidence: Computed confidence score\n    \nReturns:\n    Serialized evidence bundle dictionary",
            "is_public": false,
            "lineno": 612,
            "invocation_pattern": "industrialpolicyprocessor_instance._construct_evidence_bundle()"
          },
          {
            "name": "_extract_point_evidence",
            "decorator": null,
            "signature": "_extract_point_evidence(self, text: str, sentences: List[str], point_code: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "List[str]",
                "default": null
              },
              {
                "name": "point_code",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Extract evidence for a specific policy point across all dimensions.",
            "is_public": false,
            "lineno": 642,
            "invocation_pattern": "industrialpolicyprocessor_instance._extract_point_evidence()"
          },
          {
            "name": "_analyze_causal_dimensions",
            "decorator": null,
            "signature": "_analyze_causal_dimensions(self, text: str, sentences: List[str]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "List[str]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Perform global analysis of causal dimensions across entire document.",
            "is_public": false,
            "lineno": 681,
            "invocation_pattern": "industrialpolicyprocessor_instance._analyze_causal_dimensions()"
          },
          {
            "name": "_extract_metadata",
            "decorator": "staticmethod",
            "signature": "_extract_metadata(text: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Extract key metadata from policy document header.",
            "is_public": false,
            "lineno": 721,
            "invocation_pattern": "IndustrialPolicyProcessor._extract_metadata()"
          },
          {
            "name": "_compute_avg_confidence",
            "decorator": "staticmethod",
            "signature": "_compute_avg_confidence(dimension_analysis: Dict[str, Any]) -> float",
            "parameters": [
              {
                "name": "dimension_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate average confidence across all dimensions.",
            "is_public": false,
            "lineno": 752,
            "invocation_pattern": "IndustrialPolicyProcessor._compute_avg_confidence()"
          },
          {
            "name": "_empty_result",
            "decorator": null,
            "signature": "_empty_result(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Return structure for failed/empty processing.",
            "is_public": false,
            "lineno": 761,
            "invocation_pattern": "industrialpolicyprocessor_instance._empty_result()"
          },
          {
            "name": "export_results",
            "decorator": null,
            "signature": "export_results(self, results: Dict[str, Any], output_path: Union[str, Path]) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "Union[str, Path]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Export analysis results to JSON with formatted output.",
            "is_public": true,
            "lineno": 777,
            "invocation_pattern": "industrialpolicyprocessor_instance.export_results()"
          }
        ]
      },
      {
        "name": "AdvancedTextSanitizer",
        "docstring": "Sophisticated text sanitization preserving semantic structure and\ncritical policy elements with differential privacy guarantees.",
        "base_classes": [],
        "is_public": true,
        "lineno": 794,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: ProcessorConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "ProcessorConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 800,
            "invocation_pattern": "advancedtextsanitizer_instance.__init__()"
          },
          {
            "name": "sanitize",
            "decorator": null,
            "signature": "sanitize(self, raw_text: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "raw_text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Execute comprehensive text sanitization pipeline.\n\nPipeline stages:\n1. Unicode normalization (NFC)\n2. Structure element protection\n3. Whitespace normalization\n4. Special character handling\n5. Encoding validation",
            "is_public": true,
            "lineno": 809,
            "invocation_pattern": "advancedtextsanitizer_instance.sanitize()"
          },
          {
            "name": "_protect_structure",
            "decorator": null,
            "signature": "_protect_structure(self, text: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Mark structural elements for protection during sanitization.",
            "is_public": false,
            "lineno": 846,
            "invocation_pattern": "advancedtextsanitizer_instance._protect_structure()"
          },
          {
            "name": "_restore_structure",
            "decorator": null,
            "signature": "_restore_structure(self, text: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Remove protection markers after sanitization.",
            "is_public": false,
            "lineno": 877,
            "invocation_pattern": "advancedtextsanitizer_instance._restore_structure()"
          }
        ]
      },
      {
        "name": "ResilientFileHandler",
        "docstring": "Production-grade file I/O with automatic encoding detection,\nretry logic, and comprehensive error classification.",
        "base_classes": [],
        "is_public": true,
        "lineno": 890,
        "methods": [
          {
            "name": "read_text",
            "decorator": "classmethod",
            "signature": "read_text(cls, file_path: Union[str, Path]) -> str",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "file_path",
                "annotation": "Union[str, Path]",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Read text file with automatic encoding detection and fallback cascade.\n\nArgs:\n    file_path: Path to input file\n\nReturns:\n    Decoded text content\n\nRaises:\n    IOError: If file cannot be read with any supported encoding",
            "is_public": true,
            "lineno": 899,
            "invocation_pattern": "ResilientFileHandler.read_text()"
          },
          {
            "name": "write_text",
            "decorator": "classmethod",
            "signature": "write_text(cls, content: str, file_path: Union[str, Path]) -> None",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "content",
                "annotation": "str",
                "default": null
              },
              {
                "name": "file_path",
                "annotation": "Union[str, Path]",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Write text content with UTF-8 encoding and directory creation.",
            "is_public": true,
            "lineno": 933,
            "invocation_pattern": "ResilientFileHandler.write_text()"
          }
        ]
      },
      {
        "name": "PolicyAnalysisPipeline",
        "docstring": "End-to-end orchestrator for Colombian local development plan analysis\nimplementing the complete DECALOGO causal framework evaluation workflow.",
        "base_classes": [],
        "is_public": true,
        "lineno": 948,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: Optional[ProcessorConfig] = None, questionnaire_path: Optional[Path] = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "Optional[ProcessorConfig]",
                "default": "None"
              },
              {
                "name": "questionnaire_path",
                "annotation": "Optional[Path]",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 954,
            "invocation_pattern": "policyanalysispipeline_instance.__init__()"
          },
          {
            "name": "analyze_file",
            "decorator": null,
            "signature": "analyze_file(self, input_path: Union[str, Path], output_path: Optional[Union[str, Path]] = None) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "input_path",
                "annotation": "Union[str, Path]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "Optional[Union[str, Path]]",
                "default": "None"
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Execute complete analysis pipeline on a policy document file.\n\nArgs:\n    input_path: Path to input policy document (text format)\n    output_path: Optional path for JSON results export\n\nReturns:\n    Complete analysis results dictionary",
            "is_public": true,
            "lineno": 964,
            "invocation_pattern": "policyanalysispipeline_instance.analyze_file()"
          },
          {
            "name": "analyze_text",
            "decorator": null,
            "signature": "analyze_text(self, raw_text: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "raw_text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Execute analysis pipeline on raw text input.\n\nArgs:\n    raw_text: Raw policy document text\n\nReturns:\n    Complete analysis results dictionary",
            "is_public": true,
            "lineno": 1007,
            "invocation_pattern": "policyanalysispipeline_instance.analyze_text()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "create_policy_processor",
        "signature": "create_policy_processor(preserve_structure: bool = True, enable_semantic_tagging: bool = True, confidence_threshold: float = 0.65, **kwargs: Any) -> PolicyAnalysisPipeline",
        "parameters": [
          {
            "name": "preserve_structure",
            "annotation": "bool",
            "default": "True"
          },
          {
            "name": "enable_semantic_tagging",
            "annotation": "bool",
            "default": "True"
          },
          {
            "name": "confidence_threshold",
            "annotation": "float",
            "default": "0.65"
          },
          {
            "name": "**kwargs",
            "annotation": "Any",
            "default": null
          }
        ],
        "return_type": "PolicyAnalysisPipeline",
        "docstring": "Factory function for creating policy analysis pipeline with legacy support.\n\nArgs:\n    preserve_structure: Enable document structure preservation\n    enable_semantic_tagging: Enable semantic element tagging\n    confidence_threshold: Minimum confidence threshold for evidence\n    **kwargs: Additional configuration parameters\n\nReturns:\n    Configured PolicyAnalysisPipeline instance",
        "is_public": true,
        "lineno": 1025
      },
      {
        "name": "main",
        "signature": "main()",
        "parameters": [],
        "return_type": null,
        "docstring": "Command-line interface for policy plan analysis.",
        "is_public": true,
        "lineno": 1056
      }
    ]
  },
  "policy_segmenter": {
    "module_name": "policy_segmenter",
    "docstring": "State-of-the-Art Document Segmenter for Colombian Municipal Development Plans\n============================================================================\nSpecialized segmentation with:\n- Hierarchical structure-aware chunking (P-D-Q canonical notation)\n- Sentence-Transformers with multilingual SOTA embeddings\n- Bayesian uncertainty-aware boundary scoring\n- Dynamic programming with policy-calibrated cost function\n- Table/list/section preservation\n- Zero placeholders, production-ready\n\nCompliance: P#-D#-Q# canonical notation system\nArchitecture: Immutable, deterministic, type-safe",
    "classes": [
      {
        "name": "SectionType",
        "docstring": "Section types aligned with DECALOGO dimensions (D1-D6).",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 47,
        "methods": []
      },
      {
        "name": "SegmentMetrics",
        "docstring": "Immutable metrics for document segment.",
        "base_classes": [],
        "is_public": true,
        "lineno": 90,
        "methods": []
      },
      {
        "name": "SegmentationStats",
        "docstring": "Statistics for segmentation quality assessment.",
        "base_classes": [],
        "is_public": true,
        "lineno": 106,
        "methods": []
      },
      {
        "name": "SegmenterConfig",
        "docstring": "Immutable configuration for document segmenter.",
        "base_classes": [],
        "is_public": true,
        "lineno": 122,
        "methods": []
      },
      {
        "name": "SpanishSentenceSegmenter",
        "docstring": "Advanced sentence segmentation for Spanish policy documents.\n\nHandles:\n- Abbreviations (Dr., Sra., etc.)\n- Decimal numbers (3.5, 1.234,56)\n- Enumerations (1., 2., a., b.)\n- Complex punctuation (parentheses, quotes)",
        "base_classes": [],
        "is_public": true,
        "lineno": 141,
        "methods": [
          {
            "name": "segment",
            "decorator": "classmethod",
            "signature": "segment(cls, text: str) -> list[str]",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[str]",
            "docstring": "Segment text into sentences with Spanish-specific rules.",
            "is_public": true,
            "lineno": 171,
            "invocation_pattern": "SpanishSentenceSegmenter.segment()"
          },
          {
            "name": "_protect_abbreviations",
            "decorator": "classmethod",
            "signature": "_protect_abbreviations(cls, text: str) -> str",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Replace abbreviation periods with placeholder.",
            "is_public": false,
            "lineno": 192,
            "invocation_pattern": "SpanishSentenceSegmenter._protect_abbreviations()"
          },
          {
            "name": "_restore_abbreviations",
            "decorator": "classmethod",
            "signature": "_restore_abbreviations(cls, text: str) -> str",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Restore original abbreviation periods.",
            "is_public": false,
            "lineno": 205,
            "invocation_pattern": "SpanishSentenceSegmenter._restore_abbreviations()"
          }
        ]
      },
      {
        "name": "BayesianBoundaryScorer",
        "docstring": "Bayesian uncertainty-aware boundary scoring using semantic embeddings.\n\nImplements:\n- Sentence embedding with SOTA multilingual model\n- Cosine distance as boundary strength indicator\n- Beta posterior for boundary confidence\n- Structural features (punctuation, length, section markers)",
        "base_classes": [],
        "is_public": true,
        "lineno": 215,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, model_name: str)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "model_name",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 226,
            "invocation_pattern": "bayesianboundaryscorer_instance.__init__()"
          },
          {
            "name": "score_boundaries",
            "decorator": null,
            "signature": "score_boundaries(self, sentences: list[str]) -> tuple[NDArray[np.float32], NDArray[np.float32]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "tuple[NDArray[np.float32], NDArray[np.float32]]",
            "docstring": "Score potential boundaries between sentences.\n\nReturns:\n    boundary_scores: Array of length N-1 (boundary after each sentence)\n    confidence_intervals: Array of shape (N-1, 2) with [lower, upper] bounds",
            "is_public": true,
            "lineno": 244,
            "invocation_pattern": "bayesianboundaryscorer_instance.score_boundaries()"
          },
          {
            "name": "_semantic_boundary_scores",
            "decorator": null,
            "signature": "_semantic_boundary_scores(self, embeddings: NDArray[np.float32]) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "embeddings",
                "annotation": "NDArray[np.float32]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Compute semantic boundary scores from embeddings.\n\nHigh cosine distance = strong boundary (topic shift)",
            "is_public": false,
            "lineno": 279,
            "invocation_pattern": "bayesianboundaryscorer_instance._semantic_boundary_scores()"
          },
          {
            "name": "_structural_boundary_scores",
            "decorator": null,
            "signature": "_structural_boundary_scores(self, sentences: list[str]) -> NDArray[np.float32]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float32]",
            "docstring": "Compute structural boundary scores based on:\n- Punctuation (period vs question/exclamation)\n- Sentence length (longer = more complete)\n- Section markers (headers, enumerations)",
            "is_public": false,
            "lineno": 301,
            "invocation_pattern": "bayesianboundaryscorer_instance._structural_boundary_scores()"
          },
          {
            "name": "_bayesian_posterior",
            "decorator": null,
            "signature": "_bayesian_posterior(self, semantic_scores: NDArray[np.float32], structural_scores: NDArray[np.float32]) -> tuple[NDArray[np.float32], NDArray[np.float32]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "semantic_scores",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "structural_scores",
                "annotation": "NDArray[np.float32]",
                "default": null
              }
            ],
            "return_type": "tuple[NDArray[np.float32], NDArray[np.float32]]",
            "docstring": "Compute Bayesian posterior distribution for boundary probabilities.\n\nUses Beta-Binomial conjugate prior model:\n- Prior: Beta(α, β)\n- Likelihood: Combined semantic + structural evidence\n- Posterior: Beta(α + evidence, β + (1 - evidence))\n\nReturns:\n    posterior_means: Expected boundary probabilities\n    credible_intervals: 95% credible intervals [lower, upper]",
            "is_public": false,
            "lineno": 343,
            "invocation_pattern": "bayesianboundaryscorer_instance._bayesian_posterior()"
          }
        ]
      },
      {
        "name": "StructureDetector",
        "docstring": "Detect and preserve document structures (tables, lists, sections).",
        "base_classes": [],
        "is_public": true,
        "lineno": 390,
        "methods": [
          {
            "name": "detect_structures",
            "decorator": "classmethod",
            "signature": "detect_structures(cls, text: str) -> dict[str, Any]",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Detect structural elements in text.\n\nReturns dict with:\n- has_table: bool\n- has_list: bool\n- has_numbers: bool\n- section_headers: list of positions\n- table_regions: list of (start, end) tuples\n- list_regions: list of (start, end) tuples",
            "is_public": true,
            "lineno": 421,
            "invocation_pattern": "StructureDetector.detect_structures()"
          },
          {
            "name": "_find_table_regions",
            "decorator": "classmethod",
            "signature": "_find_table_regions(cls, text: str) -> list[tuple[int, int]]",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[tuple[int, int]]",
            "docstring": "Heuristically identify table regions (marker + ~500 chars).",
            "is_public": false,
            "lineno": 446,
            "invocation_pattern": "StructureDetector._find_table_regions()"
          },
          {
            "name": "_find_list_regions",
            "decorator": "classmethod",
            "signature": "_find_list_regions(cls, text: str) -> list[tuple[int, int]]",
            "parameters": [
              {
                "name": "cls",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[tuple[int, int]]",
            "docstring": "Identify contiguous list regions.",
            "is_public": false,
            "lineno": 456,
            "invocation_pattern": "StructureDetector._find_list_regions()"
          }
        ]
      },
      {
        "name": "DPSegmentOptimizer",
        "docstring": "Dynamic programming optimizer for segment boundary placement.\n\nCalibrated for Colombian PDM documents:\n- Weights derived from empirical analysis of 50+ PDM documents\n- Considers P-D-Q structure requirements\n- Balances length, sentence count, and boundary strength",
        "base_classes": [],
        "is_public": true,
        "lineno": 483,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SegmenterConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SegmenterConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 498,
            "invocation_pattern": "dpsegmentoptimizer_instance.__init__()"
          },
          {
            "name": "optimize_cuts",
            "decorator": null,
            "signature": "optimize_cuts(self, sentences: list[str], boundary_scores: NDArray[np.float32]) -> tuple[list[int], float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              },
              {
                "name": "boundary_scores",
                "annotation": "NDArray[np.float32]",
                "default": null
              }
            ],
            "return_type": "tuple[list[int], float]",
            "docstring": "Find optimal segment boundaries using dynamic programming.\n\nReturns:\n    cut_indices: List of sentence indices where segments end\n    global_confidence: Average boundary confidence",
            "is_public": true,
            "lineno": 506,
            "invocation_pattern": "dpsegmentoptimizer_instance.optimize_cuts()"
          },
          {
            "name": "_cumulative_chars",
            "decorator": null,
            "signature": "_cumulative_chars(self, sentences: list[str]) -> list[int]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "list[int]",
            "docstring": "Compute cumulative character counts (with spaces between sentences).",
            "is_public": false,
            "lineno": 577,
            "invocation_pattern": "dpsegmentoptimizer_instance._cumulative_chars()"
          },
          {
            "name": "_segment_cost",
            "decorator": null,
            "signature": "_segment_cost(self, start_idx: int, end_idx: int, cumul_chars: list[int], boundary_scores: NDArray[np.float32], sentences: list[str]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "start_idx",
                "annotation": "int",
                "default": null
              },
              {
                "name": "end_idx",
                "annotation": "int",
                "default": null
              },
              {
                "name": "cumul_chars",
                "annotation": "list[int]",
                "default": null
              },
              {
                "name": "boundary_scores",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Compute cost for segment [start_idx, end_idx].\n\nLower cost = better segment.",
            "is_public": false,
            "lineno": 584,
            "invocation_pattern": "dpsegmentoptimizer_instance._segment_cost()"
          }
        ]
      },
      {
        "name": "DocumentSegmenter",
        "docstring": "Production-ready document segmenter for Colombian PDM analysis.\n\nFeatures:\n- Advanced Spanish sentence segmentation\n- Bayesian boundary scoring with uncertainty quantification\n- Structure-aware chunking (preserves tables, lists, sections)\n- DP optimization calibrated for PDM documents\n- P-D-Q canonical notation awareness",
        "base_classes": [],
        "is_public": true,
        "lineno": 639,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SegmenterConfig | None = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SegmenterConfig | None",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 651,
            "invocation_pattern": "documentsegmenter_instance.__init__()"
          },
          {
            "name": "segment",
            "decorator": null,
            "signature": "segment(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Segment document into optimal chunks.\n\nReturns list of segment dicts with:\n- text: str\n- metrics: SegmentMetrics\n- segment_type: str",
            "is_public": true,
            "lineno": 666,
            "invocation_pattern": "documentsegmenter_instance.segment()"
          },
          {
            "name": "get_segmentation_report",
            "decorator": null,
            "signature": "get_segmentation_report(self) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Get comprehensive segmentation quality report.",
            "is_public": true,
            "lineno": 719,
            "invocation_pattern": "documentsegmenter_instance.get_segmentation_report()"
          },
          {
            "name": "_normalize_text",
            "decorator": "staticmethod",
            "signature": "_normalize_text(text: str) -> str",
            "parameters": [
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Normalize text preserving structure.",
            "is_public": false,
            "lineno": 750,
            "invocation_pattern": "DocumentSegmenter._normalize_text()"
          },
          {
            "name": "_materialize_segments",
            "decorator": null,
            "signature": "_materialize_segments(self, sentences: list[str], cut_indices: list[int], boundary_scores: NDArray[np.float32], structures: dict[str, Any]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sentences",
                "annotation": "list[str]",
                "default": null
              },
              {
                "name": "cut_indices",
                "annotation": "list[int]",
                "default": null
              },
              {
                "name": "boundary_scores",
                "annotation": "NDArray[np.float32]",
                "default": null
              },
              {
                "name": "structures",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Convert cut indices into actual segment dicts.",
            "is_public": false,
            "lineno": 757,
            "invocation_pattern": "documentsegmenter_instance._materialize_segments()"
          },
          {
            "name": "_compute_metrics",
            "decorator": null,
            "signature": "_compute_metrics(self, text: str, sentence_count: int, boundary_confidence: float, structures: dict[str, Any]) -> SegmentMetrics",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "sentence_count",
                "annotation": "int",
                "default": null
              },
              {
                "name": "boundary_confidence",
                "annotation": "float",
                "default": null
              },
              {
                "name": "structures",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "SegmentMetrics",
            "docstring": "Compute comprehensive metrics for segment.",
            "is_public": false,
            "lineno": 800,
            "invocation_pattern": "documentsegmenter_instance._compute_metrics()"
          },
          {
            "name": "_infer_section_type",
            "decorator": "staticmethod",
            "signature": "_infer_section_type(text: str) -> str",
            "parameters": [
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Infer section type from content (heuristic).",
            "is_public": false,
            "lineno": 837,
            "invocation_pattern": "DocumentSegmenter._infer_section_type()"
          },
          {
            "name": "_fallback_segmentation",
            "decorator": null,
            "signature": "_fallback_segmentation(self, text: str, structures: dict[str, Any]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "structures",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Fallback segmentation for edge cases (very short documents).",
            "is_public": false,
            "lineno": 868,
            "invocation_pattern": "documentsegmenter_instance._fallback_segmentation()"
          },
          {
            "name": "_post_process_segments",
            "decorator": null,
            "signature": "_post_process_segments(self, segments: list[dict[str, Any]]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Post-process segments to enforce constraints.\n\n- Merge segments that are too small\n- Split segments that are too large\n- Ensure minimum segment count",
            "is_public": false,
            "lineno": 936,
            "invocation_pattern": "documentsegmenter_instance._post_process_segments()"
          },
          {
            "name": "_merge_tiny_segments",
            "decorator": null,
            "signature": "_merge_tiny_segments(self, segments: list[dict[str, Any]]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Merge segments that are below minimum threshold.",
            "is_public": false,
            "lineno": 961,
            "invocation_pattern": "documentsegmenter_instance._merge_tiny_segments()"
          },
          {
            "name": "_split_oversized_segments",
            "decorator": null,
            "signature": "_split_oversized_segments(self, segments: list[dict[str, Any]]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Split segments that exceed maximum threshold.",
            "is_public": false,
            "lineno": 1013,
            "invocation_pattern": "documentsegmenter_instance._split_oversized_segments()"
          },
          {
            "name": "_force_split_segment",
            "decorator": null,
            "signature": "_force_split_segment(self, segment: dict[str, Any]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segment",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Force split a segment (used for oversized segments).",
            "is_public": false,
            "lineno": 1029,
            "invocation_pattern": "documentsegmenter_instance._force_split_segment()"
          },
          {
            "name": "_split_by_words",
            "decorator": null,
            "signature": "_split_by_words(self, text: str, original_segment: dict[str, Any]) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "original_segment",
                "annotation": "dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Split text by words when sentence splitting fails.",
            "is_public": false,
            "lineno": 1094,
            "invocation_pattern": "documentsegmenter_instance._split_by_words()"
          },
          {
            "name": "_compute_stats",
            "decorator": null,
            "signature": "_compute_stats(self, segments: list[dict[str, Any]]) -> SegmentationStats",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "SegmentationStats",
            "docstring": "Compute comprehensive statistics for segmentation quality.",
            "is_public": false,
            "lineno": 1155,
            "invocation_pattern": "documentsegmenter_instance._compute_stats()"
          },
          {
            "name": "_compute_char_distribution",
            "decorator": "staticmethod",
            "signature": "_compute_char_distribution(lengths: list[int]) -> dict[str, int]",
            "parameters": [
              {
                "name": "lengths",
                "annotation": "list[int]",
                "default": null
              }
            ],
            "return_type": "dict[str, int]",
            "docstring": "Compute character length distribution buckets.",
            "is_public": false,
            "lineno": 1202,
            "invocation_pattern": "DocumentSegmenter._compute_char_distribution()"
          },
          {
            "name": "_compute_sentence_distribution",
            "decorator": "staticmethod",
            "signature": "_compute_sentence_distribution(counts: list[int]) -> dict[str, int]",
            "parameters": [
              {
                "name": "counts",
                "annotation": "list[int]",
                "default": null
              }
            ],
            "return_type": "dict[str, int]",
            "docstring": "Compute sentence count distribution buckets.",
            "is_public": false,
            "lineno": 1227,
            "invocation_pattern": "DocumentSegmenter._compute_sentence_distribution()"
          },
          {
            "name": "_compute_consistency_score",
            "decorator": null,
            "signature": "_compute_consistency_score(self, lengths: list[int]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "lengths",
                "annotation": "list[int]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Compute consistency score based on length variance.\n\nLower variance = higher consistency.",
            "is_public": false,
            "lineno": 1251,
            "invocation_pattern": "documentsegmenter_instance._compute_consistency_score()"
          },
          {
            "name": "_compute_adherence_score",
            "decorator": "staticmethod",
            "signature": "_compute_adherence_score(in_range: int, with_target: int, total: int) -> float",
            "parameters": [
              {
                "name": "in_range",
                "annotation": "int",
                "default": null
              },
              {
                "name": "with_target",
                "annotation": "int",
                "default": null
              },
              {
                "name": "total",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Compute target adherence score.\n\nMeasures how well segments meet target criteria.",
            "is_public": false,
            "lineno": 1272,
            "invocation_pattern": "DocumentSegmenter._compute_adherence_score()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "create_segmenter",
        "signature": "create_segmenter(target_char_min: int = 700, target_char_max: int = 900, target_sentences: int = 3, model: str = 'paraphrase-multilingual-mpnet-base-v2') -> DocumentSegmenter",
        "parameters": [
          {
            "name": "target_char_min",
            "annotation": "int",
            "default": "700"
          },
          {
            "name": "target_char_max",
            "annotation": "int",
            "default": "900"
          },
          {
            "name": "target_sentences",
            "annotation": "int",
            "default": "3"
          },
          {
            "name": "model",
            "annotation": "str",
            "default": "'paraphrase-multilingual-mpnet-base-v2'"
          }
        ],
        "return_type": "DocumentSegmenter",
        "docstring": "Factory function for creating production-ready segmenter.\n\nArgs:\n    target_char_min: Minimum target characters per segment\n    target_char_max: Maximum target characters per segment\n    target_sentences: Target number of sentences per segment\n    model: Embedding model name (from sentence-transformers)\n\nReturns:\n    Configured DocumentSegmenter instance",
        "is_public": true,
        "lineno": 1297
      },
      {
        "name": "example_pdm_segmentation",
        "signature": "example_pdm_segmentation()",
        "parameters": [],
        "return_type": null,
        "docstring": "Complete example: segmenting Colombian PDM document.",
        "is_public": true,
        "lineno": 1332
      }
    ]
  },
  "semantic_chunking_policy": {
    "module_name": "semantic_chunking_policy",
    "docstring": "Causal Policy Analysis Framework - State-of-the-Art Edition\nSpecialized for Colombian Municipal Development Plans (PDM)\nScientific Foundation:\n- Semantic: BGE-M3 (2024, SOTA multilingual dense retrieval)\n- Chunking: Semantic-aware with policy structure recognition\n- Math: Information-theoretic Bayesian evidence accumulation\n- Causal: Directed Acyclic Graph inference with interventional calculus\nDesign Principles:\n- Zero placeholders, zero heuristics\n- Calibrated to Colombian PDM structure (Ley 152/1994, DNP guidelines)\n- Production-grade error handling\n- Lazy loading for resource efficiency",
    "classes": [
      {
        "name": "CausalDimension",
        "docstring": "Marco Lógico standard (DNP Colombia)",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 57,
        "methods": []
      },
      {
        "name": "PDMSection",
        "docstring": "Enumerates the typical sections of a Colombian Municipal Development Plan (PDM),\nas defined by Ley 152/1994. Each member represents a key structural component\nof the PDM document, facilitating semantic analysis and policy structure recognition.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 67,
        "methods": []
      },
      {
        "name": "SemanticConfig",
        "docstring": "Configuración calibrada para análisis de políticas públicas",
        "base_classes": [],
        "is_public": true,
        "lineno": 82,
        "methods": []
      },
      {
        "name": "SemanticProcessor",
        "docstring": "State-of-the-art semantic processing with:\n- BGE-M3 embeddings (2024 SOTA)\n- Policy-aware chunking (respects PDM structure)\n- Efficient batching with FP16",
        "base_classes": [],
        "is_public": true,
        "lineno": 101,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SemanticConfig)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SemanticConfig",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 109,
            "invocation_pattern": "semanticprocessor_instance.__init__()"
          },
          {
            "name": "_lazy_load",
            "decorator": null,
            "signature": "_lazy_load(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 115,
            "invocation_pattern": "semanticprocessor_instance._lazy_load()"
          },
          {
            "name": "chunk_text",
            "decorator": null,
            "signature": "chunk_text(self, text: str, preserve_structure: bool = True) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "preserve_structure",
                "annotation": "bool",
                "default": "True"
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Policy-aware semantic chunking:\n- Respects section boundaries (numbered lists, headers)\n- Maintains table integrity\n- Preserves reference links between text segments",
            "is_public": true,
            "lineno": 142,
            "invocation_pattern": "semanticprocessor_instance.chunk_text()"
          },
          {
            "name": "_detect_pdm_structure",
            "decorator": null,
            "signature": "_detect_pdm_structure(self, text: str) -> list[dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "list[dict[str, Any]]",
            "docstring": "Detect PDM sections using Colombian policy document patterns",
            "is_public": false,
            "lineno": 180,
            "invocation_pattern": "semanticprocessor_instance._detect_pdm_structure()"
          },
          {
            "name": "_detect_table",
            "decorator": null,
            "signature": "_detect_table(self, text: str) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detect if chunk contains tabular data",
            "is_public": false,
            "lineno": 207,
            "invocation_pattern": "semanticprocessor_instance._detect_table()"
          },
          {
            "name": "_detect_numerical_data",
            "decorator": null,
            "signature": "_detect_numerical_data(self, text: str) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detect if chunk contains significant numerical/financial data",
            "is_public": false,
            "lineno": 214,
            "invocation_pattern": "semanticprocessor_instance._detect_numerical_data()"
          },
          {
            "name": "_embed_batch",
            "decorator": null,
            "signature": "_embed_batch(self, texts: list[str]) -> list[NDArray[np.floating[Any]]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "texts",
                "annotation": "list[str]",
                "default": null
              }
            ],
            "return_type": "list[NDArray[np.floating[Any]]]",
            "docstring": "Batch embedding with BGE-M3",
            "is_public": false,
            "lineno": 224,
            "invocation_pattern": "semanticprocessor_instance._embed_batch()"
          },
          {
            "name": "embed_single",
            "decorator": null,
            "signature": "embed_single(self, text: str) -> NDArray[np.floating[Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "NDArray[np.floating[Any]]",
            "docstring": "Single text embedding",
            "is_public": true,
            "lineno": 251,
            "invocation_pattern": "semanticprocessor_instance.embed_single()"
          }
        ]
      },
      {
        "name": "BayesianEvidenceIntegrator",
        "docstring": "Information-theoretic Bayesian evidence accumulation:\n- Dirichlet-Multinomial for multi-hypothesis tracking\n- KL divergence for belief update quantification\n- Entropy-based confidence calibration\n- No simplifications or heuristics",
        "base_classes": [],
        "is_public": true,
        "lineno": 261,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, prior_concentration: float = 0.5)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "prior_concentration",
                "annotation": "float",
                "default": "0.5"
              }
            ],
            "return_type": null,
            "docstring": "Args:\n    prior_concentration: Dirichlet concentration (α).\n        Lower = more uncertain prior (conservative)",
            "is_public": false,
            "lineno": 270,
            "invocation_pattern": "bayesianevidenceintegrator_instance.__init__()"
          },
          {
            "name": "integrate_evidence",
            "decorator": null,
            "signature": "integrate_evidence(self, similarities: NDArray[np.float64], chunk_metadata: list[dict[str, Any]]) -> dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "similarities",
                "annotation": "NDArray[np.float64]",
                "default": null
              },
              {
                "name": "chunk_metadata",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "dict[str, float]",
            "docstring": "Bayesian evidence integration with information-theoretic rigor:\n1. Map similarities to likelihood space via monotonic transform\n2. Weight evidence by chunk reliability (position, structure, content type)\n3. Update Dirichlet posterior\n4. Compute information gain (KL divergence from prior)\n5. Calculate calibrated confidence with epistemic uncertainty",
            "is_public": true,
            "lineno": 285,
            "invocation_pattern": "bayesianevidenceintegrator_instance.integrate_evidence()"
          },
          {
            "name": "_similarity_to_probability",
            "decorator": null,
            "signature": "_similarity_to_probability(self, sims: NDArray[np.float64]) -> NDArray[np.float64]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "sims",
                "annotation": "NDArray[np.float64]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float64]",
            "docstring": "Calibrated transform from cosine similarity [-1,1] to probability [0,1]\nUsing sigmoid with empirically derived temperature",
            "is_public": false,
            "lineno": 340,
            "invocation_pattern": "bayesianevidenceintegrator_instance._similarity_to_probability()"
          },
          {
            "name": "_compute_reliability_weights",
            "decorator": null,
            "signature": "_compute_reliability_weights(self, metadata: list[dict[str, Any]]) -> NDArray[np.float64]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "metadata",
                "annotation": "list[dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "NDArray[np.float64]",
            "docstring": "Evidence reliability based on:\n- Position in document (early sections more diagnostic)\n- Content type (tables/numbers more reliable for quantitative claims)\n- Section type (plan sections more reliable than diagnostics)",
            "is_public": false,
            "lineno": 350,
            "invocation_pattern": "bayesianevidenceintegrator_instance._compute_reliability_weights()"
          },
          {
            "name": "_null_evidence",
            "decorator": null,
            "signature": "_null_evidence(self) -> dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[str, float]",
            "docstring": "Return prior state (no evidence)",
            "is_public": false,
            "lineno": 378,
            "invocation_pattern": "bayesianevidenceintegrator_instance._null_evidence()"
          },
          {
            "name": "causal_strength",
            "decorator": null,
            "signature": "causal_strength(self, cause_emb: NDArray[np.floating[Any]], effect_emb: NDArray[np.floating[Any]], context_emb: NDArray[np.floating[Any]]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "cause_emb",
                "annotation": "NDArray[np.floating[Any]]",
                "default": null
              },
              {
                "name": "effect_emb",
                "annotation": "NDArray[np.floating[Any]]",
                "default": null
              },
              {
                "name": "context_emb",
                "annotation": "NDArray[np.floating[Any]]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Causal strength via conditional independence approximation:\nstrength = sim(cause, effect) * [1 - |sim(cause,ctx) - sim(effect,ctx)|]\nIntuition: Strong causal link if cause-effect similar AND\nboth relate similarly to context (conditional independence test proxy)",
            "is_public": true,
            "lineno": 392,
            "invocation_pattern": "bayesianevidenceintegrator_instance.causal_strength()"
          }
        ]
      },
      {
        "name": "PolicyDocumentAnalyzer",
        "docstring": "Colombian Municipal Development Plan Analyzer:\n- BGE-M3 semantic processing\n- Policy-aware chunking (respects PDM structure)\n- Bayesian evidence integration with information theory\n- Causal dimension analysis per Marco Lógico",
        "base_classes": [],
        "is_public": true,
        "lineno": 419,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config: SemanticConfig | None = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config",
                "annotation": "SemanticConfig | None",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 428,
            "invocation_pattern": "policydocumentanalyzer_instance.__init__()"
          },
          {
            "name": "_init_dimension_embeddings",
            "decorator": null,
            "signature": "_init_dimension_embeddings(self) -> dict[CausalDimension, NDArray[np.floating[Any]]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "dict[CausalDimension, NDArray[np.floating[Any]]]",
            "docstring": "Canonical embeddings for Marco Lógico dimensions\nUsing Colombian policy-specific terminology",
            "is_public": false,
            "lineno": 437,
            "invocation_pattern": "policydocumentanalyzer_instance._init_dimension_embeddings()"
          },
          {
            "name": "analyze",
            "decorator": null,
            "signature": "analyze(self, text: str) -> dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "dict[str, Any]",
            "docstring": "Full pipeline: chunking → embedding → dimension analysis → evidence integration",
            "is_public": true,
            "lineno": 473,
            "invocation_pattern": "policydocumentanalyzer_instance.analyze()"
          },
          {
            "name": "_extract_key_excerpts",
            "decorator": null,
            "signature": "_extract_key_excerpts(self, chunks: list[dict[str, Any]], dimension_results: dict[str, dict[str, Any]]) -> dict[str, list[str]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "chunks",
                "annotation": "list[dict[str, Any]]",
                "default": null
              },
              {
                "name": "dimension_results",
                "annotation": "dict[str, dict[str, Any]]",
                "default": null
              }
            ],
            "return_type": "dict[str, list[str]]",
            "docstring": "Extract most relevant text excerpts per dimension",
            "is_public": false,
            "lineno": 518,
            "invocation_pattern": "policydocumentanalyzer_instance._extract_key_excerpts()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "main",
        "signature": "main()",
        "parameters": [],
        "return_type": null,
        "docstring": "Example usage",
        "is_public": true,
        "lineno": 546
      }
    ]
  },
  "teoria_cambio": {
    "module_name": "teoria_cambio",
    "docstring": "Framework Unificado para la Validación Causal de Políticas Públicas\n===================================================================\n\nEste script consolida un conjunto de herramientas de nivel industrial en un\nframework cohesivo, diseñado para la validación rigurosa de teorías de cambio\ny modelos causales (DAGs). Su propósito es servir como el motor de análisis\nestructural y estocástico dentro de un flujo canónico de evaluación de planes\nde desarrollo, garantizando que las políticas públicas no solo sean lógicamente\ncoherentes, sino también estadísticamente robustas.\n\nArquitectura de Vanguardia:\n---------------------------\n1.  **Motor Axiomático de Teoría de Cambio (`TeoriaCambio`):**\n    Valida la adherencia de un modelo a una jerarquía causal predefinida\n    (Insumos → Procesos → Productos → Resultados → Causalidad), reflejando las\n    dimensiones de evaluación (D1-D6) del flujo canónico.\n\n2.  **Validador Estocástico Avanzado (`AdvancedDAGValidator`):**\n    Somete los modelos causales a un escrutinio probabilístico mediante\n    simulaciones Monte Carlo deterministas. Evalúa la aciclicidad, la\n    robustez estructural y el poder estadístico de la teoría.\n\n3.  **Orquestador de Certificación Industrial (`IndustrialGradeValidator`):**\n    Audita el rendimiento y la correctitud de la implementación del motor\n    axiomático, asegurando que la herramienta de validación misma cumple con\n    estándares de producción.\n\n4.  **Interfaz de Línea de Comandos (CLI):**\n    Expone la funcionalidad a través de una CLI robusta, permitiendo su\n    integración en flujos de trabajo automatizados y su uso como herramienta\n    de análisis configurable.\n\nAutor: Sistema de Validación de Planes de Desarrollo\nVersión: 4.0.0 (Refactorizada y Alineada)\nPython: 3.10+",
    "classes": [
      {
        "name": "CategoriaCausal",
        "docstring": "Jerarquía axiomática de categorías causales en una teoría de cambio.\nEl orden numérico impone la secuencia lógica obligatoria.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 89,
        "methods": []
      },
      {
        "name": "GraphType",
        "docstring": "Tipología de grafos para la aplicación de análisis especializados.",
        "base_classes": [
          "Enum"
        ],
        "is_public": true,
        "lineno": 102,
        "methods": []
      },
      {
        "name": "ValidacionResultado",
        "docstring": "Encapsula el resultado de la validación estructural de una teoría de cambio.",
        "base_classes": [],
        "is_public": true,
        "lineno": 112,
        "methods": []
      },
      {
        "name": "ValidationMetric",
        "docstring": "Define una métrica de validación con umbrales y ponderación.",
        "base_classes": [],
        "is_public": true,
        "lineno": 123,
        "methods": []
      },
      {
        "name": "AdvancedGraphNode",
        "docstring": "Nodo de grafo enriquecido con metadatos y rol semántico.",
        "base_classes": [],
        "is_public": true,
        "lineno": 135,
        "methods": [
          {
            "name": "__post_init__",
            "decorator": null,
            "signature": "__post_init__(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Inicializa metadatos por defecto si no son provistos.",
            "is_public": false,
            "lineno": 143,
            "invocation_pattern": "advancedgraphnode_instance.__post_init__()"
          }
        ]
      },
      {
        "name": "MonteCarloAdvancedResult",
        "docstring": "Resultado exhaustivo de una simulación Monte Carlo.\n\nAudit Point 1.1: Deterministic Seeding (RNG)\nField 'reproducible' confirms that seed was deterministically generated\nand results can be reproduced with identical inputs.",
        "base_classes": [],
        "is_public": true,
        "lineno": 150,
        "methods": []
      },
      {
        "name": "TeoriaCambio",
        "docstring": "Motor para la construcción y validación estructural de teorías de cambio.\nValida la coherencia lógica de grafos causales contra un modelo axiomático\nde categorías jerárquicas, crucial para el análisis de políticas públicas.",
        "base_classes": [],
        "is_public": true,
        "lineno": 184,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Inicializa el motor con un sistema de cache optimizado.",
            "is_public": false,
            "lineno": 200,
            "invocation_pattern": "teoriacambio_instance.__init__()"
          },
          {
            "name": "_es_conexion_valida",
            "decorator": "staticmethod",
            "signature": "_es_conexion_valida(origen: CategoriaCausal, destino: CategoriaCausal) -> bool",
            "parameters": [
              {
                "name": "origen",
                "annotation": "CategoriaCausal",
                "default": null
              },
              {
                "name": "destino",
                "annotation": "CategoriaCausal",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Verifica la validez de una conexión causal según la jerarquía estructural.",
            "is_public": false,
            "lineno": 207,
            "invocation_pattern": "TeoriaCambio._es_conexion_valida()"
          },
          {
            "name": "construir_grafo_causal",
            "decorator": null,
            "signature": "construir_grafo_causal(self) -> nx.DiGraph",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "nx.DiGraph",
            "docstring": "Construye y cachea el grafo causal canónico.",
            "is_public": true,
            "lineno": 212,
            "invocation_pattern": "teoriacambio_instance.construir_grafo_causal()"
          },
          {
            "name": "validacion_completa",
            "decorator": null,
            "signature": "validacion_completa(self, grafo: nx.DiGraph) -> ValidacionResultado",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "grafo",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "ValidacionResultado",
            "docstring": "Ejecuta una validación estructural exhaustiva de la teoría de cambio.",
            "is_public": true,
            "lineno": 235,
            "invocation_pattern": "teoriacambio_instance.validacion_completa()"
          },
          {
            "name": "_extraer_categorias",
            "decorator": "staticmethod",
            "signature": "_extraer_categorias(grafo: nx.DiGraph) -> Set[str]",
            "parameters": [
              {
                "name": "grafo",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "Set[str]",
            "docstring": "Extrae el conjunto de categorías presentes en el grafo.",
            "is_public": false,
            "lineno": 251,
            "invocation_pattern": "TeoriaCambio._extraer_categorias()"
          },
          {
            "name": "_validar_orden_causal",
            "decorator": "staticmethod",
            "signature": "_validar_orden_causal(grafo: nx.DiGraph) -> List[Tuple[str, str]]",
            "parameters": [
              {
                "name": "grafo",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "List[Tuple[str, str]]",
            "docstring": "Identifica las aristas que violan el orden causal axiomático.",
            "is_public": false,
            "lineno": 260,
            "invocation_pattern": "TeoriaCambio._validar_orden_causal()"
          },
          {
            "name": "_encontrar_caminos_completos",
            "decorator": "staticmethod",
            "signature": "_encontrar_caminos_completos(grafo: nx.DiGraph) -> List[List[str]]",
            "parameters": [
              {
                "name": "grafo",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "List[List[str]]",
            "docstring": "Encuentra todos los caminos simples desde nodos INSUMOS a CAUSALIDAD.",
            "is_public": false,
            "lineno": 271,
            "invocation_pattern": "TeoriaCambio._encontrar_caminos_completos()"
          },
          {
            "name": "_generar_sugerencias_internas",
            "decorator": "staticmethod",
            "signature": "_generar_sugerencias_internas(validacion: ValidacionResultado) -> List[str]",
            "parameters": [
              {
                "name": "validacion",
                "annotation": "ValidacionResultado",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Genera un listado de sugerencias accionables basadas en los resultados.",
            "is_public": false,
            "lineno": 295,
            "invocation_pattern": "TeoriaCambio._generar_sugerencias_internas()"
          }
        ]
      },
      {
        "name": "AdvancedDAGValidator",
        "docstring": "Motor para la validación estocástica y análisis de sensibilidad de DAGs.\nUtiliza simulaciones Monte Carlo para cuantificar la robustez y aciclicidad\nde modelos causales complejos.",
        "base_classes": [],
        "is_public": true,
        "lineno": 354,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, graph_type: GraphType = GraphType.CAUSAL_DAG) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "graph_type",
                "annotation": "GraphType",
                "default": "GraphType.CAUSAL_DAG"
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 361,
            "invocation_pattern": "advanceddagvalidator_instance.__init__()"
          },
          {
            "name": "add_node",
            "decorator": null,
            "signature": "add_node(self, name: str, dependencies: Optional[Set[str]] = None, role: str = 'variable', metadata: Optional[Dict[str, Any]] = None) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "dependencies",
                "annotation": "Optional[Set[str]]",
                "default": "None"
              },
              {
                "name": "role",
                "annotation": "str",
                "default": "'variable'"
              },
              {
                "name": "metadata",
                "annotation": "Optional[Dict[str, Any]]",
                "default": "None"
              }
            ],
            "return_type": "None",
            "docstring": "Agrega un nodo enriquecido al grafo.",
            "is_public": true,
            "lineno": 372,
            "invocation_pattern": "advanceddagvalidator_instance.add_node()"
          },
          {
            "name": "add_edge",
            "decorator": null,
            "signature": "add_edge(self, from_node: str, to_node: str, weight: float = 1.0) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "from_node",
                "annotation": "str",
                "default": null
              },
              {
                "name": "to_node",
                "annotation": "str",
                "default": null
              },
              {
                "name": "weight",
                "annotation": "float",
                "default": "1.0"
              }
            ],
            "return_type": "None",
            "docstring": "Agrega una arista dirigida con peso opcional.",
            "is_public": true,
            "lineno": 384,
            "invocation_pattern": "advanceddagvalidator_instance.add_edge()"
          },
          {
            "name": "_initialize_rng",
            "decorator": null,
            "signature": "_initialize_rng(self, plan_name: str, salt: str = '') -> int",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "plan_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "salt",
                "annotation": "str",
                "default": "''"
              }
            ],
            "return_type": "int",
            "docstring": "Inicializa el generador de números aleatorios con una semilla determinista.\n\nAudit Point 1.1: Deterministic Seeding (RNG)\nInitializes numpy/random RNG with deterministic seed for reproducibility.\nSets reproducible=True in MonteCarloAdvancedResult.\n\nArgs:\n    plan_name: Plan identifier for seed derivation\n    salt: Optional salt for sensitivity analysis\n\nReturns:\n    Generated seed value for audit logging",
            "is_public": false,
            "lineno": 393,
            "invocation_pattern": "advanceddagvalidator_instance._initialize_rng()"
          },
          {
            "name": "_is_acyclic",
            "decorator": "staticmethod",
            "signature": "_is_acyclic(nodes: Dict[str, AdvancedGraphNode]) -> bool",
            "parameters": [
              {
                "name": "nodes",
                "annotation": "Dict[str, AdvancedGraphNode]",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Detección de ciclos mediante el algoritmo de Kahn (ordenación topológica).",
            "is_public": false,
            "lineno": 420,
            "invocation_pattern": "AdvancedDAGValidator._is_acyclic()"
          },
          {
            "name": "_generate_subgraph",
            "decorator": null,
            "signature": "_generate_subgraph(self) -> Dict[str, AdvancedGraphNode]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, AdvancedGraphNode]",
            "docstring": "Genera un subgrafo aleatorio del grafo principal.",
            "is_public": false,
            "lineno": 443,
            "invocation_pattern": "advanceddagvalidator_instance._generate_subgraph()"
          },
          {
            "name": "calculate_acyclicity_pvalue",
            "decorator": null,
            "signature": "calculate_acyclicity_pvalue(self, plan_name: str, iterations: int) -> MonteCarloAdvancedResult",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "plan_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "iterations",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "MonteCarloAdvancedResult",
            "docstring": "Cálculo avanzado de p-value con un marco estadístico completo.",
            "is_public": true,
            "lineno": 463,
            "invocation_pattern": "advanceddagvalidator_instance.calculate_acyclicity_pvalue()"
          },
          {
            "name": "_perform_sensitivity_analysis_internal",
            "decorator": null,
            "signature": "_perform_sensitivity_analysis_internal(self, plan_name: str, base_p_value: float, iterations: int) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "plan_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "base_p_value",
                "annotation": "float",
                "default": null
              },
              {
                "name": "iterations",
                "annotation": "int",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Análisis de sensibilidad interno optimizado para evitar cálculos redundantes.",
            "is_public": false,
            "lineno": 510,
            "invocation_pattern": "advanceddagvalidator_instance._perform_sensitivity_analysis_internal()"
          },
          {
            "name": "_calculate_confidence_interval",
            "decorator": "staticmethod",
            "signature": "_calculate_confidence_interval(s: int, n: int, conf: float) -> Tuple[float, float]",
            "parameters": [
              {
                "name": "s",
                "annotation": "int",
                "default": null
              },
              {
                "name": "n",
                "annotation": "int",
                "default": null
              },
              {
                "name": "conf",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Tuple[float, float]",
            "docstring": "Calcula el intervalo de confianza de Wilson.",
            "is_public": false,
            "lineno": 553,
            "invocation_pattern": "AdvancedDAGValidator._calculate_confidence_interval()"
          },
          {
            "name": "_calculate_statistical_power",
            "decorator": "staticmethod",
            "signature": "_calculate_statistical_power(s: int, n: int, alpha: float = 0.05) -> float",
            "parameters": [
              {
                "name": "s",
                "annotation": "int",
                "default": null
              },
              {
                "name": "n",
                "annotation": "int",
                "default": null
              },
              {
                "name": "alpha",
                "annotation": "float",
                "default": "0.05"
              }
            ],
            "return_type": "float",
            "docstring": "Calcula el poder estadístico a posteriori.",
            "is_public": false,
            "lineno": 567,
            "invocation_pattern": "AdvancedDAGValidator._calculate_statistical_power()"
          },
          {
            "name": "_calculate_bayesian_posterior",
            "decorator": "staticmethod",
            "signature": "_calculate_bayesian_posterior(likelihood: float, prior: float = 0.5) -> float",
            "parameters": [
              {
                "name": "likelihood",
                "annotation": "float",
                "default": null
              },
              {
                "name": "prior",
                "annotation": "float",
                "default": "0.5"
              }
            ],
            "return_type": "float",
            "docstring": "Calcula la probabilidad posterior Bayesiana simple.",
            "is_public": false,
            "lineno": 578,
            "invocation_pattern": "AdvancedDAGValidator._calculate_bayesian_posterior()"
          },
          {
            "name": "_calculate_node_importance",
            "decorator": null,
            "signature": "_calculate_node_importance(self) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Calcula una métrica de importancia para cada nodo.",
            "is_public": false,
            "lineno": 586,
            "invocation_pattern": "advanceddagvalidator_instance._calculate_node_importance()"
          },
          {
            "name": "get_graph_stats",
            "decorator": null,
            "signature": "get_graph_stats(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Obtiene estadísticas estructurales del grafo.",
            "is_public": true,
            "lineno": 607,
            "invocation_pattern": "advanceddagvalidator_instance.get_graph_stats()"
          },
          {
            "name": "_create_empty_result",
            "decorator": null,
            "signature": "_create_empty_result(self, plan_name: str, seed: int, timestamp: str) -> MonteCarloAdvancedResult",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "plan_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "seed",
                "annotation": "int",
                "default": null
              },
              {
                "name": "timestamp",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "MonteCarloAdvancedResult",
            "docstring": "Crea un resultado vacío para grafos sin nodos.",
            "is_public": false,
            "lineno": 617,
            "invocation_pattern": "advanceddagvalidator_instance._create_empty_result()"
          }
        ]
      },
      {
        "name": "IndustrialGradeValidator",
        "docstring": "Orquesta una validación de grado industrial para el motor de Teoría de Cambio.",
        "base_classes": [],
        "is_public": true,
        "lineno": 648,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": null,
            "is_public": false,
            "lineno": 653,
            "invocation_pattern": "industrialgradevalidator_instance.__init__()"
          },
          {
            "name": "execute_suite",
            "decorator": null,
            "signature": "execute_suite(self) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Ejecuta la suite completa de validación industrial.",
            "is_public": true,
            "lineno": 663,
            "invocation_pattern": "industrialgradevalidator_instance.execute_suite()"
          },
          {
            "name": "validate_engine_readiness",
            "decorator": null,
            "signature": "validate_engine_readiness(self) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Valida la disponibilidad y tiempo de instanciación de los motores de análisis.",
            "is_public": true,
            "lineno": 695,
            "invocation_pattern": "industrialgradevalidator_instance.validate_engine_readiness()"
          },
          {
            "name": "validate_causal_categories",
            "decorator": null,
            "signature": "validate_causal_categories(self) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Valida la completitud y el orden axiomático de las categorías causales.",
            "is_public": true,
            "lineno": 714,
            "invocation_pattern": "industrialgradevalidator_instance.validate_causal_categories()"
          },
          {
            "name": "validate_connection_matrix",
            "decorator": null,
            "signature": "validate_connection_matrix(self) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Valida la matriz de transiciones causales.",
            "is_public": true,
            "lineno": 731,
            "invocation_pattern": "industrialgradevalidator_instance.validate_connection_matrix()"
          },
          {
            "name": "run_performance_benchmarks",
            "decorator": null,
            "signature": "run_performance_benchmarks(self) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": "Ejecuta benchmarks de rendimiento para las operaciones críticas del motor.",
            "is_public": true,
            "lineno": 751,
            "invocation_pattern": "industrialgradevalidator_instance.run_performance_benchmarks()"
          },
          {
            "name": "_benchmark_operation",
            "decorator": null,
            "signature": "_benchmark_operation(self, operation_name: str, callable_obj, threshold: float, *args, **kwargs)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "operation_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "callable_obj",
                "annotation": null,
                "default": null
              },
              {
                "name": "threshold",
                "annotation": "float",
                "default": null
              },
              {
                "name": "*args",
                "annotation": null,
                "default": null
              },
              {
                "name": "**kwargs",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": "Mide el tiempo de ejecución de una operación y registra la métrica.",
            "is_public": false,
            "lineno": 780,
            "invocation_pattern": "industrialgradevalidator_instance._benchmark_operation()"
          },
          {
            "name": "_log_metric",
            "decorator": null,
            "signature": "_log_metric(self, name: str, value: float, unit: str, threshold: float)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "value",
                "annotation": "float",
                "default": null
              },
              {
                "name": "unit",
                "annotation": "str",
                "default": null
              },
              {
                "name": "threshold",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": "Registra y reporta una métrica de validación.",
            "is_public": false,
            "lineno": 790,
            "invocation_pattern": "industrialgradevalidator_instance._log_metric()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "configure_logging",
        "signature": "configure_logging() -> None",
        "parameters": [],
        "return_type": "None",
        "docstring": "Configura un sistema de logging de alto rendimiento para la salida estándar.",
        "is_public": true,
        "lineno": 67
      },
      {
        "name": "_create_advanced_seed",
        "signature": "_create_advanced_seed(plan_name: str, salt: str = '') -> int",
        "parameters": [
          {
            "name": "plan_name",
            "annotation": "str",
            "default": null
          },
          {
            "name": "salt",
            "annotation": "str",
            "default": "''"
          }
        ],
        "return_type": "int",
        "docstring": "Genera una semilla determinista de alta entropía usando SHA-512.\n\nAudit Point 1.1: Deterministic Seeding (RNG)\nGlobal random seed generated deterministically from plan_name and optional salt.\nConfirms reproducibility across numpy/torch/PyMC stochastic elements.\n\nArgs:\n    plan_name: Plan identifier for deterministic derivation\n    salt: Optional salt for sensitivity analysis (varies to bound variance)\n\nReturns:\n    64-bit unsigned integer seed derived from SHA-512 hash\n\nQuality Evidence:\n    Re-run pipeline twice with identical inputs/salt → output hashes must match 100%\n    Achieves MMR-level determinism per Beach & Pedersen 2019",
        "is_public": false,
        "lineno": 322
      },
      {
        "name": "create_policy_theory_of_change_graph",
        "signature": "create_policy_theory_of_change_graph() -> AdvancedDAGValidator",
        "parameters": [],
        "return_type": "AdvancedDAGValidator",
        "docstring": "Construye un grafo causal de demostración alineado con la política P1:\n\"Derechos de las mujeres e igualdad de género\".",
        "is_public": true,
        "lineno": 807
      },
      {
        "name": "main",
        "signature": "main() -> None",
        "parameters": [],
        "return_type": "None",
        "docstring": "Punto de entrada principal para la interfaz de línea de comandos (CLI).",
        "is_public": true,
        "lineno": 842
      }
    ]
  },
  "financiero_viabilidad_tablas": {
    "module_name": "financiero_viabilidad_tablas",
    "docstring": "MUNICIPAL DEVELOPMENT PLAN ANALYZER - PDET COLOMBIA\n===================================================\nVersión: 5.0 - Causal Inference Edition (2025)\nEspecialización: Planes de Desarrollo Municipal con Análisis Causal Bayesiano\nArquitectura: Extracción Avanzada + Inferencia Causal + DAG Learning + Counterfactuals\n\nNUEVA CAPACIDAD - INFERENCIA CAUSAL:\n✓ Identificación automática de mecanismos causales en PDM\n✓ Construcción de DAGs (Directed Acyclic Graphs) para pilares PDET\n✓ Estimación bayesiana de efectos causales directos e indirectos\n✓ Análisis contrafactual de intervenciones\n✓ Cuantificación de heterogeneidad causal por contexto territorial\n✓ Detección de confounders y mediadores\n✓ Análisis de sensibilidad para supuestos de identificación\n\nCOMPLIANCE:\n✓ Python 3.10+ con type hints completos\n✓ Sin placeholders - 100% implementado y probado\n✓ Integración completa con pipeline existente\n✓ Calibrado para estructura de PDM colombianos",
    "classes": [
      {
        "name": "ColombianMunicipalContext",
        "docstring": "Contexto específico del marco normativo colombiano para PDM",
        "base_classes": [],
        "is_public": true,
        "lineno": 72,
        "methods": []
      },
      {
        "name": "CausalNode",
        "docstring": "Nodo en el grafo causal",
        "base_classes": [],
        "is_public": true,
        "lineno": 171,
        "methods": []
      },
      {
        "name": "CausalEdge",
        "docstring": "Arista causal entre nodos",
        "base_classes": [],
        "is_public": true,
        "lineno": 182,
        "methods": []
      },
      {
        "name": "CausalDAG",
        "docstring": "Grafo Acíclico Dirigido completo",
        "base_classes": [],
        "is_public": true,
        "lineno": 194,
        "methods": []
      },
      {
        "name": "CausalEffect",
        "docstring": "Efecto causal estimado",
        "base_classes": [],
        "is_public": true,
        "lineno": 203,
        "methods": []
      },
      {
        "name": "CounterfactualScenario",
        "docstring": "Escenario contrafactual",
        "base_classes": [],
        "is_public": true,
        "lineno": 218,
        "methods": []
      },
      {
        "name": "ExtractedTable",
        "docstring": null,
        "base_classes": [],
        "is_public": true,
        "lineno": 227,
        "methods": []
      },
      {
        "name": "FinancialIndicator",
        "docstring": null,
        "base_classes": [],
        "is_public": true,
        "lineno": 238,
        "methods": []
      },
      {
        "name": "ResponsibleEntity",
        "docstring": null,
        "base_classes": [],
        "is_public": true,
        "lineno": 251,
        "methods": []
      },
      {
        "name": "QualityScore",
        "docstring": null,
        "base_classes": [],
        "is_public": true,
        "lineno": 262,
        "methods": []
      },
      {
        "name": "PDETMunicipalPlanAnalyzer",
        "docstring": "Analizador de vanguardia para Planes de Desarrollo Municipal PDET",
        "base_classes": [],
        "is_public": true,
        "lineno": 278,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, use_gpu: bool = True, language: str = 'es', confidence_threshold: float = 0.7)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "use_gpu",
                "annotation": "bool",
                "default": "True"
              },
              {
                "name": "language",
                "annotation": "str",
                "default": "'es'"
              },
              {
                "name": "confidence_threshold",
                "annotation": "float",
                "default": "0.7"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 281,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.__init__()"
          },
          {
            "name": "_get_spanish_stopwords",
            "decorator": null,
            "signature": "_get_spanish_stopwords(self) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": null,
            "is_public": false,
            "lineno": 322,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._get_spanish_stopwords()"
          },
          {
            "name": "_clean_dataframe",
            "decorator": null,
            "signature": "_clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "df",
                "annotation": "pd.DataFrame",
                "default": null
              }
            ],
            "return_type": "pd.DataFrame",
            "docstring": null,
            "is_public": false,
            "lineno": 402,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._clean_dataframe()"
          },
          {
            "name": "_is_likely_header",
            "decorator": null,
            "signature": "_is_likely_header(self, row: pd.Series) -> bool",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "row",
                "annotation": "pd.Series",
                "default": null
              }
            ],
            "return_type": "bool",
            "docstring": null,
            "is_public": false,
            "lineno": 420,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._is_likely_header()"
          },
          {
            "name": "_deduplicate_tables",
            "decorator": null,
            "signature": "_deduplicate_tables(self, tables: List[ExtractedTable]) -> List[ExtractedTable]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "List[ExtractedTable]",
            "docstring": null,
            "is_public": false,
            "lineno": 428,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._deduplicate_tables()"
          },
          {
            "name": "_classify_tables",
            "decorator": null,
            "signature": "_classify_tables(self, tables: List[ExtractedTable]) -> List[ExtractedTable]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "List[ExtractedTable]",
            "docstring": null,
            "is_public": false,
            "lineno": 495,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._classify_tables()"
          },
          {
            "name": "analyze_financial_feasibility",
            "decorator": null,
            "signature": "analyze_financial_feasibility(self, tables: List[ExtractedTable], text: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": null,
            "is_public": true,
            "lineno": 521,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.analyze_financial_feasibility()"
          },
          {
            "name": "_extract_financial_amounts",
            "decorator": null,
            "signature": "_extract_financial_amounts(self, text: str, tables: List[ExtractedTable]) -> List[FinancialIndicator]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "List[FinancialIndicator]",
            "docstring": null,
            "is_public": false,
            "lineno": 538,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_financial_amounts()"
          },
          {
            "name": "_identify_funding_source",
            "decorator": null,
            "signature": "_identify_funding_source(self, context: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "context",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": null,
            "is_public": false,
            "lineno": 585,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._identify_funding_source()"
          },
          {
            "name": "_extract_from_budget_table",
            "decorator": null,
            "signature": "_extract_from_budget_table(self, df: pd.DataFrame) -> List[FinancialIndicator]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "df",
                "annotation": "pd.DataFrame",
                "default": null
              }
            ],
            "return_type": "List[FinancialIndicator]",
            "docstring": null,
            "is_public": false,
            "lineno": 602,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_from_budget_table()"
          },
          {
            "name": "_analyze_funding_sources",
            "decorator": null,
            "signature": "_analyze_funding_sources(self, indicators: List[FinancialIndicator], tables: List[ExtractedTable]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "indicators",
                "annotation": "List[FinancialIndicator]",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": null,
            "is_public": false,
            "lineno": 642,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._analyze_funding_sources()"
          },
          {
            "name": "_assess_financial_sustainability",
            "decorator": null,
            "signature": "_assess_financial_sustainability(self, indicators: List[FinancialIndicator], funding_sources: Dict[str, Any]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "indicators",
                "annotation": "List[FinancialIndicator]",
                "default": null
              },
              {
                "name": "funding_sources",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": null,
            "is_public": false,
            "lineno": 663,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._assess_financial_sustainability()"
          },
          {
            "name": "_bayesian_risk_inference",
            "decorator": null,
            "signature": "_bayesian_risk_inference(self, indicators: List[FinancialIndicator], funding_sources: Dict[str, Any], sustainability: float) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "indicators",
                "annotation": "List[FinancialIndicator]",
                "default": null
              },
              {
                "name": "funding_sources",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "sustainability",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": null,
            "is_public": false,
            "lineno": 679,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._bayesian_risk_inference()"
          },
          {
            "name": "_interpret_risk",
            "decorator": null,
            "signature": "_interpret_risk(self, risk: float) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "risk",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": null,
            "is_public": false,
            "lineno": 721,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._interpret_risk()"
          },
          {
            "name": "_indicator_to_dict",
            "decorator": null,
            "signature": "_indicator_to_dict(self, ind: FinancialIndicator) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "ind",
                "annotation": "FinancialIndicator",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": null,
            "is_public": false,
            "lineno": 733,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._indicator_to_dict()"
          },
          {
            "name": "identify_responsible_entities",
            "decorator": null,
            "signature": "identify_responsible_entities(self, text: str, tables: List[ExtractedTable]) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": true,
            "lineno": 747,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.identify_responsible_entities()"
          },
          {
            "name": "_extract_entities_ner",
            "decorator": null,
            "signature": "_extract_entities_ner(self, text: str) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": false,
            "lineno": 761,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_entities_ner()"
          },
          {
            "name": "_extract_entities_syntax",
            "decorator": null,
            "signature": "_extract_entities_syntax(self, text: str) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": false,
            "lineno": 786,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_entities_syntax()"
          },
          {
            "name": "_classify_entity_type",
            "decorator": null,
            "signature": "_classify_entity_type(self, name: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "name",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": null,
            "is_public": false,
            "lineno": 813,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._classify_entity_type()"
          },
          {
            "name": "_extract_from_responsibility_tables",
            "decorator": null,
            "signature": "_extract_from_responsibility_tables(self, tables: List[ExtractedTable]) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": false,
            "lineno": 826,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_from_responsibility_tables()"
          },
          {
            "name": "_consolidate_entities",
            "decorator": null,
            "signature": "_consolidate_entities(self, entities: List[ResponsibleEntity]) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "entities",
                "annotation": "List[ResponsibleEntity]",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": false,
            "lineno": 857,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._consolidate_entities()"
          },
          {
            "name": "_score_entity_specificity",
            "decorator": null,
            "signature": "_score_entity_specificity(self, entities: List[ResponsibleEntity], full_text: str) -> List[ResponsibleEntity]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "entities",
                "annotation": "List[ResponsibleEntity]",
                "default": null
              },
              {
                "name": "full_text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[ResponsibleEntity]",
            "docstring": null,
            "is_public": false,
            "lineno": 891,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_entity_specificity()"
          },
          {
            "name": "construct_causal_dag",
            "decorator": null,
            "signature": "construct_causal_dag(self, text: str, tables: List[ExtractedTable], financial_analysis: Dict[str, Any]) -> CausalDAG",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "CausalDAG",
            "docstring": null,
            "is_public": true,
            "lineno": 916,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.construct_causal_dag()"
          },
          {
            "name": "_identify_causal_nodes",
            "decorator": null,
            "signature": "_identify_causal_nodes(self, text: str, tables: List[ExtractedTable], financial_analysis: Dict[str, Any]) -> Dict[str, CausalNode]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, CausalNode]",
            "docstring": null,
            "is_public": false,
            "lineno": 958,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._identify_causal_nodes()"
          },
          {
            "name": "_find_semantic_mentions",
            "decorator": null,
            "signature": "_find_semantic_mentions(self, text: str, concept: str, concept_embedding: np.ndarray) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "concept",
                "annotation": "str",
                "default": null
              },
              {
                "name": "concept_embedding",
                "annotation": "np.ndarray",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": null,
            "is_public": false,
            "lineno": 1008,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._find_semantic_mentions()"
          },
          {
            "name": "_find_outcome_mentions",
            "decorator": null,
            "signature": "_find_outcome_mentions(self, text: str, outcome: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "outcome",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": null,
            "is_public": false,
            "lineno": 1026,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._find_outcome_mentions()"
          },
          {
            "name": "_find_mediator_mentions",
            "decorator": null,
            "signature": "_find_mediator_mentions(self, text: str, mediator: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "mediator",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": null,
            "is_public": false,
            "lineno": 1058,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._find_mediator_mentions()"
          },
          {
            "name": "_extract_budget_for_pillar",
            "decorator": null,
            "signature": "_extract_budget_for_pillar(self, pillar: str, text: str, financial_analysis: Dict[str, Any]) -> Optional[Decimal]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pillar",
                "annotation": "str",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Optional[Decimal]",
            "docstring": null,
            "is_public": false,
            "lineno": 1089,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_budget_for_pillar()"
          },
          {
            "name": "_identify_causal_edges",
            "decorator": null,
            "signature": "_identify_causal_edges(self, text: str, nodes: Dict[str, CausalNode]) -> List[CausalEdge]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, CausalNode]",
                "default": null
              }
            ],
            "return_type": "List[CausalEdge]",
            "docstring": null,
            "is_public": false,
            "lineno": 1110,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._identify_causal_edges()"
          },
          {
            "name": "_match_text_to_node",
            "decorator": null,
            "signature": "_match_text_to_node(self, text: str, nodes: Dict[str, CausalNode]) -> Optional[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, CausalNode]",
                "default": null
              }
            ],
            "return_type": "Optional[str]",
            "docstring": null,
            "is_public": false,
            "lineno": 1173,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._match_text_to_node()"
          },
          {
            "name": "_refine_edge_probabilities",
            "decorator": null,
            "signature": "_refine_edge_probabilities(self, edges: List[CausalEdge], text: str, nodes: Dict[str, CausalNode]) -> List[CausalEdge]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "edges",
                "annotation": "List[CausalEdge]",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "nodes",
                "annotation": "Dict[str, CausalNode]",
                "default": null
              }
            ],
            "return_type": "List[CausalEdge]",
            "docstring": null,
            "is_public": false,
            "lineno": 1196,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._refine_edge_probabilities()"
          },
          {
            "name": "_break_cycles",
            "decorator": null,
            "signature": "_break_cycles(self, G: nx.DiGraph) -> nx.DiGraph",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "G",
                "annotation": "nx.DiGraph",
                "default": null
              }
            ],
            "return_type": "nx.DiGraph",
            "docstring": null,
            "is_public": false,
            "lineno": 1219,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._break_cycles()"
          },
          {
            "name": "estimate_causal_effects",
            "decorator": null,
            "signature": "estimate_causal_effects(self, dag: CausalDAG, text: str, financial_analysis: Dict[str, Any]) -> List[CausalEffect]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "List[CausalEffect]",
            "docstring": null,
            "is_public": true,
            "lineno": 1234,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.estimate_causal_effects()"
          },
          {
            "name": "_estimate_effect_bayesian",
            "decorator": null,
            "signature": "_estimate_effect_bayesian(self, treatment: str, outcome: str, dag: CausalDAG, financial_analysis: Dict[str, Any]) -> Optional[CausalEffect]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "treatment",
                "annotation": "str",
                "default": null
              },
              {
                "name": "outcome",
                "annotation": "str",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Optional[CausalEffect]",
            "docstring": null,
            "is_public": false,
            "lineno": 1259,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._estimate_effect_bayesian()"
          },
          {
            "name": "_get_prior_effect",
            "decorator": null,
            "signature": "_get_prior_effect(self, treatment: str, outcome: str) -> Tuple[float, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "treatment",
                "annotation": "str",
                "default": null
              },
              {
                "name": "outcome",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Tuple[float, float]",
            "docstring": "Priors informados basados en meta-análisis de programas PDET\nReferencia: Cinelli et al. (2022) - Sensitivity Analysis for Causal Inference",
            "is_public": false,
            "lineno": 1329,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._get_prior_effect()"
          },
          {
            "name": "_identify_confounders",
            "decorator": null,
            "signature": "_identify_confounders(self, treatment: str, outcome: str, dag: CausalDAG) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "treatment",
                "annotation": "str",
                "default": null
              },
              {
                "name": "outcome",
                "annotation": "str",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Identifica confounders usando d-separation (Pearl, 2009)",
            "is_public": false,
            "lineno": 1349,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._identify_confounders()"
          },
          {
            "name": "generate_counterfactuals",
            "decorator": null,
            "signature": "generate_counterfactuals(self, dag: CausalDAG, causal_effects: List[CausalEffect], financial_analysis: Dict[str, Any]) -> List[CounterfactualScenario]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "causal_effects",
                "annotation": "List[CausalEffect]",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "List[CounterfactualScenario]",
            "docstring": "Genera escenarios contrafactuales usando el framework de Pearl (2009)\nLevel 3 - Counterfactual: \"What if we had done X instead of Y?\"\n\nImplementación basada en:\n- Pearl & Mackenzie (2018) - The Book of Why\n- Sharma & Kiciman (2020) - DoWhy: An End-to-End Library for Causal Inference",
            "is_public": true,
            "lineno": 1369,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.generate_counterfactuals()"
          },
          {
            "name": "_simulate_intervention",
            "decorator": null,
            "signature": "_simulate_intervention(self, intervention: Dict[str, float], dag: CausalDAG, causal_effects: List[CausalEffect], description: str) -> CounterfactualScenario",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "intervention",
                "annotation": "Dict[str, float]",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "causal_effects",
                "annotation": "List[CausalEffect]",
                "default": null
              },
              {
                "name": "description",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "CounterfactualScenario",
            "docstring": "Simula intervención usando do-calculus (Pearl, 2009)\nImplementa: P(Y | do(X=x)) mediante propagación por el DAG",
            "is_public": false,
            "lineno": 1433,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._simulate_intervention()"
          },
          {
            "name": "_generate_scenario_narrative",
            "decorator": null,
            "signature": "_generate_scenario_narrative(self, description: str, intervention: Dict[str, float], predicted_outcomes: Dict[str, Tuple[float, float, float]], probabilities: Dict[str, float]) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "description",
                "annotation": "str",
                "default": null
              },
              {
                "name": "intervention",
                "annotation": "Dict[str, float]",
                "default": null
              },
              {
                "name": "predicted_outcomes",
                "annotation": "Dict[str, Tuple[float, float, float]]",
                "default": null
              },
              {
                "name": "probabilities",
                "annotation": "Dict[str, float]",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Genera narrativa interpretable del escenario contrafactual",
            "is_public": false,
            "lineno": 1499,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._generate_scenario_narrative()"
          },
          {
            "name": "sensitivity_analysis",
            "decorator": null,
            "signature": "sensitivity_analysis(self, causal_effects: List[CausalEffect], dag: CausalDAG) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "causal_effects",
                "annotation": "List[CausalEffect]",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Análisis de sensibilidad para supuestos de identificación causal\nBasado en: Cinelli, Forney & Pearl (2022) - \"A Crash Course in Good and Bad Controls\"",
            "is_public": true,
            "lineno": 1529,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.sensitivity_analysis()"
          },
          {
            "name": "_compute_e_value",
            "decorator": null,
            "signature": "_compute_e_value(self, effect: CausalEffect) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "effect",
                "annotation": "CausalEffect",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "E-value: mínima fuerza de confounding no observado para anular el efecto\nFórmula: E = effect_estimate + sqrt(effect_estimate * (effect_estimate - 1))\n\nReferencia: VanderWeele & Ding (2017) - Ann Intern Med",
            "is_public": false,
            "lineno": 1552,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._compute_e_value()"
          },
          {
            "name": "_compute_robustness_value",
            "decorator": null,
            "signature": "_compute_robustness_value(self, effect: CausalEffect, dag: CausalDAG) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "effect",
                "annotation": "CausalEffect",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Robustness Value: percentil de la distribución posterior que cruza cero\nValores altos (>0.95) indican alta robustez",
            "is_public": false,
            "lineno": 1569,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._compute_robustness_value()"
          },
          {
            "name": "_interpret_sensitivity",
            "decorator": null,
            "signature": "_interpret_sensitivity(self, e_value: float, robustness: float) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "e_value",
                "annotation": "float",
                "default": null
              },
              {
                "name": "robustness",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Interpretación de resultados de sensibilidad",
            "is_public": false,
            "lineno": 1588,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._interpret_sensitivity()"
          },
          {
            "name": "calculate_quality_score",
            "decorator": null,
            "signature": "calculate_quality_score(self, text: str, tables: List[ExtractedTable], financial_analysis: Dict[str, Any], responsible_entities: List[ResponsibleEntity], causal_dag: CausalDAG, causal_effects: List[CausalEffect]) -> QualityScore",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "responsible_entities",
                "annotation": "List[ResponsibleEntity]",
                "default": null
              },
              {
                "name": "causal_dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "causal_effects",
                "annotation": "List[CausalEffect]",
                "default": null
              }
            ],
            "return_type": "QualityScore",
            "docstring": "Puntaje bayesiano integral de calidad del PDM\nIntegra todas las dimensiones de análisis con pesos calibrados",
            "is_public": true,
            "lineno": 1605,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.calculate_quality_score()"
          },
          {
            "name": "_score_financial_component",
            "decorator": null,
            "signature": "_score_financial_component(self, financial_analysis: Dict[str, Any]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "financial_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score componente financiero (0-10)",
            "is_public": false,
            "lineno": 1656,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_financial_component()"
          },
          {
            "name": "_score_indicators",
            "decorator": null,
            "signature": "_score_indicators(self, tables: List[ExtractedTable], text: str) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score calidad de indicadores (0-10)",
            "is_public": false,
            "lineno": 1677,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_indicators()"
          },
          {
            "name": "_score_responsibility_clarity",
            "decorator": null,
            "signature": "_score_responsibility_clarity(self, entities: List[ResponsibleEntity]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "entities",
                "annotation": "List[ResponsibleEntity]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score claridad de responsables (0-10)",
            "is_public": false,
            "lineno": 1715,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_responsibility_clarity()"
          },
          {
            "name": "_score_temporal_consistency",
            "decorator": null,
            "signature": "_score_temporal_consistency(self, text: str, tables: List[ExtractedTable]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score consistencia temporal (0-10)",
            "is_public": false,
            "lineno": 1732,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_temporal_consistency()"
          },
          {
            "name": "_score_pdet_alignment",
            "decorator": null,
            "signature": "_score_pdet_alignment(self, text: str, tables: List[ExtractedTable], dag: CausalDAG) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "tables",
                "annotation": "List[ExtractedTable]",
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score alineación con pilares PDET (0-10)",
            "is_public": false,
            "lineno": 1753,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_pdet_alignment()"
          },
          {
            "name": "_score_causal_coherence",
            "decorator": null,
            "signature": "_score_causal_coherence(self, dag: CausalDAG, effects: List[CausalEffect]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "effects",
                "annotation": "List[CausalEffect]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Score coherencia causal del plan (0-10)",
            "is_public": false,
            "lineno": 1778,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._score_causal_coherence()"
          },
          {
            "name": "_estimate_score_confidence",
            "decorator": null,
            "signature": "_estimate_score_confidence(self, scores: np.ndarray, weights: np.ndarray) -> Tuple[float, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "scores",
                "annotation": "np.ndarray",
                "default": null
              },
              {
                "name": "weights",
                "annotation": "np.ndarray",
                "default": null
              }
            ],
            "return_type": "Tuple[float, float]",
            "docstring": "Estima intervalo de confianza para el score usando bootstrap",
            "is_public": false,
            "lineno": 1802,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._estimate_score_confidence()"
          },
          {
            "name": "export_causal_network",
            "decorator": null,
            "signature": "export_causal_network(self, dag: CausalDAG, output_path: str) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "dag",
                "annotation": "CausalDAG",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Exporta el DAG causal en formato GraphML para Gephi/Cytoscape",
            "is_public": true,
            "lineno": 1824,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.export_causal_network()"
          },
          {
            "name": "generate_executive_report",
            "decorator": null,
            "signature": "generate_executive_report(self, analysis_results: Dict[str, Any]) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "analysis_results",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Genera reporte ejecutivo en Markdown",
            "is_public": true,
            "lineno": 1841,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance.generate_executive_report()"
          },
          {
            "name": "_interpret_overall_quality",
            "decorator": null,
            "signature": "_interpret_overall_quality(self, score: float) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "score",
                "annotation": "float",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Interpretación del score global",
            "is_public": false,
            "lineno": 1923,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._interpret_overall_quality()"
          },
          {
            "name": "_generate_recommendations",
            "decorator": null,
            "signature": "_generate_recommendations(self, analysis_results: Dict[str, Any]) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "analysis_results",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Genera recomendaciones específicas basadas en el análisis",
            "is_public": false,
            "lineno": 1944,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._generate_recommendations()"
          },
          {
            "name": "_extract_full_text",
            "decorator": null,
            "signature": "_extract_full_text(self, pdf_path: str) -> str",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "pdf_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Extrae texto completo del PDF usando múltiples métodos",
            "is_public": false,
            "lineno": 2128,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._extract_full_text()"
          },
          {
            "name": "_entity_to_dict",
            "decorator": null,
            "signature": "_entity_to_dict(self, entity: ResponsibleEntity) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "entity",
                "annotation": "ResponsibleEntity",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Convierte ResponsibleEntity a diccionario",
            "is_public": false,
            "lineno": 2159,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._entity_to_dict()"
          },
          {
            "name": "_effect_to_dict",
            "decorator": null,
            "signature": "_effect_to_dict(self, effect: CausalEffect) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "effect",
                "annotation": "CausalEffect",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Convierte CausalEffect a diccionario",
            "is_public": false,
            "lineno": 2170,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._effect_to_dict()"
          },
          {
            "name": "_scenario_to_dict",
            "decorator": null,
            "signature": "_scenario_to_dict(self, scenario: CounterfactualScenario) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "scenario",
                "annotation": "CounterfactualScenario",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Convierte CounterfactualScenario a diccionario",
            "is_public": false,
            "lineno": 2185,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._scenario_to_dict()"
          },
          {
            "name": "_quality_to_dict",
            "decorator": null,
            "signature": "_quality_to_dict(self, quality: QualityScore) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "quality",
                "annotation": "QualityScore",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Convierte QualityScore a diccionario",
            "is_public": false,
            "lineno": 2194,
            "invocation_pattern": "pdetmunicipalplananalyzer_instance._quality_to_dict()"
          }
        ]
      },
      {
        "name": "PDETAnalysisException",
        "docstring": "Excepción personalizada para errores de análisis",
        "base_classes": [
          "Exception"
        ],
        "is_public": true,
        "lineno": 2213,
        "methods": []
      }
    ],
    "functions": [
      {
        "name": "validate_pdf_path",
        "signature": "validate_pdf_path(pdf_path: str) -> Path",
        "parameters": [
          {
            "name": "pdf_path",
            "annotation": "str",
            "default": null
          }
        ],
        "return_type": "Path",
        "docstring": "Valida que el path del PDF exista y sea válido",
        "is_public": true,
        "lineno": 2218
      },
      {
        "name": "setup_logging",
        "signature": "setup_logging(log_level: str = 'INFO') -> None",
        "parameters": [
          {
            "name": "log_level",
            "annotation": "str",
            "default": "'INFO'"
          }
        ],
        "return_type": "None",
        "docstring": "Configura logging para el análisis",
        "is_public": true,
        "lineno": 2235
      }
    ]
  },
  "Analyzer_one": {
    "module_name": "Analyzer_one",
    "docstring": "Enhanced Municipal Development Plan Analyzer - Production-Grade Implementation.\n\nThis module implements state-of-the-art techniques for comprehensive municipal plan analysis:\n- Semantic cubes with knowledge graphs and ontological reasoning\n- Multi-dimensional baseline analysis with automated extraction\n- Advanced NLP for multimodal text mining and causal discovery\n- Real-time monitoring with statistical process control\n- Bayesian optimization for resource allocation\n- Uncertainty quantification with Monte Carlo methods\n\nPython 3.11+ Compatible Version",
    "classes": [
      {
        "name": "ValueChainLink",
        "docstring": "Represents a link in the municipal development value chain.",
        "base_classes": [],
        "is_public": true,
        "lineno": 77,
        "methods": []
      },
      {
        "name": "MunicipalOntology",
        "docstring": "Core ontology for municipal development domains.",
        "base_classes": [],
        "is_public": true,
        "lineno": 90,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 93,
            "invocation_pattern": "municipalontology_instance.__init__()"
          }
        ]
      },
      {
        "name": "SemanticAnalyzer",
        "docstring": "Advanced semantic analysis for municipal documents.",
        "base_classes": [],
        "is_public": true,
        "lineno": 149,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, ontology: MunicipalOntology)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "ontology",
                "annotation": "MunicipalOntology",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 152,
            "invocation_pattern": "semanticanalyzer_instance.__init__()"
          },
          {
            "name": "extract_semantic_cube",
            "decorator": null,
            "signature": "extract_semantic_cube(self, document_segments: List[str]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "document_segments",
                "annotation": "List[str]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Extract multidimensional semantic cube from document segments.",
            "is_public": true,
            "lineno": 163,
            "invocation_pattern": "semanticanalyzer_instance.extract_semantic_cube()"
          },
          {
            "name": "_empty_semantic_cube",
            "decorator": null,
            "signature": "_empty_semantic_cube(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Return empty semantic cube structure.",
            "is_public": false,
            "lineno": 235,
            "invocation_pattern": "semanticanalyzer_instance._empty_semantic_cube()"
          },
          {
            "name": "_vectorize_segments",
            "decorator": null,
            "signature": "_vectorize_segments(self, segments: List[str]) -> np.ndarray",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "List[str]",
                "default": null
              }
            ],
            "return_type": "np.ndarray",
            "docstring": "Vectorize document segments using TF-IDF.",
            "is_public": false,
            "lineno": 256,
            "invocation_pattern": "semanticanalyzer_instance._vectorize_segments()"
          },
          {
            "name": "_process_segment",
            "decorator": null,
            "signature": "_process_segment(self, segment: str, idx: int, vector) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segment",
                "annotation": "str",
                "default": null
              },
              {
                "name": "idx",
                "annotation": "int",
                "default": null
              },
              {
                "name": "vector",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Process individual segment and extract features.",
            "is_public": false,
            "lineno": 271,
            "invocation_pattern": "semanticanalyzer_instance._process_segment()"
          },
          {
            "name": "_classify_value_chain_link",
            "decorator": null,
            "signature": "_classify_value_chain_link(self, segment: str) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segment",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Classify segment by value chain link using keyword matching.",
            "is_public": false,
            "lineno": 308,
            "invocation_pattern": "semanticanalyzer_instance._classify_value_chain_link()"
          },
          {
            "name": "_classify_policy_domain",
            "decorator": null,
            "signature": "_classify_policy_domain(self, segment: str) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segment",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Classify segment by policy domain using keyword matching.",
            "is_public": false,
            "lineno": 331,
            "invocation_pattern": "semanticanalyzer_instance._classify_policy_domain()"
          },
          {
            "name": "_classify_cross_cutting_themes",
            "decorator": null,
            "signature": "_classify_cross_cutting_themes(self, segment: str) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segment",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Classify segment by cross-cutting themes.",
            "is_public": false,
            "lineno": 346,
            "invocation_pattern": "semanticanalyzer_instance._classify_cross_cutting_themes()"
          },
          {
            "name": "_calculate_semantic_complexity",
            "decorator": null,
            "signature": "_calculate_semantic_complexity(self, semantic_cube: Dict[str, Any]) -> float",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "semantic_cube",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "float",
            "docstring": "Calculate semantic complexity of the cube.",
            "is_public": false,
            "lineno": 361,
            "invocation_pattern": "semanticanalyzer_instance._calculate_semantic_complexity()"
          }
        ]
      },
      {
        "name": "PerformanceAnalyzer",
        "docstring": "Analyze value chain performance with operational loss functions.",
        "base_classes": [],
        "is_public": true,
        "lineno": 379,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, ontology: MunicipalOntology)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "ontology",
                "annotation": "MunicipalOntology",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 382,
            "invocation_pattern": "performanceanalyzer_instance.__init__()"
          },
          {
            "name": "analyze_performance",
            "decorator": null,
            "signature": "analyze_performance(self, semantic_cube: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "semantic_cube",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Analyze performance indicators across value chain links.",
            "is_public": true,
            "lineno": 389,
            "invocation_pattern": "performanceanalyzer_instance.analyze_performance()"
          },
          {
            "name": "_calculate_throughput_metrics",
            "decorator": null,
            "signature": "_calculate_throughput_metrics(self, segments: List[Dict], link_config: ValueChainLink) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "List[Dict]",
                "default": null
              },
              {
                "name": "link_config",
                "annotation": "ValueChainLink",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Calculate throughput metrics for a value chain link.",
            "is_public": false,
            "lineno": 420,
            "invocation_pattern": "performanceanalyzer_instance._calculate_throughput_metrics()"
          },
          {
            "name": "_detect_bottlenecks",
            "decorator": null,
            "signature": "_detect_bottlenecks(self, segments: List[Dict], link_config: ValueChainLink) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "List[Dict]",
                "default": null
              },
              {
                "name": "link_config",
                "annotation": "ValueChainLink",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Detect bottlenecks in value chain link.",
            "is_public": false,
            "lineno": 458,
            "invocation_pattern": "performanceanalyzer_instance._detect_bottlenecks()"
          },
          {
            "name": "_calculate_loss_functions",
            "decorator": null,
            "signature": "_calculate_loss_functions(self, metrics: Dict[str, Any], link_config: ValueChainLink) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "metrics",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "link_config",
                "annotation": "ValueChainLink",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Calculate operational loss functions.",
            "is_public": false,
            "lineno": 492,
            "invocation_pattern": "performanceanalyzer_instance._calculate_loss_functions()"
          },
          {
            "name": "_generate_recommendations",
            "decorator": null,
            "signature": "_generate_recommendations(self, performance_analysis: Dict[str, Any]) -> List[Dict[str, Any]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "performance_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, Any]]",
            "docstring": "Generate optimization recommendations.",
            "is_public": false,
            "lineno": 526,
            "invocation_pattern": "performanceanalyzer_instance._generate_recommendations()"
          }
        ]
      },
      {
        "name": "TextMiningEngine",
        "docstring": "Advanced text mining for critical diagnosis.",
        "base_classes": [],
        "is_public": true,
        "lineno": 555,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, ontology: MunicipalOntology)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "ontology",
                "annotation": "MunicipalOntology",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 558,
            "invocation_pattern": "textminingengine_instance.__init__()"
          },
          {
            "name": "diagnose_critical_links",
            "decorator": null,
            "signature": "diagnose_critical_links(self, semantic_cube: Dict[str, Any], performance_analysis: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "semantic_cube",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "performance_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Diagnose critical value chain links.",
            "is_public": true,
            "lineno": 575,
            "invocation_pattern": "textminingengine_instance.diagnose_critical_links()"
          },
          {
            "name": "_identify_critical_links",
            "decorator": null,
            "signature": "_identify_critical_links(self, performance_analysis: Dict[str, Any]) -> Dict[str, float]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "performance_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, float]",
            "docstring": "Identify critical links based on performance metrics.",
            "is_public": false,
            "lineno": 611,
            "invocation_pattern": "textminingengine_instance._identify_critical_links()"
          },
          {
            "name": "_analyze_link_text",
            "decorator": null,
            "signature": "_analyze_link_text(self, segments: List[Dict]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "List[Dict]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Analyze text content for a link.",
            "is_public": false,
            "lineno": 638,
            "invocation_pattern": "textminingengine_instance._analyze_link_text()"
          },
          {
            "name": "_assess_risks",
            "decorator": null,
            "signature": "_assess_risks(self, segments: List[Dict], text_analysis: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "segments",
                "annotation": "List[Dict]",
                "default": null
              },
              {
                "name": "text_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Assess risks for a value chain link.",
            "is_public": false,
            "lineno": 675,
            "invocation_pattern": "textminingengine_instance._assess_risks()"
          },
          {
            "name": "_generate_interventions",
            "decorator": null,
            "signature": "_generate_interventions(self, link_name: str, risk_assessment: Dict[str, Any], text_analysis: Dict[str, Any]) -> List[Dict[str, str]]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "link_name",
                "annotation": "str",
                "default": null
              },
              {
                "name": "risk_assessment",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "text_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "List[Dict[str, str]]",
            "docstring": "Generate intervention recommendations.",
            "is_public": false,
            "lineno": 703,
            "invocation_pattern": "textminingengine_instance._generate_interventions()"
          }
        ]
      },
      {
        "name": "MunicipalAnalyzer",
        "docstring": "Main analyzer integrating all components.",
        "base_classes": [],
        "is_public": true,
        "lineno": 737,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 740,
            "invocation_pattern": "municipalanalyzer_instance.__init__()"
          },
          {
            "name": "analyze_document",
            "decorator": null,
            "signature": "analyze_document(self, document_path: str) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "document_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Perform comprehensive analysis of a municipal document.",
            "is_public": true,
            "lineno": 748,
            "invocation_pattern": "municipalanalyzer_instance.analyze_document()"
          },
          {
            "name": "_load_document",
            "decorator": null,
            "signature": "_load_document(self, document_path: str) -> List[str]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "document_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "List[str]",
            "docstring": "Load and segment document.",
            "is_public": false,
            "lineno": 790,
            "invocation_pattern": "municipalanalyzer_instance._load_document()"
          },
          {
            "name": "_generate_summary",
            "decorator": null,
            "signature": "_generate_summary(self, semantic_cube: Dict[str, Any], performance_analysis: Dict[str, Any], critical_diagnosis: Dict[str, Any]) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "semantic_cube",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "performance_analysis",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "critical_diagnosis",
                "annotation": "Dict[str, Any]",
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Generate executive summary of analysis.",
            "is_public": false,
            "lineno": 812,
            "invocation_pattern": "municipalanalyzer_instance._generate_summary()"
          }
        ]
      },
      {
        "name": "DocumentProcessor",
        "docstring": "Utility class for document processing.",
        "base_classes": [],
        "is_public": true,
        "lineno": 980,
        "methods": [
          {
            "name": "load_pdf",
            "decorator": "staticmethod",
            "signature": "load_pdf(pdf_path: str) -> str",
            "parameters": [
              {
                "name": "pdf_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Load text from PDF file.",
            "is_public": true,
            "lineno": 984,
            "invocation_pattern": "DocumentProcessor.load_pdf()"
          },
          {
            "name": "load_docx",
            "decorator": "staticmethod",
            "signature": "load_docx(docx_path: str) -> str",
            "parameters": [
              {
                "name": "docx_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "str",
            "docstring": "Load text from DOCX file.",
            "is_public": true,
            "lineno": 1002,
            "invocation_pattern": "DocumentProcessor.load_docx()"
          },
          {
            "name": "segment_text",
            "decorator": "staticmethod",
            "signature": "segment_text(text: str, method: str = 'sentence') -> List[str]",
            "parameters": [
              {
                "name": "text",
                "annotation": "str",
                "default": null
              },
              {
                "name": "method",
                "annotation": "str",
                "default": "'sentence'"
              }
            ],
            "return_type": "List[str]",
            "docstring": "Segment text using different methods.",
            "is_public": true,
            "lineno": 1019,
            "invocation_pattern": "DocumentProcessor.segment_text()"
          }
        ]
      },
      {
        "name": "ResultsExporter",
        "docstring": "Export analysis results to different formats.",
        "base_classes": [],
        "is_public": true,
        "lineno": 1062,
        "methods": [
          {
            "name": "export_to_json",
            "decorator": "staticmethod",
            "signature": "export_to_json(results: Dict[str, Any], output_path: str) -> None",
            "parameters": [
              {
                "name": "results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Export results to JSON file.",
            "is_public": true,
            "lineno": 1066,
            "invocation_pattern": "ResultsExporter.export_to_json()"
          },
          {
            "name": "export_to_excel",
            "decorator": "staticmethod",
            "signature": "export_to_excel(results: Dict[str, Any], output_path: str) -> None",
            "parameters": [
              {
                "name": "results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Export results to Excel file.",
            "is_public": true,
            "lineno": 1076,
            "invocation_pattern": "ResultsExporter.export_to_excel()"
          },
          {
            "name": "export_summary_report",
            "decorator": "staticmethod",
            "signature": "export_summary_report(results: Dict[str, Any], output_path: str) -> None",
            "parameters": [
              {
                "name": "results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Export a summary report in text format.",
            "is_public": true,
            "lineno": 1141,
            "invocation_pattern": "ResultsExporter.export_summary_report()"
          }
        ]
      },
      {
        "name": "ConfigurationManager",
        "docstring": "Manage analyzer configuration.",
        "base_classes": [],
        "is_public": true,
        "lineno": 1253,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, config_path: Optional[str] = None)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "config_path",
                "annotation": "Optional[str]",
                "default": "None"
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 1256,
            "invocation_pattern": "configurationmanager_instance.__init__()"
          },
          {
            "name": "load_config",
            "decorator": null,
            "signature": "load_config(self) -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Load configuration from file or create default.",
            "is_public": true,
            "lineno": 1260,
            "invocation_pattern": "configurationmanager_instance.load_config()"
          },
          {
            "name": "save_config",
            "decorator": null,
            "signature": "save_config(self) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Save current configuration to file.",
            "is_public": true,
            "lineno": 1295,
            "invocation_pattern": "configurationmanager_instance.save_config()"
          }
        ]
      },
      {
        "name": "BatchProcessor",
        "docstring": "Process multiple documents in batch.",
        "base_classes": [],
        "is_public": true,
        "lineno": 1304,
        "methods": [
          {
            "name": "__init__",
            "decorator": null,
            "signature": "__init__(self, analyzer: MunicipalAnalyzer)",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "analyzer",
                "annotation": "MunicipalAnalyzer",
                "default": null
              }
            ],
            "return_type": null,
            "docstring": null,
            "is_public": false,
            "lineno": 1307,
            "invocation_pattern": "batchprocessor_instance.__init__()"
          },
          {
            "name": "process_directory",
            "decorator": null,
            "signature": "process_directory(self, directory_path: str, pattern: str = '*.txt') -> Dict[str, Any]",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "directory_path",
                "annotation": "str",
                "default": null
              },
              {
                "name": "pattern",
                "annotation": "str",
                "default": "'*.txt'"
              }
            ],
            "return_type": "Dict[str, Any]",
            "docstring": "Process all files matching pattern in directory.",
            "is_public": true,
            "lineno": 1310,
            "invocation_pattern": "batchprocessor_instance.process_directory()"
          },
          {
            "name": "export_batch_results",
            "decorator": null,
            "signature": "export_batch_results(self, batch_results: Dict[str, Any], output_dir: str) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "batch_results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_dir",
                "annotation": "str",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Export batch processing results.",
            "is_public": true,
            "lineno": 1333,
            "invocation_pattern": "batchprocessor_instance.export_batch_results()"
          },
          {
            "name": "_create_batch_summary",
            "decorator": null,
            "signature": "_create_batch_summary(self, batch_results: Dict[str, Any], output_path: Path) -> None",
            "parameters": [
              {
                "name": "self",
                "annotation": null,
                "default": null
              },
              {
                "name": "batch_results",
                "annotation": "Dict[str, Any]",
                "default": null
              },
              {
                "name": "output_path",
                "annotation": "Path",
                "default": null
              }
            ],
            "return_type": "None",
            "docstring": "Create summary of batch processing results.",
            "is_public": false,
            "lineno": 1355,
            "invocation_pattern": "batchprocessor_instance._create_batch_summary()"
          }
        ]
      }
    ],
    "functions": [
      {
        "name": "example_usage",
        "signature": "example_usage()",
        "parameters": [],
        "return_type": null,
        "docstring": "Example usage of the Municipal Analyzer.",
        "is_public": true,
        "lineno": 860
      },
      {
        "name": "main",
        "signature": "main()",
        "parameters": [],
        "return_type": null,
        "docstring": "Simple command-line interface.",
        "is_public": true,
        "lineno": 1402
      }
    ]
  }
}